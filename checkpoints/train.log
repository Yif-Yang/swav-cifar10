INFO - 09/02/20 13:55:22 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 13:55:22 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 13:55:22 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 13:59:40 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 13:59:40 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 13:59:40 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 13:59:41 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 13:59:58 - 0:00:18 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 13:59:58 - 0:00:18 - Building model done.
INFO - 09/02/20 14:00:02 - 0:00:22 - Building optimizer done.
INFO - 09/02/20 14:00:02 - 0:00:22 - Initializing mixed precision done.
INFO - 09/02/20 14:00:02 - 0:00:22 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:00:36 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:00:36 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:00:36 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:00:36 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:00:53 - 0:00:18 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:00:53 - 0:00:18 - Building model done.
INFO - 09/02/20 14:00:57 - 0:00:22 - Building optimizer done.
INFO - 09/02/20 14:00:57 - 0:00:22 - Initializing mixed precision done.
INFO - 09/02/20 14:00:57 - 0:00:22 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:04:10 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:04:10 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:04:10 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:04:36 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:04:36 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:04:36 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:04:36 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:04:54 - 0:00:18 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:04:54 - 0:00:18 - Building model done.
INFO - 09/02/20 14:04:58 - 0:00:22 - Building optimizer done.
INFO - 09/02/20 14:04:58 - 0:00:22 - Initializing mixed precision done.
INFO - 09/02/20 14:04:58 - 0:00:22 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:05:20 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:05:20 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:05:20 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:05:21 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:05:39 - 0:00:19 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:05:39 - 0:00:19 - Building model done.
INFO - 09/02/20 14:05:43 - 0:00:23 - Building optimizer done.
INFO - 09/02/20 14:05:43 - 0:00:23 - Initializing mixed precision done.
INFO - 09/02/20 14:05:43 - 0:00:23 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:06:55 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:06:55 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:06:55 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:06:56 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:07:16 - 0:00:21 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:07:16 - 0:00:21 - Building model done.
INFO - 09/02/20 14:07:20 - 0:00:25 - Building optimizer done.
INFO - 09/02/20 14:07:20 - 0:00:25 - Initializing mixed precision done.
INFO - 09/02/20 14:07:20 - 0:00:25 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:07:47 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:07:47 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:07:47 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:07:48 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:08:08 - 0:00:21 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:08:08 - 0:00:21 - Building model done.
INFO - 09/02/20 14:08:12 - 0:00:25 - Building optimizer done.
INFO - 09/02/20 14:08:13 - 0:00:25 - Initializing mixed precision done.
INFO - 09/02/20 14:08:13 - 0:00:25 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:11:52 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:11:52 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:11:52 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:11:52 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:12:10 - 0:00:19 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:12:10 - 0:00:19 - Building model done.
INFO - 09/02/20 14:12:14 - 0:00:23 - Building optimizer done.
INFO - 09/02/20 14:12:14 - 0:00:23 - Initializing mixed precision done.
INFO - 09/02/20 14:12:14 - 0:00:23 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:15:57 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:15:57 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [1]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:15:57 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:15:58 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:16:16 - 0:00:19 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:16:16 - 0:00:19 - Building model done.
INFO - 09/02/20 14:16:20 - 0:00:23 - Building optimizer done.
INFO - 09/02/20 14:16:20 - 0:00:23 - Initializing mixed precision done.
INFO - 09/02/20 14:16:20 - 0:00:23 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:17:39 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:17:39 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 32
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:17:39 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:17:39 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:17:59 - 0:00:21 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:17:59 - 0:00:21 - Building model done.
INFO - 09/02/20 14:18:03 - 0:00:24 - Building optimizer done.
INFO - 09/02/20 14:18:03 - 0:00:24 - Initializing mixed precision done.
INFO - 09/02/20 14:18:03 - 0:00:24 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:18:08 - 0:00:30 - Epoch: [0][0]	Time 5.399 (5.399)	Data 0.725 (0.725)	Loss 4.2811 (4.2811)	Lr: 0.0000
INFO - 09/02/20 14:19:41 - 0:02:03 - Epoch: [0][50]	Time 2.376 (1.927)	Data 0.000 (0.014)	Loss 4.2079 (4.2377)	Lr: 0.0019
INFO - 09/02/20 14:21:10 - 0:03:31 - Epoch: [0][100]	Time 1.714 (1.851)	Data 0.000 (0.007)	Loss 4.1233 (4.1972)	Lr: 0.0038
INFO - 09/02/20 14:22:42 - 0:05:03 - Epoch: [0][150]	Time 1.970 (1.846)	Data 0.000 (0.005)	Loss 4.0517 (4.1614)	Lr: 0.0058
INFO - 09/02/20 14:24:17 - 0:06:38 - Epoch: [0][200]	Time 0.901 (1.859)	Data 0.000 (0.004)	Loss 4.0036 (4.1334)	Lr: 0.0077
INFO - 09/02/20 14:25:40 - 0:08:02 - Epoch: [0][250]	Time 0.781 (1.822)	Data 0.000 (0.003)	Loss 3.9891 (4.1089)	Lr: 0.0096
INFO - 09/02/20 14:27:09 - 0:09:30 - Epoch: [0][300]	Time 2.282 (1.813)	Data 0.000 (0.003)	Loss 3.9839 (4.0880)	Lr: 0.0115
INFO - 09/02/20 14:28:54 - 0:11:15 - Epoch: [0][350]	Time 2.449 (1.854)	Data 0.000 (0.002)	Loss 3.9498 (4.0694)	Lr: 0.0134
INFO - 09/02/20 14:30:53 - 0:13:15 - Epoch: [0][400]	Time 1.666 (1.921)	Data 0.000 (0.002)	Loss 3.9347 (4.0536)	Lr: 0.0154
INFO - 09/02/20 14:32:54 - 0:15:15 - Epoch: [0][450]	Time 2.455 (1.976)	Data 0.000 (0.002)	Loss 3.9246 (4.0402)	Lr: 0.0173
INFO - 09/02/20 14:34:50 - 0:17:12 - Epoch: [0][500]	Time 2.444 (2.011)	Data 0.000 (0.002)	Loss 3.9209 (4.0285)	Lr: 0.0192
INFO - 09/02/20 14:36:41 - 0:19:03 - Epoch: [0][550]	Time 2.419 (2.030)	Data 0.000 (0.001)	Loss 3.9178 (4.0186)	Lr: 0.0211
INFO - 09/02/20 14:38:31 - 0:20:53 - Epoch: [0][600]	Time 2.432 (2.044)	Data 0.000 (0.001)	Loss 3.9157 (4.0101)	Lr: 0.0230
INFO - 09/02/20 14:40:26 - 0:22:47 - Epoch: [0][650]	Time 2.074 (2.063)	Data 0.000 (0.001)	Loss 3.9140 (4.0028)	Lr: 0.0250
INFO - 09/02/20 14:42:15 - 0:24:36 - Epoch: [0][700]	Time 0.785 (2.071)	Data 0.000 (0.001)	Loss 3.9140 (3.9965)	Lr: 0.0269
INFO - 09/02/20 14:43:36 - 0:25:58 - Epoch: [0][750]	Time 1.792 (2.042)	Data 0.000 (0.001)	Loss 3.9133 (3.9909)	Lr: 0.0288
INFO - 09/02/20 14:45:06 - 0:27:27 - Epoch: [0][800]	Time 1.623 (2.026)	Data 0.000 (0.001)	Loss 3.9125 (3.9860)	Lr: 0.0307
INFO - 09/02/20 14:46:40 - 0:29:02 - Epoch: [0][850]	Time 2.255 (2.018)	Data 0.000 (0.001)	Loss 3.9126 (3.9817)	Lr: 0.0327
INFO - 09/02/20 14:48:19 - 0:30:41 - Epoch: [0][900]	Time 2.165 (2.016)	Data 0.000 (0.001)	Loss 3.9125 (3.9779)	Lr: 0.0346
INFO - 09/02/20 14:49:54 - 0:32:15 - Epoch: [0][950]	Time 1.677 (2.009)	Data 0.000 (0.001)	Loss 3.9122 (3.9745)	Lr: 0.0365
INFO - 09/02/20 14:51:51 - 0:34:12 - Epoch: [0][1000]	Time 2.356 (2.026)	Data 0.000 (0.001)	Loss 3.9123 (3.9713)	Lr: 0.0384
INFO - 09/02/20 14:53:49 - 0:36:10 - Epoch: [0][1050]	Time 2.468 (2.042)	Data 0.000 (0.001)	Loss 3.9122 (3.9685)	Lr: 0.0403
INFO - 09/02/20 14:57:17 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 14:57:17 - 0:00:00 - arch: resnet50
                                     base_lr: 0.6
                                     batch_size: 512
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 14:57:17 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 14:57:18 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 14:57:23 - 0:00:06 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 14:57:23 - 0:00:06 - Building model done.
INFO - 09/02/20 14:57:23 - 0:00:06 - Building optimizer done.
INFO - 09/02/20 14:57:23 - 0:00:06 - Initializing mixed precision done.
INFO - 09/02/20 14:57:23 - 0:00:06 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 14:57:37 - 0:00:20 - Epoch: [0][0]	Time 14.022 (14.022)	Data 1.877 (1.877)	Loss 4.2315 (4.2315)	Lr: 0.0000
INFO - 09/02/20 14:58:09 - 0:00:52 - Epoch: [0][50]	Time 0.632 (0.902)	Data 0.001 (0.037)	Loss 3.9797 (4.1128)	Lr: 0.0310
INFO - 09/02/20 14:58:39 - 0:01:22 - ============ Starting epoch 1 ... ============
INFO - 09/02/20 14:58:42 - 0:01:25 - Epoch: [1][0]	Time 2.386 (2.386)	Data 1.695 (1.695)	Loss 3.9151 (3.9151)	Lr: 0.0601
INFO - 09/02/20 14:59:13 - 0:01:56 - Epoch: [1][50]	Time 0.630 (0.668)	Data 0.000 (0.033)	Loss 3.9123 (3.9130)	Lr: 0.0910
INFO - 09/02/20 14:59:43 - 0:02:26 - ============ Starting epoch 2 ... ============
INFO - 09/02/20 14:59:45 - 0:02:28 - Epoch: [2][0]	Time 2.347 (2.347)	Data 1.655 (1.655)	Loss 3.9121 (3.9121)	Lr: 0.1201
INFO - 09/02/20 15:00:17 - 0:03:00 - Epoch: [2][50]	Time 0.628 (0.671)	Data 0.000 (0.033)	Loss 3.9121 (3.9121)	Lr: 0.1511
INFO - 09/02/20 15:00:47 - 0:03:30 - ============ Starting epoch 3 ... ============
INFO - 09/02/20 15:00:49 - 0:03:32 - Epoch: [3][0]	Time 2.165 (2.165)	Data 1.497 (1.497)	Loss 3.9121 (3.9121)	Lr: 0.1802
INFO - 09/02/20 15:01:21 - 0:04:03 - Epoch: [3][50]	Time 0.629 (0.664)	Data 0.000 (0.030)	Loss 3.9121 (3.9121)	Lr: 0.2111
INFO - 09/02/20 15:01:50 - 0:04:33 - ============ Starting epoch 4 ... ============
INFO - 09/02/20 15:01:52 - 0:04:35 - Epoch: [4][0]	Time 2.271 (2.271)	Data 1.593 (1.593)	Loss 3.9121 (3.9121)	Lr: 0.2402
INFO - 09/02/20 15:02:24 - 0:05:07 - Epoch: [4][50]	Time 0.631 (0.666)	Data 0.000 (0.032)	Loss 3.9122 (3.9121)	Lr: 0.2712
INFO - 09/02/20 15:02:53 - 0:05:36 - ============ Starting epoch 5 ... ============
INFO - 09/02/20 15:02:56 - 0:05:39 - Epoch: [5][0]	Time 2.579 (2.579)	Data 1.883 (1.883)	Loss 3.9121 (3.9121)	Lr: 0.3003
INFO - 09/02/20 15:03:28 - 0:06:11 - Epoch: [5][50]	Time 0.629 (0.674)	Data 0.000 (0.037)	Loss 3.9122 (3.9122)	Lr: 0.3313
INFO - 09/02/20 15:03:57 - 0:06:40 - ============ Starting epoch 6 ... ============
INFO - 09/02/20 15:04:00 - 0:06:43 - Epoch: [6][0]	Time 2.306 (2.306)	Data 1.644 (1.644)	Loss 3.9121 (3.9121)	Lr: 0.3604
INFO - 09/02/20 15:04:31 - 0:07:14 - Epoch: [6][50]	Time 0.627 (0.666)	Data 0.000 (0.032)	Loss 3.9122 (3.9121)	Lr: 0.3913
INFO - 09/02/20 15:05:01 - 0:07:44 - ============ Starting epoch 7 ... ============
INFO - 09/02/20 15:05:03 - 0:07:46 - Epoch: [7][0]	Time 2.579 (2.579)	Data 1.887 (1.887)	Loss 3.9126 (3.9126)	Lr: 0.4204
INFO - 09/02/20 15:05:35 - 0:08:18 - Epoch: [7][50]	Time 0.660 (0.672)	Data 0.000 (0.037)	Loss 3.9125 (3.9129)	Lr: 0.4514
INFO - 09/02/20 15:06:05 - 0:08:48 - ============ Starting epoch 8 ... ============
INFO - 09/02/20 15:06:07 - 0:08:50 - Epoch: [8][0]	Time 2.262 (2.262)	Data 1.614 (1.614)	Loss 3.9129 (3.9129)	Lr: 0.4805
INFO - 09/02/20 15:06:38 - 0:09:21 - Epoch: [8][50]	Time 0.629 (0.662)	Data 0.000 (0.032)	Loss 3.9121 (3.9123)	Lr: 0.5115
INFO - 09/02/20 15:07:08 - 0:09:51 - ============ Starting epoch 9 ... ============
INFO - 09/02/20 15:07:10 - 0:09:53 - Epoch: [9][0]	Time 2.414 (2.414)	Data 1.756 (1.756)	Loss 3.9121 (3.9121)	Lr: 0.5406
INFO - 09/02/20 15:07:42 - 0:10:25 - Epoch: [9][50]	Time 0.627 (0.668)	Data 0.000 (0.035)	Loss 3.9121 (3.9121)	Lr: 0.5715
INFO - 09/02/20 15:08:11 - 0:10:54 - ============ Starting epoch 10 ... ============
INFO - 09/02/20 15:08:14 - 0:10:57 - Epoch: [10][0]	Time 2.329 (2.329)	Data 1.662 (1.662)	Loss 3.9121 (3.9121)	Lr: 0.6000
INFO - 09/02/20 15:08:45 - 0:11:28 - Epoch: [10][50]	Time 0.633 (0.666)	Data 0.000 (0.033)	Loss 3.9121 (3.9121)	Lr: 0.6000
INFO - 09/02/20 15:09:15 - 0:11:58 - ============ Starting epoch 11 ... ============
INFO - 09/02/20 15:09:17 - 0:12:00 - Epoch: [11][0]	Time 2.320 (2.320)	Data 1.637 (1.637)	Loss 3.9121 (3.9121)	Lr: 0.6000
INFO - 09/02/20 15:09:49 - 0:12:32 - Epoch: [11][50]	Time 0.629 (0.667)	Data 0.000 (0.032)	Loss 3.9121 (3.9121)	Lr: 0.6000
INFO - 09/02/20 15:10:19 - 0:13:01 - ============ Starting epoch 12 ... ============
INFO - 09/02/20 15:10:21 - 0:13:04 - Epoch: [12][0]	Time 2.602 (2.602)	Data 1.938 (1.938)	Loss 3.9121 (3.9121)	Lr: 0.6000
INFO - 09/02/20 15:10:53 - 0:13:36 - Epoch: [12][50]	Time 0.644 (0.677)	Data 0.000 (0.038)	Loss 3.9121 (3.9121)	Lr: 0.5999
INFO - 09/02/20 15:11:23 - 0:14:06 - ============ Starting epoch 13 ... ============
INFO - 09/02/20 15:11:25 - 0:14:08 - Epoch: [13][0]	Time 2.422 (2.422)	Data 1.728 (1.728)	Loss 3.9121 (3.9121)	Lr: 0.5999
INFO - 09/02/20 15:11:57 - 0:14:40 - Epoch: [13][50]	Time 0.658 (0.671)	Data 0.000 (0.034)	Loss 3.9121 (3.9121)	Lr: 0.5999
INFO - 09/02/20 15:12:27 - 0:15:10 - ============ Starting epoch 14 ... ============
INFO - 09/02/20 15:12:30 - 0:15:13 - Epoch: [14][0]	Time 2.738 (2.738)	Data 2.026 (2.026)	Loss 3.9121 (3.9121)	Lr: 0.5998
INFO - 09/02/20 15:13:02 - 0:15:45 - Epoch: [14][50]	Time 0.629 (0.683)	Data 0.000 (0.040)	Loss 3.9121 (3.9121)	Lr: 0.5998
INFO - 09/02/20 15:13:32 - 0:16:14 - ============ Starting epoch 15 ... ============
INFO - 09/02/20 15:13:34 - 0:16:17 - Epoch: [15][0]	Time 2.544 (2.544)	Data 1.890 (1.890)	Loss 3.9121 (3.9121)	Lr: 0.5998
INFO - 09/02/20 15:14:06 - 0:16:49 - Epoch: [15][50]	Time 0.628 (0.670)	Data 0.000 (0.037)	Loss 3.9121 (3.9121)	Lr: 0.5997
INFO - 09/02/20 15:14:35 - 0:17:18 - ============ Starting epoch 16 ... ============
INFO - 09/02/20 15:14:37 - 0:17:20 - Epoch: [16][0]	Time 2.249 (2.249)	Data 1.574 (1.574)	Loss 3.9121 (3.9121)	Lr: 0.5997
INFO - 09/02/20 15:15:09 - 0:17:52 - Epoch: [16][50]	Time 0.627 (0.664)	Data 0.000 (0.031)	Loss 3.9121 (3.9121)	Lr: 0.5996
INFO - 09/02/20 15:15:39 - 0:18:21 - ============ Starting epoch 17 ... ============
INFO - 09/02/20 15:15:41 - 0:18:24 - Epoch: [17][0]	Time 2.562 (2.562)	Data 1.864 (1.864)	Loss 3.9121 (3.9121)	Lr: 0.5995
INFO - 09/02/20 15:16:13 - 0:18:56 - Epoch: [17][50]	Time 0.625 (0.670)	Data 0.000 (0.037)	Loss 3.9121 (3.9121)	Lr: 0.5995
INFO - 09/02/20 15:16:42 - 0:19:25 - ============ Starting epoch 18 ... ============
INFO - 09/02/20 15:16:45 - 0:19:28 - Epoch: [18][0]	Time 2.514 (2.514)	Data 1.849 (1.849)	Loss 3.9121 (3.9121)	Lr: 0.5994
INFO - 09/02/20 15:17:16 - 0:19:59 - Epoch: [18][50]	Time 0.653 (0.670)	Data 0.000 (0.037)	Loss 3.9121 (3.9121)	Lr: 0.5993
INFO - 09/02/20 15:17:46 - 0:20:29 - ============ Starting epoch 19 ... ============
INFO - 09/02/20 15:17:48 - 0:20:31 - Epoch: [19][0]	Time 2.262 (2.262)	Data 1.593 (1.593)	Loss 3.9121 (3.9121)	Lr: 0.5992
INFO - 09/02/20 15:18:20 - 0:21:03 - Epoch: [19][50]	Time 0.627 (0.664)	Data 0.000 (0.031)	Loss 3.9121 (3.9121)	Lr: 0.5991
INFO - 09/02/20 15:18:49 - 0:21:32 - ============ Starting epoch 20 ... ============
INFO - 09/02/20 15:18:51 - 0:21:34 - Epoch: [20][0]	Time 2.175 (2.175)	Data 1.514 (1.514)	Loss 3.9121 (3.9121)	Lr: 0.5990
INFO - 09/02/20 15:19:23 - 0:22:06 - Epoch: [20][50]	Time 0.625 (0.664)	Data 0.000 (0.030)	Loss 3.9120 (3.9121)	Lr: 0.5989
INFO - 09/02/20 15:19:53 - 0:22:36 - ============ Starting epoch 21 ... ============
INFO - 09/02/20 15:19:55 - 0:22:38 - Epoch: [21][0]	Time 2.375 (2.375)	Data 1.699 (1.699)	Loss 3.9121 (3.9121)	Lr: 0.5988
INFO - 09/02/20 15:20:27 - 0:23:09 - Epoch: [21][50]	Time 0.627 (0.666)	Data 0.000 (0.034)	Loss 3.9120 (3.9121)	Lr: 0.5987
INFO - 09/02/20 15:20:56 - 0:23:39 - ============ Starting epoch 22 ... ============
INFO - 09/02/20 15:20:59 - 0:23:42 - Epoch: [22][0]	Time 2.562 (2.562)	Data 1.874 (1.874)	Loss 3.9121 (3.9121)	Lr: 0.5986
INFO - 09/02/20 15:21:30 - 0:24:13 - Epoch: [22][50]	Time 0.630 (0.672)	Data 0.000 (0.037)	Loss 3.9120 (3.9121)	Lr: 0.5985
INFO - 09/02/20 15:22:00 - 0:24:43 - ============ Starting epoch 23 ... ============
INFO - 09/02/20 15:22:02 - 0:24:45 - Epoch: [23][0]	Time 2.546 (2.546)	Data 1.843 (1.843)	Loss 3.9143 (3.9143)	Lr: 0.5984
INFO - 09/02/20 15:22:34 - 0:25:17 - Epoch: [23][50]	Time 0.630 (0.671)	Data 0.000 (0.036)	Loss 3.9121 (3.9123)	Lr: 0.5982
INFO - 09/02/20 15:23:04 - 0:25:47 - ============ Starting epoch 24 ... ============
INFO - 09/02/20 15:23:06 - 0:25:49 - Epoch: [24][0]	Time 2.262 (2.262)	Data 1.581 (1.581)	Loss 3.9120 (3.9120)	Lr: 0.5981
INFO - 09/02/20 15:23:38 - 0:26:21 - Epoch: [24][50]	Time 0.668 (0.674)	Data 0.000 (0.031)	Loss 3.9120 (3.9121)	Lr: 0.5980
INFO - 09/02/20 15:24:08 - 0:26:51 - ============ Starting epoch 25 ... ============
INFO - 09/02/20 15:24:10 - 0:26:53 - Epoch: [25][0]	Time 2.439 (2.439)	Data 1.769 (1.769)	Loss 3.9121 (3.9121)	Lr: 0.5978
INFO - 09/02/20 15:24:42 - 0:27:25 - Epoch: [25][50]	Time 0.644 (0.675)	Data 0.000 (0.035)	Loss 3.9121 (3.9121)	Lr: 0.5977
INFO - 09/02/20 15:25:12 - 0:27:55 - ============ Starting epoch 26 ... ============
INFO - 09/02/20 15:25:15 - 0:27:58 - Epoch: [26][0]	Time 2.630 (2.630)	Data 1.931 (1.931)	Loss 3.9121 (3.9121)	Lr: 0.5975
INFO - 09/02/20 15:25:46 - 0:28:29 - Epoch: [26][50]	Time 0.628 (0.673)	Data 0.000 (0.038)	Loss 3.9121 (3.9121)	Lr: 0.5974
INFO - 09/02/20 15:26:16 - 0:28:59 - ============ Starting epoch 27 ... ============
INFO - 09/02/20 15:26:18 - 0:29:01 - Epoch: [27][0]	Time 2.376 (2.376)	Data 1.694 (1.694)	Loss 3.9121 (3.9121)	Lr: 0.5972
INFO - 09/02/20 15:26:50 - 0:29:33 - Epoch: [27][50]	Time 0.628 (0.665)	Data 0.000 (0.033)	Loss 3.9121 (3.9121)	Lr: 0.5970
INFO - 09/02/20 15:27:19 - 0:30:02 - ============ Starting epoch 28 ... ============
INFO - 09/02/20 15:27:22 - 0:30:05 - Epoch: [28][0]	Time 2.470 (2.470)	Data 1.826 (1.826)	Loss 3.9120 (3.9120)	Lr: 0.5969
INFO - 09/02/20 15:27:53 - 0:30:36 - Epoch: [28][50]	Time 0.631 (0.670)	Data 0.000 (0.036)	Loss 3.9120 (3.9121)	Lr: 0.5967
INFO - 09/02/20 15:28:23 - 0:31:06 - ============ Starting epoch 29 ... ============
INFO - 09/02/20 15:28:25 - 0:31:08 - Epoch: [29][0]	Time 2.557 (2.557)	Data 1.879 (1.879)	Loss 3.9121 (3.9121)	Lr: 0.5965
INFO - 09/02/20 15:28:57 - 0:31:40 - Epoch: [29][50]	Time 0.643 (0.672)	Data 0.000 (0.037)	Loss 3.9121 (3.9120)	Lr: 0.5963
INFO - 09/02/20 15:29:27 - 0:32:10 - ============ Starting epoch 30 ... ============
INFO - 09/02/20 15:29:29 - 0:32:12 - Epoch: [30][0]	Time 2.366 (2.366)	Data 1.663 (1.663)	Loss 3.9120 (3.9120)	Lr: 0.5961
INFO - 09/02/20 15:30:01 - 0:32:44 - Epoch: [30][50]	Time 0.645 (0.668)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5959
INFO - 09/02/20 15:30:30 - 0:33:13 - ============ Starting epoch 31 ... ============
INFO - 09/02/20 15:30:33 - 0:33:15 - Epoch: [31][0]	Time 2.296 (2.296)	Data 1.616 (1.616)	Loss 3.9121 (3.9121)	Lr: 0.5957
INFO - 09/02/20 15:31:04 - 0:33:47 - Epoch: [31][50]	Time 0.628 (0.666)	Data 0.000 (0.032)	Loss 3.9121 (3.9121)	Lr: 0.5955
INFO - 09/02/20 15:31:34 - 0:34:17 - ============ Starting epoch 32 ... ============
INFO - 09/02/20 15:31:36 - 0:34:19 - Epoch: [32][0]	Time 2.244 (2.244)	Data 1.573 (1.573)	Loss 3.9120 (3.9120)	Lr: 0.5953
INFO - 09/02/20 15:32:08 - 0:34:51 - Epoch: [32][50]	Time 0.641 (0.664)	Data 0.000 (0.031)	Loss 3.9121 (3.9120)	Lr: 0.5951
INFO - 09/02/20 15:32:37 - 0:35:20 - ============ Starting epoch 33 ... ============
INFO - 09/02/20 15:32:39 - 0:35:22 - Epoch: [33][0]	Time 2.211 (2.211)	Data 1.555 (1.555)	Loss 3.9120 (3.9120)	Lr: 0.5949
INFO - 09/02/20 15:33:11 - 0:35:54 - Epoch: [33][50]	Time 0.628 (0.665)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.5946
INFO - 09/02/20 15:33:41 - 0:36:24 - ============ Starting epoch 34 ... ============
INFO - 09/02/20 15:33:43 - 0:36:26 - Epoch: [34][0]	Time 2.659 (2.659)	Data 1.981 (1.981)	Loss 3.9120 (3.9120)	Lr: 0.5944
INFO - 09/02/20 15:34:16 - 0:36:59 - Epoch: [34][50]	Time 0.665 (0.690)	Data 0.000 (0.039)	Loss 3.9120 (3.9120)	Lr: 0.5942
INFO - 09/02/20 15:34:45 - 0:37:28 - ============ Starting epoch 35 ... ============
INFO - 09/02/20 15:34:48 - 0:37:31 - Epoch: [35][0]	Time 2.398 (2.398)	Data 1.758 (1.758)	Loss 3.9120 (3.9120)	Lr: 0.5939
INFO - 09/02/20 15:35:19 - 0:38:02 - Epoch: [35][50]	Time 0.627 (0.667)	Data 0.000 (0.035)	Loss 3.9120 (3.9120)	Lr: 0.5937
INFO - 09/02/20 15:35:49 - 0:38:32 - ============ Starting epoch 36 ... ============
INFO - 09/02/20 15:35:51 - 0:38:34 - Epoch: [36][0]	Time 2.488 (2.488)	Data 1.849 (1.849)	Loss 3.9120 (3.9120)	Lr: 0.5935
INFO - 09/02/20 15:36:23 - 0:39:06 - Epoch: [36][50]	Time 0.628 (0.668)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.5932
INFO - 09/02/20 15:36:53 - 0:39:35 - ============ Starting epoch 37 ... ============
INFO - 09/02/20 15:36:55 - 0:39:38 - Epoch: [37][0]	Time 2.350 (2.350)	Data 1.661 (1.661)	Loss 3.9120 (3.9120)	Lr: 0.5929
INFO - 09/02/20 15:37:27 - 0:40:10 - Epoch: [37][50]	Time 0.627 (0.672)	Data 0.000 (0.033)	Loss 3.9121 (3.9120)	Lr: 0.5927
INFO - 09/02/20 15:37:57 - 0:40:39 - ============ Starting epoch 38 ... ============
INFO - 09/02/20 15:37:59 - 0:40:42 - Epoch: [38][0]	Time 2.597 (2.597)	Data 1.914 (1.914)	Loss 3.9120 (3.9120)	Lr: 0.5924
INFO - 09/02/20 15:38:31 - 0:41:14 - Epoch: [38][50]	Time 0.624 (0.669)	Data 0.000 (0.038)	Loss 3.9121 (3.9121)	Lr: 0.5921
INFO - 09/02/20 15:39:00 - 0:41:43 - ============ Starting epoch 39 ... ============
INFO - 09/02/20 15:39:02 - 0:41:45 - Epoch: [39][0]	Time 2.301 (2.301)	Data 1.613 (1.613)	Loss 3.9121 (3.9121)	Lr: 0.5919
INFO - 09/02/20 15:39:34 - 0:42:17 - Epoch: [39][50]	Time 0.628 (0.663)	Data 0.000 (0.032)	Loss 3.9121 (3.9120)	Lr: 0.5916
INFO - 09/02/20 15:40:03 - 0:42:46 - ============ Starting epoch 40 ... ============
INFO - 09/02/20 15:40:05 - 0:42:48 - Epoch: [40][0]	Time 2.303 (2.303)	Data 1.608 (1.608)	Loss 3.9120 (3.9120)	Lr: 0.5913
INFO - 09/02/20 15:40:37 - 0:43:20 - Epoch: [40][50]	Time 0.625 (0.661)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.5910
INFO - 09/02/20 15:41:06 - 0:43:49 - ============ Starting epoch 41 ... ============
INFO - 09/02/20 15:41:08 - 0:43:51 - Epoch: [41][0]	Time 2.172 (2.172)	Data 1.529 (1.529)	Loss 3.9120 (3.9120)	Lr: 0.5907
INFO - 09/02/20 15:41:40 - 0:44:23 - Epoch: [41][50]	Time 0.626 (0.661)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.5904
INFO - 09/02/20 15:42:09 - 0:44:52 - ============ Starting epoch 42 ... ============
INFO - 09/02/20 15:42:11 - 0:44:54 - Epoch: [42][0]	Time 2.246 (2.246)	Data 1.605 (1.605)	Loss 3.9120 (3.9120)	Lr: 0.5901
INFO - 09/02/20 15:42:43 - 0:45:26 - Epoch: [42][50]	Time 0.625 (0.659)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.5898
INFO - 09/02/20 15:43:12 - 0:45:55 - ============ Starting epoch 43 ... ============
INFO - 09/02/20 15:43:15 - 0:45:57 - Epoch: [43][0]	Time 2.518 (2.518)	Data 1.869 (1.869)	Loss 3.9120 (3.9120)	Lr: 0.5895
INFO - 09/02/20 15:43:46 - 0:46:29 - Epoch: [43][50]	Time 0.675 (0.664)	Data 0.001 (0.037)	Loss 3.9121 (3.9120)	Lr: 0.5891
INFO - 09/02/20 15:44:15 - 0:46:58 - ============ Starting epoch 44 ... ============
INFO - 09/02/20 15:44:17 - 0:47:00 - Epoch: [44][0]	Time 2.329 (2.329)	Data 1.637 (1.637)	Loss 3.9120 (3.9120)	Lr: 0.5888
INFO - 09/02/20 15:44:49 - 0:47:32 - Epoch: [44][50]	Time 0.620 (0.658)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5885
INFO - 09/02/20 15:45:18 - 0:48:01 - ============ Starting epoch 45 ... ============
INFO - 09/02/20 15:45:20 - 0:48:03 - Epoch: [45][0]	Time 2.289 (2.289)	Data 1.657 (1.657)	Loss 3.9120 (3.9120)	Lr: 0.5882
INFO - 09/02/20 15:45:51 - 0:48:34 - Epoch: [45][50]	Time 0.623 (0.658)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5878
INFO - 09/02/20 15:46:20 - 0:49:03 - ============ Starting epoch 46 ... ============
INFO - 09/02/20 15:46:22 - 0:49:05 - Epoch: [46][0]	Time 2.301 (2.301)	Data 1.620 (1.620)	Loss 3.9120 (3.9120)	Lr: 0.5875
INFO - 09/02/20 15:46:54 - 0:49:37 - Epoch: [46][50]	Time 0.621 (0.657)	Data 0.001 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.5871
INFO - 09/02/20 15:47:23 - 0:50:06 - ============ Starting epoch 47 ... ============
INFO - 09/02/20 15:47:25 - 0:50:08 - Epoch: [47][0]	Time 2.431 (2.431)	Data 1.749 (1.749)	Loss 3.9120 (3.9120)	Lr: 0.5868
INFO - 09/02/20 15:47:56 - 0:50:39 - Epoch: [47][50]	Time 0.615 (0.657)	Data 0.001 (0.035)	Loss 3.9120 (3.9120)	Lr: 0.5864
INFO - 09/02/20 15:48:25 - 0:51:08 - ============ Starting epoch 48 ... ============
INFO - 09/02/20 15:48:28 - 0:51:10 - Epoch: [48][0]	Time 2.340 (2.340)	Data 1.666 (1.666)	Loss 3.9120 (3.9120)	Lr: 0.5861
INFO - 09/02/20 15:48:59 - 0:51:42 - Epoch: [48][50]	Time 0.615 (0.658)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5857
INFO - 09/02/20 15:49:28 - 0:52:11 - ============ Starting epoch 49 ... ============
INFO - 09/02/20 15:49:30 - 0:52:13 - Epoch: [49][0]	Time 2.289 (2.289)	Data 1.652 (1.652)	Loss 3.9120 (3.9120)	Lr: 0.5853
INFO - 09/02/20 15:50:02 - 0:52:44 - Epoch: [49][50]	Time 0.616 (0.664)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5849
INFO - 09/02/20 15:50:31 - 0:53:14 - ============ Starting epoch 50 ... ============
INFO - 09/02/20 15:50:33 - 0:53:16 - Epoch: [50][0]	Time 2.610 (2.610)	Data 1.947 (1.947)	Loss 3.9120 (3.9120)	Lr: 0.5846
INFO - 09/02/20 15:51:05 - 0:53:48 - Epoch: [50][50]	Time 0.619 (0.664)	Data 0.001 (0.039)	Loss 3.9120 (3.9120)	Lr: 0.5842
INFO - 09/02/20 15:51:34 - 0:54:17 - ============ Starting epoch 51 ... ============
INFO - 09/02/20 15:51:36 - 0:54:19 - Epoch: [51][0]	Time 2.533 (2.533)	Data 1.900 (1.900)	Loss 3.9120 (3.9120)	Lr: 0.5838
INFO - 09/02/20 15:52:07 - 0:54:50 - Epoch: [51][50]	Time 0.627 (0.657)	Data 0.001 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.5834
INFO - 09/02/20 15:52:36 - 0:55:19 - ============ Starting epoch 52 ... ============
INFO - 09/02/20 15:52:39 - 0:55:21 - Epoch: [52][0]	Time 2.293 (2.293)	Data 1.658 (1.658)	Loss 3.9120 (3.9120)	Lr: 0.5830
INFO - 09/02/20 15:53:10 - 0:55:53 - Epoch: [52][50]	Time 0.616 (0.653)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5826
INFO - 09/02/20 15:53:38 - 0:56:21 - ============ Starting epoch 53 ... ============
INFO - 09/02/20 15:53:41 - 0:56:24 - Epoch: [53][0]	Time 2.551 (2.551)	Data 1.918 (1.918)	Loss 3.9120 (3.9120)	Lr: 0.5822
INFO - 09/02/20 15:54:12 - 0:56:55 - Epoch: [53][50]	Time 0.618 (0.657)	Data 0.001 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.5818
INFO - 09/02/20 15:54:41 - 0:57:24 - ============ Starting epoch 54 ... ============
INFO - 09/02/20 15:54:43 - 0:57:26 - Epoch: [54][0]	Time 2.573 (2.573)	Data 1.890 (1.890)	Loss 3.9120 (3.9120)	Lr: 0.5814
INFO - 09/02/20 15:55:14 - 0:57:57 - Epoch: [54][50]	Time 0.616 (0.658)	Data 0.000 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.5809
INFO - 09/02/20 15:55:43 - 0:58:26 - ============ Starting epoch 55 ... ============
INFO - 09/02/20 15:55:46 - 0:58:29 - Epoch: [55][0]	Time 2.646 (2.646)	Data 1.976 (1.976)	Loss 3.9120 (3.9120)	Lr: 0.5805
INFO - 09/02/20 15:56:17 - 0:59:00 - Epoch: [55][50]	Time 0.638 (0.670)	Data 0.001 (0.039)	Loss 3.9121 (3.9120)	Lr: 0.5801
INFO - 09/02/20 15:56:46 - 0:59:29 - ============ Starting epoch 56 ... ============
INFO - 09/02/20 15:56:49 - 0:59:32 - Epoch: [56][0]	Time 2.488 (2.488)	Data 1.832 (1.832)	Loss 3.9120 (3.9120)	Lr: 0.5797
INFO - 09/02/20 15:57:20 - 1:00:03 - Epoch: [56][50]	Time 0.614 (0.653)	Data 0.001 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.5792
INFO - 09/02/20 15:57:48 - 1:00:31 - ============ Starting epoch 57 ... ============
INFO - 09/02/20 15:57:51 - 1:00:33 - Epoch: [57][0]	Time 2.183 (2.183)	Data 1.526 (1.526)	Loss 3.9120 (3.9120)	Lr: 0.5788
INFO - 09/02/20 15:58:21 - 1:01:04 - Epoch: [57][50]	Time 0.612 (0.649)	Data 0.001 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.5783
INFO - 09/02/20 15:58:50 - 1:01:33 - ============ Starting epoch 58 ... ============
INFO - 09/02/20 15:58:53 - 1:01:35 - Epoch: [58][0]	Time 2.318 (2.318)	Data 1.647 (1.647)	Loss 3.9120 (3.9120)	Lr: 0.5779
INFO - 09/02/20 15:59:23 - 1:02:06 - Epoch: [58][50]	Time 0.611 (0.649)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5774
INFO - 09/02/20 15:59:52 - 1:02:35 - ============ Starting epoch 59 ... ============
INFO - 09/02/20 15:59:54 - 1:02:37 - Epoch: [59][0]	Time 2.305 (2.305)	Data 1.674 (1.674)	Loss 3.9120 (3.9120)	Lr: 0.5770
INFO - 09/02/20 16:00:25 - 1:03:08 - Epoch: [59][50]	Time 0.640 (0.648)	Data 0.001 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.5765
INFO - 09/02/20 16:00:54 - 1:03:37 - ============ Starting epoch 60 ... ============
INFO - 09/02/20 16:00:56 - 1:03:39 - Epoch: [60][0]	Time 2.534 (2.534)	Data 1.900 (1.900)	Loss 3.9120 (3.9120)	Lr: 0.5760
INFO - 09/02/20 16:01:27 - 1:04:10 - Epoch: [60][50]	Time 0.614 (0.654)	Data 0.001 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.5755
INFO - 09/02/20 16:01:56 - 1:04:39 - ============ Starting epoch 61 ... ============
INFO - 09/02/20 16:01:58 - 1:04:41 - Epoch: [61][0]	Time 2.243 (2.243)	Data 1.610 (1.610)	Loss 3.9120 (3.9120)	Lr: 0.5751
INFO - 09/02/20 16:02:29 - 1:05:12 - Epoch: [61][50]	Time 0.620 (0.648)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.5746
INFO - 09/02/20 16:02:38 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 16:02:38 - 0:00:00 - arch: resnet50
                                     base_lr: 0.06
                                     batch_size: 512
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 16:02:38 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 16:02:38 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 16:02:44 - 0:00:06 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 16:02:44 - 0:00:06 - Building model done.
INFO - 09/02/20 16:02:44 - 0:00:06 - Building optimizer done.
INFO - 09/02/20 16:02:44 - 0:00:06 - Initializing mixed precision done.
INFO - 09/02/20 16:02:44 - 0:00:06 - Found checkpoint at ./checkpoint.pth.tar
INFO - 09/02/20 16:03:06 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 16:03:06 - 0:00:00 - arch: resnet50
                                     base_lr: 0.06
                                     batch_size: 512
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 50
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 16:03:06 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 16:03:07 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 16:03:12 - 0:00:06 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=50, bias=False)
                                     )
INFO - 09/02/20 16:03:12 - 0:00:06 - Building model done.
INFO - 09/02/20 16:03:13 - 0:00:06 - Building optimizer done.
INFO - 09/02/20 16:03:13 - 0:00:06 - Initializing mixed precision done.
INFO - 09/02/20 16:03:13 - 0:00:06 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 16:03:27 - 0:00:20 - Epoch: [0][0]	Time 13.954 (13.954)	Data 1.751 (1.751)	Loss 4.2315 (4.2315)	Lr: 0.0000
INFO - 09/02/20 16:03:58 - 0:00:52 - Epoch: [0][50]	Time 0.629 (0.893)	Data 0.000 (0.035)	Loss 4.1437 (4.2091)	Lr: 0.0031
INFO - 09/02/20 16:04:28 - 0:01:22 - ============ Starting epoch 1 ... ============
INFO - 09/02/20 16:04:30 - 0:01:24 - Epoch: [1][0]	Time 2.523 (2.523)	Data 1.852 (1.852)	Loss 4.0515 (4.0515)	Lr: 0.0060
INFO - 09/02/20 16:05:02 - 0:01:56 - Epoch: [1][50]	Time 0.624 (0.668)	Data 0.000 (0.037)	Loss 3.9741 (4.0044)	Lr: 0.0091
INFO - 09/02/20 16:05:31 - 0:02:25 - ============ Starting epoch 2 ... ============
INFO - 09/02/20 16:05:34 - 0:02:27 - Epoch: [2][0]	Time 2.247 (2.247)	Data 1.605 (1.605)	Loss 3.9368 (3.9368)	Lr: 0.0120
INFO - 09/02/20 16:06:05 - 0:02:59 - Epoch: [2][50]	Time 0.627 (0.660)	Data 0.000 (0.032)	Loss 3.9202 (3.9262)	Lr: 0.0151
INFO - 09/02/20 16:06:34 - 0:03:28 - ============ Starting epoch 3 ... ============
INFO - 09/02/20 16:06:37 - 0:03:30 - Epoch: [3][0]	Time 2.378 (2.378)	Data 1.686 (1.686)	Loss 3.9146 (3.9146)	Lr: 0.0180
INFO - 09/02/20 16:07:08 - 0:04:02 - Epoch: [3][50]	Time 0.632 (0.662)	Data 0.000 (0.033)	Loss 3.9130 (3.9136)	Lr: 0.0211
INFO - 09/02/20 16:07:37 - 0:04:31 - ============ Starting epoch 4 ... ============
INFO - 09/02/20 16:07:40 - 0:04:34 - Epoch: [4][0]	Time 2.557 (2.557)	Data 1.893 (1.893)	Loss 3.9125 (3.9125)	Lr: 0.0240
INFO - 09/02/20 16:08:11 - 0:05:05 - Epoch: [4][50]	Time 0.623 (0.668)	Data 0.000 (0.037)	Loss 3.9123 (3.9124)	Lr: 0.0271
INFO - 09/02/20 16:08:41 - 0:05:34 - ============ Starting epoch 5 ... ============
INFO - 09/02/20 16:08:43 - 0:05:37 - Epoch: [5][0]	Time 2.436 (2.436)	Data 1.797 (1.797)	Loss 3.9122 (3.9122)	Lr: 0.0300
INFO - 09/02/20 16:09:15 - 0:06:08 - Epoch: [5][50]	Time 0.653 (0.665)	Data 0.000 (0.035)	Loss 3.9121 (3.9122)	Lr: 0.0331
INFO - 09/02/20 16:09:44 - 0:06:38 - ============ Starting epoch 6 ... ============
INFO - 09/02/20 16:09:46 - 0:06:40 - Epoch: [6][0]	Time 2.259 (2.259)	Data 1.613 (1.613)	Loss 3.9121 (3.9121)	Lr: 0.0360
INFO - 09/02/20 16:10:17 - 0:07:11 - Epoch: [6][50]	Time 0.624 (0.660)	Data 0.000 (0.032)	Loss 3.9121 (3.9121)	Lr: 0.0391
INFO - 09/02/20 16:10:47 - 0:07:40 - ============ Starting epoch 7 ... ============
INFO - 09/02/20 16:10:49 - 0:07:43 - Epoch: [7][0]	Time 2.281 (2.281)	Data 1.646 (1.646)	Loss 3.9121 (3.9121)	Lr: 0.0420
INFO - 09/02/20 16:11:21 - 0:08:14 - Epoch: [7][50]	Time 0.646 (0.663)	Data 0.000 (0.033)	Loss 3.9121 (3.9121)	Lr: 0.0451
INFO - 09/02/20 16:11:50 - 0:08:43 - ============ Starting epoch 8 ... ============
INFO - 09/02/20 16:11:52 - 0:08:46 - Epoch: [8][0]	Time 2.470 (2.470)	Data 1.816 (1.816)	Loss 3.9120 (3.9120)	Lr: 0.0480
INFO - 09/02/20 16:12:23 - 0:09:17 - Epoch: [8][50]	Time 0.622 (0.663)	Data 0.000 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.0511
INFO - 09/02/20 16:12:53 - 0:09:46 - ============ Starting epoch 9 ... ============
INFO - 09/02/20 16:12:55 - 0:09:49 - Epoch: [9][0]	Time 2.336 (2.336)	Data 1.636 (1.636)	Loss 3.9121 (3.9121)	Lr: 0.0541
INFO - 09/02/20 16:13:26 - 0:10:20 - Epoch: [9][50]	Time 0.620 (0.660)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0572
INFO - 09/02/20 16:13:55 - 0:10:49 - ============ Starting epoch 10 ... ============
INFO - 09/02/20 16:13:58 - 0:10:52 - Epoch: [10][0]	Time 2.310 (2.310)	Data 1.671 (1.671)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:14:29 - 0:11:23 - Epoch: [10][50]	Time 0.630 (0.659)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:14:58 - 0:11:52 - ============ Starting epoch 11 ... ============
INFO - 09/02/20 16:15:01 - 0:11:54 - Epoch: [11][0]	Time 2.251 (2.251)	Data 1.613 (1.613)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:15:32 - 0:12:26 - Epoch: [11][50]	Time 0.626 (0.656)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:16:01 - 0:12:55 - ============ Starting epoch 12 ... ============
INFO - 09/02/20 16:16:03 - 0:12:57 - Epoch: [12][0]	Time 2.208 (2.208)	Data 1.575 (1.575)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:16:34 - 0:13:28 - Epoch: [12][50]	Time 0.620 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:17:03 - 0:13:57 - ============ Starting epoch 13 ... ============
INFO - 09/02/20 16:17:06 - 0:14:00 - Epoch: [13][0]	Time 2.374 (2.374)	Data 1.713 (1.713)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:17:37 - 0:14:31 - Epoch: [13][50]	Time 0.624 (0.664)	Data 0.000 (0.034)	Loss 3.9121 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:18:06 - 0:15:00 - ============ Starting epoch 14 ... ============
INFO - 09/02/20 16:18:09 - 0:15:02 - Epoch: [14][0]	Time 2.235 (2.235)	Data 1.564 (1.564)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:18:40 - 0:15:33 - Epoch: [14][50]	Time 0.630 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:19:09 - 0:16:03 - ============ Starting epoch 15 ... ============
INFO - 09/02/20 16:19:11 - 0:16:05 - Epoch: [15][0]	Time 2.211 (2.211)	Data 1.548 (1.548)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:19:42 - 0:16:36 - Epoch: [15][50]	Time 0.623 (0.653)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:20:11 - 0:17:05 - ============ Starting epoch 16 ... ============
INFO - 09/02/20 16:20:13 - 0:17:07 - Epoch: [16][0]	Time 2.125 (2.125)	Data 1.491 (1.491)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:20:44 - 0:17:38 - Epoch: [16][50]	Time 0.619 (0.652)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:21:13 - 0:18:07 - ============ Starting epoch 17 ... ============
INFO - 09/02/20 16:21:16 - 0:18:09 - Epoch: [17][0]	Time 2.332 (2.332)	Data 1.688 (1.688)	Loss 3.9120 (3.9120)	Lr: 0.0600
INFO - 09/02/20 16:21:47 - 0:18:41 - Epoch: [17][50]	Time 0.620 (0.656)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:22:16 - 0:19:09 - ============ Starting epoch 18 ... ============
INFO - 09/02/20 16:22:18 - 0:19:12 - Epoch: [18][0]	Time 2.105 (2.105)	Data 1.467 (1.467)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:22:49 - 0:19:43 - Epoch: [18][50]	Time 0.622 (0.651)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:23:18 - 0:20:12 - ============ Starting epoch 19 ... ============
INFO - 09/02/20 16:23:20 - 0:20:14 - Epoch: [19][0]	Time 2.098 (2.098)	Data 1.467 (1.467)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:23:51 - 0:20:45 - Epoch: [19][50]	Time 0.622 (0.650)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:24:20 - 0:21:14 - ============ Starting epoch 20 ... ============
INFO - 09/02/20 16:24:22 - 0:21:16 - Epoch: [20][0]	Time 2.306 (2.306)	Data 1.642 (1.642)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:24:53 - 0:21:47 - Epoch: [20][50]	Time 0.619 (0.655)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:25:22 - 0:22:16 - ============ Starting epoch 21 ... ============
INFO - 09/02/20 16:25:25 - 0:22:18 - Epoch: [21][0]	Time 2.253 (2.253)	Data 1.616 (1.616)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:25:56 - 0:22:49 - Epoch: [21][50]	Time 0.620 (0.654)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:26:25 - 0:23:18 - ============ Starting epoch 22 ... ============
INFO - 09/02/20 16:26:27 - 0:23:21 - Epoch: [22][0]	Time 2.180 (2.180)	Data 1.547 (1.547)	Loss 3.9120 (3.9120)	Lr: 0.0599
INFO - 09/02/20 16:26:58 - 0:23:52 - Epoch: [22][50]	Time 0.624 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:27:27 - 0:24:21 - ============ Starting epoch 23 ... ============
INFO - 09/02/20 16:27:29 - 0:24:23 - Epoch: [23][0]	Time 2.234 (2.234)	Data 1.599 (1.599)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:28:00 - 0:24:54 - Epoch: [23][50]	Time 0.621 (0.655)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:28:29 - 0:25:23 - ============ Starting epoch 24 ... ============
INFO - 09/02/20 16:28:32 - 0:25:25 - Epoch: [24][0]	Time 2.192 (2.192)	Data 1.520 (1.520)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:29:03 - 0:25:56 - Epoch: [24][50]	Time 0.619 (0.653)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:29:32 - 0:26:25 - ============ Starting epoch 25 ... ============
INFO - 09/02/20 16:29:34 - 0:26:28 - Epoch: [25][0]	Time 2.086 (2.086)	Data 1.451 (1.451)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:30:05 - 0:26:59 - Epoch: [25][50]	Time 0.619 (0.650)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:30:34 - 0:27:28 - ============ Starting epoch 26 ... ============
INFO - 09/02/20 16:30:37 - 0:27:31 - Epoch: [26][0]	Time 2.625 (2.625)	Data 1.923 (1.923)	Loss 3.9120 (3.9120)	Lr: 0.0598
INFO - 09/02/20 16:31:08 - 0:28:02 - Epoch: [26][50]	Time 0.621 (0.663)	Data 0.000 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:31:37 - 0:28:31 - ============ Starting epoch 27 ... ============
INFO - 09/02/20 16:31:40 - 0:28:33 - Epoch: [27][0]	Time 2.241 (2.241)	Data 1.604 (1.604)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:32:11 - 0:29:04 - Epoch: [27][50]	Time 0.620 (0.654)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:32:40 - 0:29:33 - ============ Starting epoch 28 ... ============
INFO - 09/02/20 16:32:42 - 0:29:36 - Epoch: [28][0]	Time 2.527 (2.527)	Data 1.859 (1.859)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:33:13 - 0:30:07 - Epoch: [28][50]	Time 0.625 (0.660)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:33:42 - 0:30:36 - ============ Starting epoch 29 ... ============
INFO - 09/02/20 16:33:44 - 0:30:38 - Epoch: [29][0]	Time 2.169 (2.169)	Data 1.519 (1.519)	Loss 3.9120 (3.9120)	Lr: 0.0597
INFO - 09/02/20 16:34:16 - 0:31:09 - Epoch: [29][50]	Time 0.627 (0.654)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0596
INFO - 09/02/20 16:34:45 - 0:31:38 - ============ Starting epoch 30 ... ============
INFO - 09/02/20 16:34:47 - 0:31:40 - Epoch: [30][0]	Time 2.177 (2.177)	Data 1.536 (1.536)	Loss 3.9120 (3.9120)	Lr: 0.0596
INFO - 09/02/20 16:35:18 - 0:32:12 - Epoch: [30][50]	Time 0.620 (0.652)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0596
INFO - 09/02/20 16:35:47 - 0:32:41 - ============ Starting epoch 31 ... ============
INFO - 09/02/20 16:35:49 - 0:32:43 - Epoch: [31][0]	Time 2.404 (2.404)	Data 1.705 (1.705)	Loss 3.9120 (3.9120)	Lr: 0.0596
INFO - 09/02/20 16:36:21 - 0:33:14 - Epoch: [31][50]	Time 0.622 (0.660)	Data 0.000 (0.034)	Loss 3.9120 (3.9120)	Lr: 0.0596
INFO - 09/02/20 16:36:50 - 0:33:43 - ============ Starting epoch 32 ... ============
INFO - 09/02/20 16:36:52 - 0:33:46 - Epoch: [32][0]	Time 2.247 (2.247)	Data 1.615 (1.615)	Loss 3.9120 (3.9120)	Lr: 0.0595
INFO - 09/02/20 16:37:23 - 0:34:17 - Epoch: [32][50]	Time 0.620 (0.654)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0595
INFO - 09/02/20 16:37:52 - 0:34:46 - ============ Starting epoch 33 ... ============
INFO - 09/02/20 16:37:54 - 0:34:48 - Epoch: [33][0]	Time 2.172 (2.172)	Data 1.524 (1.524)	Loss 3.9120 (3.9120)	Lr: 0.0595
INFO - 09/02/20 16:38:25 - 0:35:19 - Epoch: [33][50]	Time 0.652 (0.655)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0595
INFO - 09/02/20 16:38:54 - 0:35:48 - ============ Starting epoch 34 ... ============
INFO - 09/02/20 16:38:57 - 0:35:50 - Epoch: [34][0]	Time 2.136 (2.136)	Data 1.498 (1.498)	Loss 3.9120 (3.9120)	Lr: 0.0594
INFO - 09/02/20 16:39:28 - 0:36:21 - Epoch: [34][50]	Time 0.626 (0.652)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0594
INFO - 09/02/20 16:39:57 - 0:36:50 - ============ Starting epoch 35 ... ============
INFO - 09/02/20 16:39:59 - 0:36:53 - Epoch: [35][0]	Time 2.254 (2.254)	Data 1.622 (1.622)	Loss 3.9120 (3.9120)	Lr: 0.0594
INFO - 09/02/20 16:40:30 - 0:37:24 - Epoch: [35][50]	Time 0.634 (0.654)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0594
INFO - 09/02/20 16:40:59 - 0:37:53 - ============ Starting epoch 36 ... ============
INFO - 09/02/20 16:41:01 - 0:37:55 - Epoch: [36][0]	Time 2.213 (2.213)	Data 1.572 (1.572)	Loss 3.9120 (3.9120)	Lr: 0.0594
INFO - 09/02/20 16:41:32 - 0:38:26 - Epoch: [36][50]	Time 0.669 (0.655)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0593
INFO - 09/02/20 16:42:01 - 0:38:55 - ============ Starting epoch 37 ... ============
INFO - 09/02/20 16:42:04 - 0:38:57 - Epoch: [37][0]	Time 2.264 (2.264)	Data 1.577 (1.577)	Loss 3.9120 (3.9120)	Lr: 0.0593
INFO - 09/02/20 16:42:35 - 0:39:29 - Epoch: [37][50]	Time 0.621 (0.657)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0593
INFO - 09/02/20 16:43:04 - 0:39:58 - ============ Starting epoch 38 ... ============
INFO - 09/02/20 16:43:06 - 0:40:00 - Epoch: [38][0]	Time 2.247 (2.247)	Data 1.580 (1.580)	Loss 3.9120 (3.9120)	Lr: 0.0592
INFO - 09/02/20 16:43:37 - 0:40:31 - Epoch: [38][50]	Time 0.631 (0.656)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0592
INFO - 09/02/20 16:44:06 - 0:41:00 - ============ Starting epoch 39 ... ============
INFO - 09/02/20 16:44:09 - 0:41:02 - Epoch: [39][0]	Time 2.271 (2.271)	Data 1.606 (1.606)	Loss 3.9120 (3.9120)	Lr: 0.0592
INFO - 09/02/20 16:44:40 - 0:41:34 - Epoch: [39][50]	Time 0.619 (0.656)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0592
INFO - 09/02/20 16:45:09 - 0:42:03 - ============ Starting epoch 40 ... ============
INFO - 09/02/20 16:45:11 - 0:42:05 - Epoch: [40][0]	Time 2.271 (2.271)	Data 1.636 (1.636)	Loss 3.9120 (3.9120)	Lr: 0.0591
INFO - 09/02/20 16:45:42 - 0:42:36 - Epoch: [40][50]	Time 0.620 (0.655)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0591
INFO - 09/02/20 16:46:11 - 0:43:05 - ============ Starting epoch 41 ... ============
INFO - 09/02/20 16:46:14 - 0:43:07 - Epoch: [41][0]	Time 2.380 (2.380)	Data 1.677 (1.677)	Loss 3.9120 (3.9120)	Lr: 0.0591
INFO - 09/02/20 16:46:45 - 0:43:39 - Epoch: [41][50]	Time 0.621 (0.659)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0590
INFO - 09/02/20 16:47:14 - 0:44:08 - ============ Starting epoch 42 ... ============
INFO - 09/02/20 16:47:16 - 0:44:10 - Epoch: [42][0]	Time 2.155 (2.155)	Data 1.518 (1.518)	Loss 3.9120 (3.9120)	Lr: 0.0590
INFO - 09/02/20 16:47:47 - 0:44:41 - Epoch: [42][50]	Time 0.622 (0.653)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0590
INFO - 09/02/20 16:48:16 - 0:45:10 - ============ Starting epoch 43 ... ============
INFO - 09/02/20 16:48:18 - 0:45:12 - Epoch: [43][0]	Time 2.263 (2.263)	Data 1.571 (1.571)	Loss 3.9120 (3.9120)	Lr: 0.0590
INFO - 09/02/20 16:48:50 - 0:45:43 - Epoch: [43][50]	Time 0.620 (0.655)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0589
INFO - 09/02/20 16:49:19 - 0:46:12 - ============ Starting epoch 44 ... ============
INFO - 09/02/20 16:49:21 - 0:46:15 - Epoch: [44][0]	Time 2.200 (2.200)	Data 1.565 (1.565)	Loss 3.9120 (3.9120)	Lr: 0.0589
INFO - 09/02/20 16:49:52 - 0:46:46 - Epoch: [44][50]	Time 0.618 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0589
INFO - 09/02/20 16:50:21 - 0:47:15 - ============ Starting epoch 45 ... ============
INFO - 09/02/20 16:50:23 - 0:47:17 - Epoch: [45][0]	Time 2.227 (2.227)	Data 1.568 (1.568)	Loss 3.9120 (3.9120)	Lr: 0.0588
INFO - 09/02/20 16:50:54 - 0:47:48 - Epoch: [45][50]	Time 0.621 (0.653)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0588
INFO - 09/02/20 16:51:23 - 0:48:17 - ============ Starting epoch 46 ... ============
INFO - 09/02/20 16:51:25 - 0:48:19 - Epoch: [46][0]	Time 2.111 (2.111)	Data 1.474 (1.474)	Loss 3.9120 (3.9120)	Lr: 0.0588
INFO - 09/02/20 16:51:57 - 0:48:50 - Epoch: [46][50]	Time 0.619 (0.653)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0587
INFO - 09/02/20 16:52:25 - 0:49:19 - ============ Starting epoch 47 ... ============
INFO - 09/02/20 16:52:28 - 0:49:22 - Epoch: [47][0]	Time 2.525 (2.525)	Data 1.852 (1.852)	Loss 3.9120 (3.9120)	Lr: 0.0587
INFO - 09/02/20 16:52:59 - 0:49:53 - Epoch: [47][50]	Time 0.619 (0.658)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0587
INFO - 09/02/20 16:53:28 - 0:50:22 - ============ Starting epoch 48 ... ============
INFO - 09/02/20 16:53:30 - 0:50:24 - Epoch: [48][0]	Time 2.271 (2.271)	Data 1.635 (1.635)	Loss 3.9120 (3.9120)	Lr: 0.0586
INFO - 09/02/20 16:54:01 - 0:50:55 - Epoch: [48][50]	Time 0.641 (0.655)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0586
INFO - 09/02/20 16:54:30 - 0:51:24 - ============ Starting epoch 49 ... ============
INFO - 09/02/20 16:54:33 - 0:51:26 - Epoch: [49][0]	Time 2.202 (2.202)	Data 1.567 (1.567)	Loss 3.9120 (3.9120)	Lr: 0.0585
INFO - 09/02/20 16:55:04 - 0:51:57 - Epoch: [49][50]	Time 0.624 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0585
INFO - 09/02/20 16:55:33 - 0:52:27 - ============ Starting epoch 50 ... ============
INFO - 09/02/20 16:55:35 - 0:52:29 - Epoch: [50][0]	Time 2.539 (2.539)	Data 1.888 (1.888)	Loss 3.9120 (3.9120)	Lr: 0.0585
INFO - 09/02/20 16:56:07 - 0:53:00 - Epoch: [50][50]	Time 0.620 (0.662)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0584
INFO - 09/02/20 16:56:36 - 0:53:30 - ============ Starting epoch 51 ... ============
INFO - 09/02/20 16:56:38 - 0:53:32 - Epoch: [51][0]	Time 2.178 (2.178)	Data 1.548 (1.548)	Loss 3.9120 (3.9120)	Lr: 0.0584
INFO - 09/02/20 16:57:09 - 0:54:03 - Epoch: [51][50]	Time 0.619 (0.652)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0584
INFO - 09/02/20 16:57:38 - 0:54:32 - ============ Starting epoch 52 ... ============
INFO - 09/02/20 16:57:40 - 0:54:34 - Epoch: [52][0]	Time 2.204 (2.204)	Data 1.571 (1.571)	Loss 3.9120 (3.9120)	Lr: 0.0583
INFO - 09/02/20 16:58:12 - 0:55:05 - Epoch: [52][50]	Time 0.623 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0583
INFO - 09/02/20 16:58:41 - 0:55:34 - ============ Starting epoch 53 ... ============
INFO - 09/02/20 16:58:43 - 0:55:37 - Epoch: [53][0]	Time 2.243 (2.243)	Data 1.612 (1.612)	Loss 3.9120 (3.9120)	Lr: 0.0582
INFO - 09/02/20 16:59:14 - 0:56:08 - Epoch: [53][50]	Time 0.623 (0.655)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0582
INFO - 09/02/20 16:59:43 - 0:56:37 - ============ Starting epoch 54 ... ============
INFO - 09/02/20 16:59:45 - 0:56:39 - Epoch: [54][0]	Time 2.199 (2.199)	Data 1.562 (1.562)	Loss 3.9120 (3.9120)	Lr: 0.0582
INFO - 09/02/20 17:00:16 - 0:57:10 - Epoch: [54][50]	Time 0.619 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0581
INFO - 09/02/20 17:00:45 - 0:57:39 - ============ Starting epoch 55 ... ============
INFO - 09/02/20 17:00:48 - 0:57:41 - Epoch: [55][0]	Time 2.159 (2.159)	Data 1.509 (1.509)	Loss 3.9120 (3.9120)	Lr: 0.0581
INFO - 09/02/20 17:01:19 - 0:58:12 - Epoch: [55][50]	Time 0.619 (0.652)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0580
INFO - 09/02/20 17:01:48 - 0:58:41 - ============ Starting epoch 56 ... ============
INFO - 09/02/20 17:01:50 - 0:58:44 - Epoch: [56][0]	Time 2.278 (2.278)	Data 1.590 (1.590)	Loss 3.9120 (3.9120)	Lr: 0.0580
INFO - 09/02/20 17:02:21 - 0:59:15 - Epoch: [56][50]	Time 0.620 (0.656)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0579
INFO - 09/02/20 17:02:50 - 0:59:44 - ============ Starting epoch 57 ... ============
INFO - 09/02/20 17:02:52 - 0:59:46 - Epoch: [57][0]	Time 2.144 (2.144)	Data 1.507 (1.507)	Loss 3.9120 (3.9120)	Lr: 0.0579
INFO - 09/02/20 17:03:24 - 1:00:17 - Epoch: [57][50]	Time 0.623 (0.654)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0579
INFO - 09/02/20 17:03:52 - 1:00:46 - ============ Starting epoch 58 ... ============
INFO - 09/02/20 17:03:55 - 1:00:48 - Epoch: [58][0]	Time 2.112 (2.112)	Data 1.479 (1.479)	Loss 3.9120 (3.9120)	Lr: 0.0578
INFO - 09/02/20 17:04:26 - 1:01:19 - Epoch: [58][50]	Time 0.631 (0.652)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0578
INFO - 09/02/20 17:04:55 - 1:01:48 - ============ Starting epoch 59 ... ============
INFO - 09/02/20 17:04:57 - 1:01:51 - Epoch: [59][0]	Time 2.208 (2.208)	Data 1.570 (1.570)	Loss 3.9120 (3.9120)	Lr: 0.0577
INFO - 09/02/20 17:05:28 - 1:02:22 - Epoch: [59][50]	Time 0.619 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0577
INFO - 09/02/20 17:05:57 - 1:02:51 - ============ Starting epoch 60 ... ============
INFO - 09/02/20 17:05:59 - 1:02:53 - Epoch: [60][0]	Time 2.144 (2.144)	Data 1.500 (1.500)	Loss 3.9120 (3.9120)	Lr: 0.0576
INFO - 09/02/20 17:06:30 - 1:03:24 - Epoch: [60][50]	Time 0.623 (0.651)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0576
INFO - 09/02/20 17:06:59 - 1:03:53 - ============ Starting epoch 61 ... ============
INFO - 09/02/20 17:07:02 - 1:03:55 - Epoch: [61][0]	Time 2.237 (2.237)	Data 1.568 (1.568)	Loss 3.9120 (3.9120)	Lr: 0.0575
INFO - 09/02/20 17:07:33 - 1:04:27 - Epoch: [61][50]	Time 0.620 (0.654)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0575
INFO - 09/02/20 17:08:02 - 1:04:56 - ============ Starting epoch 62 ... ============
INFO - 09/02/20 17:08:05 - 1:04:58 - Epoch: [62][0]	Time 2.590 (2.590)	Data 1.935 (1.935)	Loss 3.9120 (3.9120)	Lr: 0.0574
INFO - 09/02/20 17:08:36 - 1:05:30 - Epoch: [62][50]	Time 0.620 (0.664)	Data 0.000 (0.038)	Loss 3.9120 (3.9120)	Lr: 0.0574
INFO - 09/02/20 17:09:05 - 1:05:59 - ============ Starting epoch 63 ... ============
INFO - 09/02/20 17:09:07 - 1:06:01 - Epoch: [63][0]	Time 2.197 (2.197)	Data 1.561 (1.561)	Loss 3.9120 (3.9120)	Lr: 0.0573
INFO - 09/02/20 17:09:40 - 1:06:34 - Epoch: [63][50]	Time 1.104 (0.686)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0573
INFO - 09/02/20 17:10:26 - 1:07:20 - ============ Starting epoch 64 ... ============
INFO - 09/02/20 17:10:28 - 1:07:22 - Epoch: [64][0]	Time 2.546 (2.546)	Data 1.840 (1.840)	Loss 3.9120 (3.9120)	Lr: 0.0572
INFO - 09/02/20 17:11:02 - 1:07:56 - Epoch: [64][50]	Time 0.674 (0.703)	Data 0.000 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.0572
INFO - 09/02/20 17:11:42 - 1:08:35 - ============ Starting epoch 65 ... ============
INFO - 09/02/20 17:11:44 - 1:08:37 - Epoch: [65][0]	Time 2.234 (2.234)	Data 1.562 (1.562)	Loss 3.9120 (3.9120)	Lr: 0.0571
INFO - 09/02/20 17:12:17 - 1:09:11 - Epoch: [65][50]	Time 0.645 (0.696)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0571
INFO - 09/02/20 17:12:57 - 1:09:50 - ============ Starting epoch 66 ... ============
INFO - 09/02/20 17:12:59 - 1:09:52 - Epoch: [66][0]	Time 2.116 (2.116)	Data 1.481 (1.481)	Loss 3.9120 (3.9120)	Lr: 0.0570
INFO - 09/02/20 17:13:32 - 1:10:26 - Epoch: [66][50]	Time 0.761 (0.701)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0570
INFO - 09/02/20 17:14:12 - 1:11:05 - ============ Starting epoch 67 ... ============
INFO - 09/02/20 17:14:14 - 1:11:08 - Epoch: [67][0]	Time 2.188 (2.188)	Data 1.489 (1.489)	Loss 3.9120 (3.9120)	Lr: 0.0569
INFO - 09/02/20 17:14:48 - 1:11:42 - Epoch: [67][50]	Time 0.798 (0.718)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0569
INFO - 09/02/20 17:15:27 - 1:12:21 - ============ Starting epoch 68 ... ============
INFO - 09/02/20 17:15:30 - 1:12:23 - Epoch: [68][0]	Time 2.597 (2.597)	Data 1.886 (1.886)	Loss 3.9120 (3.9120)	Lr: 0.0568
INFO - 09/02/20 17:16:07 - 1:13:00 - Epoch: [68][50]	Time 1.118 (0.776)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0568
INFO - 09/02/20 17:16:42 - 1:13:36 - ============ Starting epoch 69 ... ============
INFO - 09/02/20 17:16:45 - 1:13:38 - Epoch: [69][0]	Time 2.276 (2.276)	Data 1.610 (1.610)	Loss 3.9120 (3.9120)	Lr: 0.0567
INFO - 09/02/20 17:17:25 - 1:14:19 - Epoch: [69][50]	Time 1.176 (0.837)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0567
INFO - 09/02/20 17:17:58 - 1:14:52 - ============ Starting epoch 70 ... ============
INFO - 09/02/20 17:18:00 - 1:14:54 - Epoch: [70][0]	Time 2.573 (2.573)	Data 1.817 (1.817)	Loss 3.9120 (3.9120)	Lr: 0.0566
INFO - 09/02/20 17:18:42 - 1:15:36 - Epoch: [70][50]	Time 0.698 (0.875)	Data 0.000 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.0565
INFO - 09/02/20 17:19:13 - 1:16:07 - ============ Starting epoch 71 ... ============
INFO - 09/02/20 17:19:16 - 1:16:09 - Epoch: [71][0]	Time 2.387 (2.387)	Data 1.691 (1.691)	Loss 3.9120 (3.9120)	Lr: 0.0565
INFO - 09/02/20 17:19:58 - 1:16:51 - Epoch: [71][50]	Time 0.677 (0.869)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0564
INFO - 09/02/20 17:20:29 - 1:17:22 - ============ Starting epoch 72 ... ============
INFO - 09/02/20 17:20:31 - 1:17:25 - Epoch: [72][0]	Time 2.531 (2.531)	Data 1.777 (1.777)	Loss 3.9120 (3.9120)	Lr: 0.0564
INFO - 09/02/20 17:21:13 - 1:18:07 - Epoch: [72][50]	Time 0.663 (0.876)	Data 0.000 (0.035)	Loss 3.9120 (3.9120)	Lr: 0.0563
INFO - 09/02/20 17:21:44 - 1:18:38 - ============ Starting epoch 73 ... ============
INFO - 09/02/20 17:21:47 - 1:18:40 - Epoch: [73][0]	Time 2.239 (2.239)	Data 1.518 (1.518)	Loss 3.9120 (3.9120)	Lr: 0.0563
INFO - 09/02/20 17:22:29 - 1:19:22 - Epoch: [73][50]	Time 0.624 (0.869)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0562
INFO - 09/02/20 17:23:00 - 1:19:54 - ============ Starting epoch 74 ... ============
INFO - 09/02/20 17:23:03 - 1:19:57 - Epoch: [74][0]	Time 2.419 (2.419)	Data 1.716 (1.716)	Loss 3.9120 (3.9120)	Lr: 0.0561
INFO - 09/02/20 17:23:45 - 1:20:39 - Epoch: [74][50]	Time 0.647 (0.878)	Data 0.000 (0.034)	Loss 3.9120 (3.9120)	Lr: 0.0561
INFO - 09/02/20 17:24:16 - 1:21:10 - ============ Starting epoch 75 ... ============
INFO - 09/02/20 17:24:19 - 1:21:13 - Epoch: [75][0]	Time 2.515 (2.515)	Data 1.692 (1.692)	Loss 3.9120 (3.9120)	Lr: 0.0560
INFO - 09/02/20 17:25:00 - 1:21:54 - Epoch: [75][50]	Time 0.645 (0.865)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0560
INFO - 09/02/20 17:25:33 - 1:22:26 - ============ Starting epoch 76 ... ============
INFO - 09/02/20 17:25:35 - 1:22:29 - Epoch: [76][0]	Time 2.422 (2.422)	Data 1.587 (1.587)	Loss 3.9120 (3.9120)	Lr: 0.0559
INFO - 09/02/20 17:26:15 - 1:23:09 - Epoch: [76][50]	Time 0.632 (0.840)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0558
INFO - 09/02/20 17:26:48 - 1:23:42 - ============ Starting epoch 77 ... ============
INFO - 09/02/20 17:26:51 - 1:23:45 - Epoch: [77][0]	Time 2.837 (2.837)	Data 1.686 (1.686)	Loss 3.9120 (3.9120)	Lr: 0.0558
INFO - 09/02/20 17:27:29 - 1:24:23 - Epoch: [77][50]	Time 0.681 (0.801)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0557
INFO - 09/02/20 17:28:06 - 1:25:00 - ============ Starting epoch 78 ... ============
INFO - 09/02/20 17:28:09 - 1:25:02 - Epoch: [78][0]	Time 2.812 (2.812)	Data 1.656 (1.656)	Loss 3.9120 (3.9120)	Lr: 0.0557
INFO - 09/02/20 17:28:43 - 1:25:37 - Epoch: [78][50]	Time 0.687 (0.732)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0556
INFO - 09/02/20 17:29:23 - 1:26:16 - ============ Starting epoch 79 ... ============
INFO - 09/02/20 17:29:25 - 1:26:19 - Epoch: [79][0]	Time 2.378 (2.378)	Data 1.627 (1.627)	Loss 3.9120 (3.9120)	Lr: 0.0555
INFO - 09/02/20 17:29:59 - 1:26:53 - Epoch: [79][50]	Time 0.651 (0.716)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0555
INFO - 09/02/20 17:30:39 - 1:27:33 - ============ Starting epoch 80 ... ============
INFO - 09/02/20 17:30:41 - 1:27:35 - Epoch: [80][0]	Time 2.324 (2.324)	Data 1.627 (1.627)	Loss 3.9120 (3.9120)	Lr: 0.0554
INFO - 09/02/20 17:31:15 - 1:28:09 - Epoch: [80][50]	Time 0.689 (0.703)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0553
INFO - 09/02/20 17:31:55 - 1:28:48 - ============ Starting epoch 81 ... ============
INFO - 09/02/20 17:31:57 - 1:28:51 - Epoch: [81][0]	Time 2.201 (2.201)	Data 1.452 (1.452)	Loss 3.9120 (3.9120)	Lr: 0.0553
INFO - 09/02/20 17:32:30 - 1:29:24 - Epoch: [81][50]	Time 0.620 (0.694)	Data 0.001 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0552
INFO - 09/02/20 17:33:10 - 1:30:04 - ============ Starting epoch 82 ... ============
INFO - 09/02/20 17:33:12 - 1:30:06 - Epoch: [82][0]	Time 2.562 (2.562)	Data 1.855 (1.855)	Loss 3.9120 (3.9120)	Lr: 0.0551
INFO - 09/02/20 17:33:46 - 1:30:40 - Epoch: [82][50]	Time 0.741 (0.705)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0551
INFO - 09/02/20 17:34:26 - 1:31:19 - ============ Starting epoch 83 ... ============
INFO - 09/02/20 17:34:28 - 1:31:22 - Epoch: [83][0]	Time 2.190 (2.190)	Data 1.511 (1.511)	Loss 3.9120 (3.9120)	Lr: 0.0550
INFO - 09/02/20 17:35:02 - 1:31:56 - Epoch: [83][50]	Time 0.783 (0.710)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0549
INFO - 09/02/20 17:35:41 - 1:32:35 - ============ Starting epoch 84 ... ============
INFO - 09/02/20 17:35:44 - 1:32:38 - Epoch: [84][0]	Time 2.558 (2.558)	Data 1.846 (1.846)	Loss 3.9120 (3.9120)	Lr: 0.0549
INFO - 09/02/20 17:36:20 - 1:33:14 - Epoch: [84][50]	Time 1.126 (0.763)	Data 0.000 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.0548
INFO - 09/02/20 17:36:57 - 1:33:51 - ============ Starting epoch 85 ... ============
INFO - 09/02/20 17:37:00 - 1:33:53 - Epoch: [85][0]	Time 2.211 (2.211)	Data 1.510 (1.510)	Loss 3.9120 (3.9120)	Lr: 0.0547
INFO - 09/02/20 17:37:39 - 1:34:32 - Epoch: [85][50]	Time 1.222 (0.810)	Data 0.000 (0.030)	Loss 3.9121 (3.9120)	Lr: 0.0547
INFO - 09/02/20 17:38:13 - 1:35:07 - ============ Starting epoch 86 ... ============
INFO - 09/02/20 17:38:15 - 1:35:09 - Epoch: [86][0]	Time 2.219 (2.219)	Data 1.518 (1.518)	Loss 3.9120 (3.9120)	Lr: 0.0546
INFO - 09/02/20 17:38:57 - 1:35:51 - Epoch: [86][50]	Time 1.162 (0.864)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0545
INFO - 09/02/20 17:39:28 - 1:36:22 - ============ Starting epoch 87 ... ============
INFO - 09/02/20 17:39:31 - 1:36:24 - Epoch: [87][0]	Time 2.394 (2.394)	Data 1.632 (1.632)	Loss 3.9120 (3.9120)	Lr: 0.0545
INFO - 09/02/20 17:40:13 - 1:37:07 - Epoch: [87][50]	Time 0.667 (0.883)	Data 0.001 (0.032)	Loss 3.9121 (3.9121)	Lr: 0.0544
INFO - 09/02/20 17:40:45 - 1:37:38 - ============ Starting epoch 88 ... ============
INFO - 09/02/20 17:40:47 - 1:37:41 - Epoch: [88][0]	Time 2.388 (2.388)	Data 1.673 (1.673)	Loss 3.9120 (3.9120)	Lr: 0.0543
INFO - 09/02/20 17:41:29 - 1:38:23 - Epoch: [88][50]	Time 0.696 (0.878)	Data 0.000 (0.033)	Loss 3.9120 (3.9121)	Lr: 0.0543
INFO - 09/02/20 17:42:01 - 1:38:55 - ============ Starting epoch 89 ... ============
INFO - 09/02/20 17:42:03 - 1:38:57 - Epoch: [89][0]	Time 2.370 (2.370)	Data 1.677 (1.677)	Loss 3.9120 (3.9120)	Lr: 0.0542
INFO - 09/02/20 17:42:46 - 1:39:40 - Epoch: [89][50]	Time 0.656 (0.877)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0541
INFO - 09/02/20 17:43:17 - 1:40:11 - ============ Starting epoch 90 ... ============
INFO - 09/02/20 17:43:19 - 1:40:13 - Epoch: [90][0]	Time 2.241 (2.241)	Data 1.499 (1.499)	Loss 3.9120 (3.9120)	Lr: 0.0540
INFO - 09/02/20 17:44:02 - 1:40:55 - Epoch: [90][50]	Time 0.665 (0.871)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0540
INFO - 09/02/20 17:44:33 - 1:41:27 - ============ Starting epoch 91 ... ============
INFO - 09/02/20 17:44:35 - 1:41:29 - Epoch: [91][0]	Time 2.400 (2.400)	Data 1.609 (1.609)	Loss 3.9120 (3.9120)	Lr: 0.0539
INFO - 09/02/20 17:45:17 - 1:42:11 - Epoch: [91][50]	Time 0.661 (0.871)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0538
INFO - 09/02/20 17:45:49 - 1:42:43 - ============ Starting epoch 92 ... ============
INFO - 09/02/20 17:45:52 - 1:42:46 - Epoch: [92][0]	Time 2.929 (2.929)	Data 2.120 (2.120)	Loss 3.9120 (3.9120)	Lr: 0.0538
INFO - 09/02/20 17:46:34 - 1:43:27 - Epoch: [92][50]	Time 0.664 (0.872)	Data 0.000 (0.042)	Loss 3.9120 (3.9120)	Lr: 0.0537
INFO - 09/02/20 17:47:05 - 1:43:59 - ============ Starting epoch 93 ... ============
INFO - 09/02/20 17:47:08 - 1:44:02 - Epoch: [93][0]	Time 2.734 (2.734)	Data 1.875 (1.875)	Loss 3.9120 (3.9120)	Lr: 0.0536
INFO - 09/02/20 17:47:49 - 1:44:43 - Epoch: [93][50]	Time 0.634 (0.858)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0535
INFO - 09/02/20 17:48:22 - 1:45:16 - ============ Starting epoch 94 ... ============
INFO - 09/02/20 17:48:24 - 1:45:18 - Epoch: [94][0]	Time 2.631 (2.631)	Data 1.527 (1.527)	Loss 3.9121 (3.9121)	Lr: 0.0535
INFO - 09/02/20 17:49:04 - 1:45:58 - Epoch: [94][50]	Time 0.649 (0.829)	Data 0.000 (0.030)	Loss 3.9120 (3.9120)	Lr: 0.0534
INFO - 09/02/20 17:49:39 - 1:46:33 - ============ Starting epoch 95 ... ============
INFO - 09/02/20 17:49:42 - 1:46:35 - Epoch: [95][0]	Time 2.723 (2.723)	Data 1.546 (1.546)	Loss 3.9120 (3.9120)	Lr: 0.0533
INFO - 09/02/20 17:50:18 - 1:47:12 - Epoch: [95][50]	Time 0.693 (0.778)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0532
INFO - 09/02/20 17:50:55 - 1:47:49 - ============ Starting epoch 96 ... ============
INFO - 09/02/20 17:50:58 - 1:47:51 - Epoch: [96][0]	Time 2.806 (2.806)	Data 1.629 (1.629)	Loss 3.9120 (3.9120)	Lr: 0.0532
INFO - 09/02/20 17:51:33 - 1:48:27 - Epoch: [96][50]	Time 0.692 (0.746)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0531
INFO - 09/02/20 17:52:12 - 1:49:06 - ============ Starting epoch 97 ... ============
INFO - 09/02/20 17:52:14 - 1:49:08 - Epoch: [97][0]	Time 2.425 (2.425)	Data 1.666 (1.666)	Loss 3.9120 (3.9120)	Lr: 0.0530
INFO - 09/02/20 17:52:49 - 1:49:43 - Epoch: [97][50]	Time 0.683 (0.720)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0529
INFO - 09/02/20 17:53:29 - 1:50:23 - ============ Starting epoch 98 ... ============
INFO - 09/02/20 17:53:31 - 1:50:25 - Epoch: [98][0]	Time 2.301 (2.301)	Data 1.600 (1.600)	Loss 3.9120 (3.9120)	Lr: 0.0528
INFO - 09/02/20 17:54:05 - 1:50:58 - Epoch: [98][50]	Time 0.673 (0.701)	Data 0.000 (0.032)	Loss 3.9120 (3.9120)	Lr: 0.0528
INFO - 09/02/20 17:54:44 - 1:51:38 - ============ Starting epoch 99 ... ============
INFO - 09/02/20 17:54:47 - 1:51:41 - Epoch: [99][0]	Time 2.558 (2.558)	Data 1.867 (1.867)	Loss 3.9120 (3.9120)	Lr: 0.0527
INFO - 09/02/20 17:55:20 - 1:52:14 - Epoch: [99][50]	Time 0.643 (0.706)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0526
INFO - 09/02/20 17:56:00 - 1:52:54 - ============ Starting epoch 100 ... ============
INFO - 09/02/20 17:56:02 - 1:52:56 - Epoch: [100][0]	Time 2.524 (2.524)	Data 1.835 (1.835)	Loss 3.9120 (3.9120)	Lr: 0.0525
INFO - 09/02/20 17:56:36 - 1:53:30 - Epoch: [100][50]	Time 0.815 (0.708)	Data 0.000 (0.036)	Loss 3.9120 (3.9120)	Lr: 0.0524
INFO - 09/02/20 17:57:16 - 1:54:09 - ============ Starting epoch 101 ... ============
INFO - 09/02/20 17:57:18 - 1:54:12 - Epoch: [101][0]	Time 2.394 (2.394)	Data 1.678 (1.678)	Loss 3.9120 (3.9120)	Lr: 0.0524
INFO - 09/02/20 17:57:53 - 1:54:46 - Epoch: [101][50]	Time 0.756 (0.722)	Data 0.000 (0.033)	Loss 3.9120 (3.9120)	Lr: 0.0523
INFO - 09/02/20 17:58:31 - 1:55:25 - ============ Starting epoch 102 ... ============
INFO - 09/02/20 17:58:34 - 1:55:28 - Epoch: [102][0]	Time 2.626 (2.626)	Data 1.866 (1.866)	Loss 3.9120 (3.9120)	Lr: 0.0522
INFO - 09/02/20 17:59:09 - 1:56:02 - Epoch: [102][50]	Time 0.795 (0.733)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0521
INFO - 09/02/20 17:59:47 - 1:56:41 - ============ Starting epoch 103 ... ============
INFO - 09/02/20 17:59:49 - 1:56:43 - Epoch: [103][0]	Time 2.182 (2.182)	Data 1.484 (1.484)	Loss 3.9120 (3.9120)	Lr: 0.0520
INFO - 09/02/20 18:00:26 - 1:57:20 - Epoch: [103][50]	Time 1.121 (0.769)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0520
INFO - 09/02/20 18:01:02 - 1:57:56 - ============ Starting epoch 104 ... ============
INFO - 09/02/20 18:01:04 - 1:57:58 - Epoch: [104][0]	Time 2.195 (2.195)	Data 1.560 (1.560)	Loss 3.9120 (3.9120)	Lr: 0.0519
INFO - 09/02/20 18:01:45 - 1:58:39 - Epoch: [104][50]	Time 1.141 (0.837)	Data 0.000 (0.031)	Loss 3.9120 (3.9120)	Lr: 0.0518
INFO - 09/02/20 18:02:17 - 1:59:11 - ============ Starting epoch 105 ... ============
INFO - 09/02/20 18:02:20 - 1:59:14 - Epoch: [105][0]	Time 2.430 (2.430)	Data 1.704 (1.704)	Loss 3.9120 (3.9120)	Lr: 0.0517
INFO - 09/02/20 18:03:02 - 1:59:56 - Epoch: [105][50]	Time 0.676 (0.871)	Data 0.000 (0.034)	Loss 3.9120 (3.9120)	Lr: 0.0516
INFO - 09/02/20 18:03:33 - 2:00:27 - ============ Starting epoch 106 ... ============
INFO - 09/02/20 18:03:36 - 2:00:29 - Epoch: [106][0]	Time 2.584 (2.584)	Data 1.897 (1.897)	Loss 3.9120 (3.9120)	Lr: 0.0516
INFO - 09/02/20 18:04:18 - 2:01:11 - Epoch: [106][50]	Time 0.673 (0.876)	Data 0.000 (0.037)	Loss 3.9120 (3.9120)	Lr: 0.0515
INFO - 09/02/20 18:04:49 - 2:01:42 - ============ Starting epoch 107 ... ============
INFO - 09/02/20 18:04:51 - 2:01:45 - Epoch: [107][0]	Time 2.418 (2.418)	Data 1.738 (1.738)	Loss 3.9120 (3.9120)	Lr: 0.0514
INFO - 09/02/20 18:05:34 - 2:02:28 - Epoch: [107][50]	Time 0.676 (0.893)	Data 0.000 (0.034)	Loss 3.9120 (3.9120)	Lr: 0.0513
INFO - 09/02/20 18:06:05 - 2:02:59 - ============ Starting epoch 108 ... ============
INFO - 09/02/20 18:06:07 - 2:03:01 - Epoch: [108][0]	Time 2.117 (2.117)	Data 1.481 (1.481)	Loss 3.9120 (3.9120)	Lr: 0.0512
INFO - 09/02/20 18:06:49 - 2:03:43 - Epoch: [108][50]	Time 0.676 (0.867)	Data 0.000 (0.029)	Loss 3.9120 (3.9120)	Lr: 0.0511
INFO - 09/02/20 18:07:44 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 18:07:44 - 0:00:00 - arch: resnet50
                                     base_lr: 0.006
                                     batch_size: 512
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 10
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 18:07:44 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 18:07:44 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 18:07:50 - 0:00:06 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=10, bias=False)
                                     )
INFO - 09/02/20 18:07:50 - 0:00:06 - Building model done.
INFO - 09/02/20 18:07:50 - 0:00:06 - Building optimizer done.
INFO - 09/02/20 18:07:50 - 0:00:06 - Initializing mixed precision done.
INFO - 09/02/20 18:07:50 - 0:00:06 - Found checkpoint at ./checkpoint.pth.tar
INFO - 09/02/20 18:08:29 - 0:00:00 - ============ Initialized logger ============
INFO - 09/02/20 18:08:29 - 0:00:00 - arch: resnet50
                                     base_lr: 0.006
                                     batch_size: 512
                                     checkpoint_freq: 25
                                     crops_for_assign: [0, 1]
                                     data_path: ../../dataset/
                                     dist_url: env://
                                     dump_checkpoints: ./checkpoints
                                     dump_path: .
                                     epoch_queue_starts: 15
                                     epochs: 400
                                     epsilon: 0.05
                                     feat_dim: 128
                                     final_lr: 0.0006
                                     freeze_prototypes_niters: 313
                                     hidden_mlp: 2048
                                     local_rank: 0
                                     max_scale_crops: [1]
                                     min_scale_crops: [0.14]
                                     nmb_crops: [2]
                                     nmb_prototypes: 10
                                     queue_length: 0
                                     rank: 0
                                     seed: 31
                                     sinkhorn_iterations: 3
                                     size_crops: [32]
                                     start_warmup: 0
                                     sync_bn: pytorch
                                     temperature: 0.1
                                     use_fp16: True
                                     warmup_epochs: 10
                                     wd: 1e-06
                                     workers: 10
                                     world_size: -1
INFO - 09/02/20 18:08:29 - 0:00:00 - The experiment will be stored in .
                                     

INFO - 09/02/20 18:08:29 - 0:00:01 - Building data done with 50000 images loaded.
INFO - 09/02/20 18:08:36 - 0:00:07 - ResNet(
                                       (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)
                                       (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (layer1): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (3): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (4): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (5): Bottleneck(
                                           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): Bottleneck(
                                           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                         (2): Bottleneck(
                                           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                                           (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (projection_head): Sequential(
                                         (0): Linear(in_features=2048, out_features=2048, bias=True)
                                         (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         (2): ReLU(inplace=True)
                                         (3): Linear(in_features=2048, out_features=128, bias=True)
                                       )
                                       (prototypes): Linear(in_features=128, out_features=10, bias=False)
                                     )
INFO - 09/02/20 18:08:36 - 0:00:07 - Building model done.
INFO - 09/02/20 18:08:36 - 0:00:07 - Building optimizer done.
INFO - 09/02/20 18:08:36 - 0:00:07 - Initializing mixed precision done.
INFO - 09/02/20 18:08:36 - 0:00:07 - ============ Starting epoch 0 ... ============
INFO - 09/02/20 18:08:49 - 0:00:21 - Epoch: [0][0]	Time 13.081 (13.081)	Data 1.617 (1.617)	Loss 2.6397 (2.6397)	Lr: 0.0000
INFO - 09/02/20 18:09:23 - 0:00:55 - Epoch: [0][50]	Time 0.811 (0.923)	Data 0.000 (0.032)	Loss 2.6187 (2.6262)	Lr: 0.0003
INFO - 09/02/20 18:10:03 - 0:01:34 - ============ Starting epoch 1 ... ============
INFO - 09/02/20 18:10:05 - 0:01:36 - Epoch: [1][0]	Time 2.310 (2.310)	Data 1.559 (1.559)	Loss 2.5173 (2.5173)	Lr: 0.0006
INFO - 09/02/20 18:10:40 - 0:02:11 - Epoch: [1][50]	Time 0.941 (0.736)	Data 0.000 (0.031)	Loss 2.4732 (2.4903)	Lr: 0.0009
INFO - 09/02/20 18:11:19 - 0:02:50 - ============ Starting epoch 2 ... ============
INFO - 09/02/20 18:11:21 - 0:02:52 - Epoch: [2][0]	Time 2.454 (2.454)	Data 1.754 (1.754)	Loss 2.4340 (2.4340)	Lr: 0.0012
INFO - 09/02/20 18:11:57 - 0:03:28 - Epoch: [2][50]	Time 1.194 (0.749)	Data 0.000 (0.035)	Loss 2.3987 (2.4189)	Lr: 0.0015
INFO - 09/02/20 18:12:34 - 0:04:06 - ============ Starting epoch 3 ... ============
INFO - 09/02/20 18:12:37 - 0:04:08 - Epoch: [3][0]	Time 2.584 (2.584)	Data 1.922 (1.922)	Loss 2.3857 (2.3857)	Lr: 0.0018
INFO - 09/02/20 18:13:16 - 0:04:48 - Epoch: [3][50]	Time 1.139 (0.820)	Data 0.000 (0.038)	Loss 2.3650 (2.3779)	Lr: 0.0021
INFO - 09/02/20 18:13:51 - 0:05:22 - ============ Starting epoch 4 ... ============
INFO - 09/02/20 18:13:53 - 0:05:24 - Epoch: [4][0]	Time 2.347 (2.347)	Data 1.701 (1.701)	Loss 2.3586 (2.3586)	Lr: 0.0024
INFO - 09/02/20 18:14:35 - 0:06:07 - Epoch: [4][50]	Time 0.683 (0.877)	Data 0.000 (0.034)	Loss 2.3480 (2.3534)	Lr: 0.0027
INFO - 09/02/20 18:15:06 - 0:06:38 - ============ Starting epoch 5 ... ============
INFO - 09/02/20 18:15:09 - 0:06:40 - Epoch: [5][0]	Time 2.371 (2.371)	Data 1.663 (1.663)	Loss 2.3366 (2.3366)	Lr: 0.0030
INFO - 09/02/20 18:15:51 - 0:07:23 - Epoch: [5][50]	Time 0.678 (0.882)	Data 0.000 (0.033)	Loss 2.3332 (2.3358)	Lr: 0.0033
INFO - 09/02/20 18:16:23 - 0:07:54 - ============ Starting epoch 6 ... ============
INFO - 09/02/20 18:16:25 - 0:07:57 - Epoch: [6][0]	Time 2.618 (2.618)	Data 1.848 (1.848)	Loss 2.3251 (2.3251)	Lr: 0.0036
INFO - 09/02/20 18:17:08 - 0:08:39 - Epoch: [6][50]	Time 0.682 (0.881)	Data 0.000 (0.037)	Loss 2.3220 (2.3234)	Lr: 0.0039
INFO - 09/02/20 18:17:39 - 0:09:10 - ============ Starting epoch 7 ... ============
INFO - 09/02/20 18:17:41 - 0:09:12 - Epoch: [7][0]	Time 2.385 (2.385)	Data 1.702 (1.702)	Loss 2.3173 (2.3173)	Lr: 0.0042
INFO - 09/02/20 18:18:23 - 0:09:55 - Epoch: [7][50]	Time 0.627 (0.875)	Data 0.000 (0.034)	Loss 2.3139 (2.3152)	Lr: 0.0045
INFO - 09/02/20 18:18:55 - 0:10:26 - ============ Starting epoch 8 ... ============
INFO - 09/02/20 18:18:58 - 0:10:29 - Epoch: [8][0]	Time 2.628 (2.628)	Data 1.800 (1.800)	Loss 2.3112 (2.3112)	Lr: 0.0048
INFO - 09/02/20 18:19:40 - 0:11:11 - Epoch: [8][50]	Time 0.656 (0.875)	Data 0.000 (0.036)	Loss 2.3092 (2.3098)	Lr: 0.0051
INFO - 09/02/20 18:20:13 - 0:11:44 - ============ Starting epoch 9 ... ============
INFO - 09/02/20 18:20:16 - 0:11:47 - Epoch: [9][0]	Time 3.194 (3.194)	Data 2.049 (2.049)	Loss 2.3075 (2.3075)	Lr: 0.0054
INFO - 09/02/20 18:20:55 - 0:12:27 - Epoch: [9][50]	Time 0.698 (0.836)	Data 0.000 (0.040)	Loss 2.3068 (2.3068)	Lr: 0.0057
INFO - 09/02/20 18:21:31 - 0:13:03 - ============ Starting epoch 10 ... ============
INFO - 09/02/20 18:21:34 - 0:13:05 - Epoch: [10][0]	Time 2.892 (2.892)	Data 1.715 (1.715)	Loss 2.3052 (2.3052)	Lr: 0.0060
INFO - 09/02/20 18:22:10 - 0:13:41 - Epoch: [10][50]	Time 0.682 (0.760)	Data 0.000 (0.034)	Loss 2.3050 (2.3051)	Lr: 0.0060
INFO - 09/02/20 18:22:49 - 0:14:20 - ============ Starting epoch 11 ... ============
INFO - 09/02/20 18:22:52 - 0:14:23 - Epoch: [11][0]	Time 2.424 (2.424)	Data 1.714 (1.714)	Loss 2.3042 (2.3042)	Lr: 0.0060
INFO - 09/02/20 18:23:26 - 0:14:57 - Epoch: [11][50]	Time 0.696 (0.715)	Data 0.000 (0.034)	Loss 2.3039 (2.3042)	Lr: 0.0060
INFO - 09/02/20 18:24:06 - 0:15:37 - ============ Starting epoch 12 ... ============
INFO - 09/02/20 18:24:08 - 0:15:39 - Epoch: [12][0]	Time 2.724 (2.724)	Data 1.993 (1.993)	Loss 2.3041 (2.3041)	Lr: 0.0060
INFO - 09/02/20 18:24:42 - 0:16:13 - Epoch: [12][50]	Time 0.680 (0.715)	Data 0.000 (0.039)	Loss 2.3035 (2.3037)	Lr: 0.0060
INFO - 09/02/20 18:25:22 - 0:16:53 - ============ Starting epoch 13 ... ============
INFO - 09/02/20 18:25:24 - 0:16:56 - Epoch: [13][0]	Time 2.407 (2.407)	Data 1.710 (1.710)	Loss 2.3035 (2.3035)	Lr: 0.0060
INFO - 09/02/20 18:25:58 - 0:17:29 - Epoch: [13][50]	Time 0.641 (0.708)	Data 0.000 (0.034)	Loss 2.3033 (2.3034)	Lr: 0.0060
INFO - 09/02/20 18:26:39 - 0:18:10 - ============ Starting epoch 14 ... ============
INFO - 09/02/20 18:26:41 - 0:18:12 - Epoch: [14][0]	Time 2.505 (2.505)	Data 1.773 (1.773)	Loss 2.3033 (2.3033)	Lr: 0.0060
INFO - 09/02/20 18:27:15 - 0:18:47 - Epoch: [14][50]	Time 0.795 (0.718)	Data 0.001 (0.035)	Loss 2.3033 (2.3032)	Lr: 0.0060
INFO - 09/02/20 18:27:55 - 0:19:27 - ============ Starting epoch 15 ... ============
INFO - 09/02/20 18:27:58 - 0:19:29 - Epoch: [15][0]	Time 2.364 (2.364)	Data 1.648 (1.648)	Loss 2.3031 (2.3031)	Lr: 0.0060
INFO - 09/02/20 18:28:32 - 0:20:03 - Epoch: [15][50]	Time 0.801 (0.721)	Data 0.001 (0.033)	Loss 2.3031 (2.3031)	Lr: 0.0060
INFO - 09/02/20 18:29:11 - 0:20:42 - ============ Starting epoch 16 ... ============
INFO - 09/02/20 18:29:14 - 0:20:45 - Epoch: [16][0]	Time 2.561 (2.561)	Data 1.802 (1.802)	Loss 2.3030 (2.3030)	Lr: 0.0060
INFO - 09/02/20 18:29:50 - 0:21:21 - Epoch: [16][50]	Time 1.180 (0.764)	Data 0.001 (0.036)	Loss 2.3030 (2.3030)	Lr: 0.0060
INFO - 09/02/20 18:30:28 - 0:21:59 - ============ Starting epoch 17 ... ============
INFO - 09/02/20 18:30:31 - 0:22:02 - Epoch: [17][0]	Time 2.649 (2.649)	Data 1.965 (1.965)	Loss 2.3029 (2.3029)	Lr: 0.0060
INFO - 09/02/20 18:31:10 - 0:22:41 - Epoch: [17][50]	Time 1.140 (0.823)	Data 0.000 (0.039)	Loss 2.3029 (2.3029)	Lr: 0.0060
INFO - 09/02/20 18:31:44 - 0:23:16 - ============ Starting epoch 18 ... ============
INFO - 09/02/20 18:31:47 - 0:23:18 - Epoch: [18][0]	Time 2.389 (2.389)	Data 1.628 (1.628)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:32:29 - 0:24:00 - Epoch: [18][50]	Time 1.153 (0.874)	Data 0.000 (0.032)	Loss 2.3029 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:33:01 - 0:24:32 - ============ Starting epoch 19 ... ============
INFO - 09/02/20 18:33:03 - 0:24:35 - Epoch: [19][0]	Time 2.397 (2.397)	Data 1.636 (1.636)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:33:46 - 0:25:17 - Epoch: [19][50]	Time 0.651 (0.880)	Data 0.000 (0.032)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:34:17 - 0:25:49 - ============ Starting epoch 20 ... ============
INFO - 09/02/20 18:34:20 - 0:25:51 - Epoch: [20][0]	Time 2.337 (2.337)	Data 1.575 (1.575)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:35:02 - 0:26:33 - Epoch: [20][50]	Time 0.684 (0.875)	Data 0.000 (0.031)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:35:33 - 0:27:04 - ============ Starting epoch 21 ... ============
INFO - 09/02/20 18:35:36 - 0:27:07 - Epoch: [21][0]	Time 2.505 (2.505)	Data 1.806 (1.806)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:36:19 - 0:27:50 - Epoch: [21][50]	Time 0.691 (0.889)	Data 0.001 (0.036)	Loss 2.3027 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:36:50 - 0:28:22 - ============ Starting epoch 22 ... ============
INFO - 09/02/20 18:36:53 - 0:28:24 - Epoch: [22][0]	Time 2.480 (2.480)	Data 1.766 (1.766)	Loss 2.3028 (2.3028)	Lr: 0.0060
INFO - 09/02/20 18:37:35 - 0:29:06 - Epoch: [22][50]	Time 0.642 (0.879)	Data 0.000 (0.035)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:38:06 - 0:29:37 - ============ Starting epoch 23 ... ============
INFO - 09/02/20 18:38:09 - 0:29:40 - Epoch: [23][0]	Time 2.518 (2.518)	Data 1.651 (1.651)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:38:50 - 0:30:22 - Epoch: [23][50]	Time 0.686 (0.868)	Data 0.000 (0.033)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:39:23 - 0:30:54 - ============ Starting epoch 24 ... ============
INFO - 09/02/20 18:39:25 - 0:30:57 - Epoch: [24][0]	Time 2.492 (2.492)	Data 1.661 (1.661)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:40:07 - 0:31:38 - Epoch: [24][50]	Time 0.640 (0.854)	Data 0.000 (0.033)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:40:40 - 0:32:12 - ============ Starting epoch 25 ... ============
INFO - 09/02/20 18:40:43 - 0:32:14 - Epoch: [25][0]	Time 2.773 (2.773)	Data 1.664 (1.664)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:41:21 - 0:32:52 - Epoch: [25][50]	Time 0.687 (0.797)	Data 0.000 (0.033)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:41:58 - 0:33:29 - ============ Starting epoch 26 ... ============
INFO - 09/02/20 18:42:01 - 0:33:32 - Epoch: [26][0]	Time 2.843 (2.843)	Data 1.659 (1.659)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:42:36 - 0:34:07 - Epoch: [26][50]	Time 0.626 (0.740)	Data 0.000 (0.033)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:43:16 - 0:34:47 - ============ Starting epoch 27 ... ============
INFO - 09/02/20 18:43:19 - 0:34:50 - Epoch: [27][0]	Time 2.509 (2.509)	Data 1.846 (1.846)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:43:52 - 0:35:24 - Epoch: [27][50]	Time 0.642 (0.711)	Data 0.000 (0.036)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:44:32 - 0:36:03 - ============ Starting epoch 28 ... ============
INFO - 09/02/20 18:44:34 - 0:36:06 - Epoch: [28][0]	Time 2.281 (2.281)	Data 1.604 (1.604)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:45:08 - 0:36:39 - Epoch: [28][50]	Time 0.682 (0.702)	Data 0.000 (0.032)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:45:48 - 0:37:20 - ============ Starting epoch 29 ... ============
INFO - 09/02/20 18:45:51 - 0:37:22 - Epoch: [29][0]	Time 2.377 (2.377)	Data 1.664 (1.664)	Loss 2.3027 (2.3027)	Lr: 0.0060
INFO - 09/02/20 18:46:24 - 0:37:56 - Epoch: [29][50]	Time 0.656 (0.706)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:47:04 - 0:38:36 - ============ Starting epoch 30 ... ============
INFO - 09/02/20 18:47:07 - 0:38:38 - Epoch: [30][0]	Time 2.321 (2.321)	Data 1.637 (1.637)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:47:41 - 0:39:12 - Epoch: [30][50]	Time 0.797 (0.715)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:48:20 - 0:39:51 - ============ Starting epoch 31 ... ============
INFO - 09/02/20 18:48:22 - 0:39:54 - Epoch: [31][0]	Time 2.457 (2.457)	Data 1.701 (1.701)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:48:58 - 0:40:29 - Epoch: [31][50]	Time 0.776 (0.742)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:49:37 - 0:41:08 - ============ Starting epoch 32 ... ============
INFO - 09/02/20 18:49:39 - 0:41:11 - Epoch: [32][0]	Time 2.628 (2.628)	Data 1.945 (1.945)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:50:16 - 0:41:47 - Epoch: [32][50]	Time 1.185 (0.768)	Data 0.000 (0.038)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:50:53 - 0:42:24 - ============ Starting epoch 33 ... ============
INFO - 09/02/20 18:50:55 - 0:42:26 - Epoch: [33][0]	Time 2.309 (2.309)	Data 1.555 (1.555)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:51:35 - 0:43:06 - Epoch: [33][50]	Time 1.127 (0.824)	Data 0.000 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0060
INFO - 09/02/20 18:52:09 - 0:43:40 - ============ Starting epoch 34 ... ============
INFO - 09/02/20 18:52:11 - 0:43:42 - Epoch: [34][0]	Time 2.337 (2.337)	Data 1.623 (1.623)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:52:54 - 0:44:25 - Epoch: [34][50]	Time 0.696 (0.880)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:53:25 - 0:44:56 - ============ Starting epoch 35 ... ============
INFO - 09/02/20 18:53:27 - 0:44:59 - Epoch: [35][0]	Time 2.386 (2.386)	Data 1.674 (1.674)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:54:10 - 0:45:41 - Epoch: [35][50]	Time 0.680 (0.872)	Data 0.001 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:54:41 - 0:46:12 - ============ Starting epoch 36 ... ============
INFO - 09/02/20 18:54:43 - 0:46:15 - Epoch: [36][0]	Time 2.556 (2.556)	Data 1.793 (1.793)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:55:26 - 0:46:57 - Epoch: [36][50]	Time 0.689 (0.885)	Data 0.000 (0.035)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:55:57 - 0:47:29 - ============ Starting epoch 37 ... ============
INFO - 09/02/20 18:56:00 - 0:47:31 - Epoch: [37][0]	Time 2.326 (2.326)	Data 1.631 (1.631)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:56:42 - 0:48:13 - Epoch: [37][50]	Time 0.642 (0.876)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:57:13 - 0:48:44 - ============ Starting epoch 38 ... ============
INFO - 09/02/20 18:57:16 - 0:48:47 - Epoch: [38][0]	Time 2.644 (2.644)	Data 1.766 (1.766)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:57:58 - 0:49:29 - Epoch: [38][50]	Time 0.648 (0.868)	Data 0.000 (0.035)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:58:30 - 0:50:01 - ============ Starting epoch 39 ... ============
INFO - 09/02/20 18:58:32 - 0:50:04 - Epoch: [39][0]	Time 2.677 (2.677)	Data 1.836 (1.836)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:59:14 - 0:50:45 - Epoch: [39][50]	Time 0.649 (0.859)	Data 0.000 (0.036)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 18:59:48 - 0:51:19 - ============ Starting epoch 40 ... ============
INFO - 09/02/20 18:59:51 - 0:51:22 - Epoch: [40][0]	Time 2.869 (2.869)	Data 1.747 (1.747)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:00:28 - 0:51:59 - Epoch: [40][50]	Time 0.672 (0.794)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:01:05 - 0:52:36 - ============ Starting epoch 41 ... ============
INFO - 09/02/20 19:01:08 - 0:52:39 - Epoch: [41][0]	Time 3.057 (3.057)	Data 1.901 (1.901)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:01:43 - 0:53:14 - Epoch: [41][50]	Time 0.674 (0.743)	Data 0.001 (0.038)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:02:21 - 0:53:52 - ============ Starting epoch 42 ... ============
INFO - 09/02/20 19:02:24 - 0:53:55 - Epoch: [42][0]	Time 3.065 (3.065)	Data 1.938 (1.938)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:02:58 - 0:54:29 - Epoch: [42][50]	Time 0.700 (0.730)	Data 0.000 (0.038)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:03:38 - 0:55:09 - ============ Starting epoch 43 ... ============
INFO - 09/02/20 19:03:40 - 0:55:12 - Epoch: [43][0]	Time 2.420 (2.420)	Data 1.691 (1.691)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:04:14 - 0:55:45 - Epoch: [43][50]	Time 0.627 (0.704)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:04:54 - 0:56:25 - ============ Starting epoch 44 ... ============
INFO - 09/02/20 19:04:57 - 0:56:28 - Epoch: [44][0]	Time 2.579 (2.579)	Data 1.851 (1.851)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:05:31 - 0:57:02 - Epoch: [44][50]	Time 0.691 (0.716)	Data 0.000 (0.037)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:06:11 - 0:57:42 - ============ Starting epoch 45 ... ============
INFO - 09/02/20 19:06:13 - 0:57:44 - Epoch: [45][0]	Time 2.561 (2.561)	Data 1.859 (1.859)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:06:47 - 0:58:18 - Epoch: [45][50]	Time 0.795 (0.710)	Data 0.000 (0.037)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:07:26 - 0:58:58 - ============ Starting epoch 46 ... ============
INFO - 09/02/20 19:07:29 - 0:59:00 - Epoch: [46][0]	Time 2.254 (2.254)	Data 1.567 (1.567)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:08:03 - 0:59:34 - Epoch: [46][50]	Time 0.812 (0.722)	Data 0.000 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:08:43 - 1:00:14 - ============ Starting epoch 47 ... ============
INFO - 09/02/20 19:08:45 - 1:00:16 - Epoch: [47][0]	Time 2.352 (2.352)	Data 1.687 (1.687)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:09:21 - 1:00:53 - Epoch: [47][50]	Time 1.148 (0.762)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:09:58 - 1:01:30 - ============ Starting epoch 48 ... ============
INFO - 09/02/20 19:10:01 - 1:01:32 - Epoch: [48][0]	Time 2.312 (2.312)	Data 1.572 (1.572)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:10:40 - 1:02:12 - Epoch: [48][50]	Time 1.144 (0.822)	Data 0.000 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:11:14 - 1:02:45 - ============ Starting epoch 49 ... ============
INFO - 09/02/20 19:11:17 - 1:02:48 - Epoch: [49][0]	Time 2.398 (2.398)	Data 1.689 (1.689)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:11:59 - 1:03:30 - Epoch: [49][50]	Time 0.764 (0.882)	Data 0.001 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:12:31 - 1:04:02 - ============ Starting epoch 50 ... ============
INFO - 09/02/20 19:12:33 - 1:04:04 - Epoch: [50][0]	Time 2.315 (2.315)	Data 1.616 (1.616)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:13:15 - 1:04:47 - Epoch: [50][50]	Time 0.686 (0.875)	Data 0.001 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:13:47 - 1:05:18 - ============ Starting epoch 51 ... ============
INFO - 09/02/20 19:13:49 - 1:05:20 - Epoch: [51][0]	Time 2.271 (2.271)	Data 1.623 (1.623)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:14:31 - 1:06:03 - Epoch: [51][50]	Time 0.699 (0.878)	Data 0.001 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0059
INFO - 09/02/20 19:15:03 - 1:06:34 - ============ Starting epoch 52 ... ============
INFO - 09/02/20 19:15:06 - 1:06:37 - Epoch: [52][0]	Time 2.396 (2.396)	Data 1.649 (1.649)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:15:48 - 1:07:19 - Epoch: [52][50]	Time 0.626 (0.877)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:16:19 - 1:07:50 - ============ Starting epoch 53 ... ============
INFO - 09/02/20 19:16:21 - 1:07:53 - Epoch: [53][0]	Time 2.416 (2.416)	Data 1.577 (1.577)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:17:04 - 1:08:35 - Epoch: [53][50]	Time 0.658 (0.871)	Data 0.000 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:17:35 - 1:09:06 - ============ Starting epoch 54 ... ============
INFO - 09/02/20 19:17:38 - 1:09:09 - Epoch: [54][0]	Time 2.571 (2.571)	Data 1.738 (1.738)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:18:19 - 1:09:51 - Epoch: [54][50]	Time 0.634 (0.866)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:18:52 - 1:10:23 - ============ Starting epoch 55 ... ============
INFO - 09/02/20 19:18:55 - 1:10:26 - Epoch: [55][0]	Time 2.939 (2.939)	Data 1.729 (1.729)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:19:35 - 1:11:06 - Epoch: [55][50]	Time 0.644 (0.833)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:20:09 - 1:11:41 - ============ Starting epoch 56 ... ============
INFO - 09/02/20 19:20:12 - 1:11:44 - Epoch: [56][0]	Time 3.192 (3.192)	Data 2.016 (2.016)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:20:49 - 1:12:20 - Epoch: [56][50]	Time 0.701 (0.782)	Data 0.001 (0.040)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:21:28 - 1:12:59 - ============ Starting epoch 57 ... ============
INFO - 09/02/20 19:21:31 - 1:13:02 - Epoch: [57][0]	Time 2.854 (2.854)	Data 1.801 (1.801)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:22:04 - 1:13:35 - Epoch: [57][50]	Time 0.678 (0.717)	Data 0.000 (0.036)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:22:44 - 1:14:15 - ============ Starting epoch 58 ... ============
INFO - 09/02/20 19:22:47 - 1:14:18 - Epoch: [58][0]	Time 2.669 (2.669)	Data 1.903 (1.903)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:23:20 - 1:14:52 - Epoch: [58][50]	Time 0.694 (0.711)	Data 0.000 (0.038)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:24:01 - 1:15:32 - ============ Starting epoch 59 ... ============
INFO - 09/02/20 19:24:03 - 1:15:34 - Epoch: [59][0]	Time 2.431 (2.431)	Data 1.723 (1.723)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:24:37 - 1:16:08 - Epoch: [59][50]	Time 0.664 (0.714)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:25:17 - 1:16:48 - ============ Starting epoch 60 ... ============
INFO - 09/02/20 19:25:20 - 1:16:51 - Epoch: [60][0]	Time 2.519 (2.519)	Data 1.779 (1.779)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:25:54 - 1:17:25 - Epoch: [60][50]	Time 0.801 (0.717)	Data 0.000 (0.035)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:26:33 - 1:18:04 - ============ Starting epoch 61 ... ============
INFO - 09/02/20 19:26:35 - 1:18:07 - Epoch: [61][0]	Time 2.321 (2.321)	Data 1.610 (1.610)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:27:10 - 1:18:41 - Epoch: [61][50]	Time 0.783 (0.721)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:27:49 - 1:19:21 - ============ Starting epoch 62 ... ============
INFO - 09/02/20 19:27:52 - 1:19:23 - Epoch: [62][0]	Time 2.435 (2.435)	Data 1.662 (1.662)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:28:27 - 1:19:58 - Epoch: [62][50]	Time 0.877 (0.741)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:29:06 - 1:20:37 - ============ Starting epoch 63 ... ============
INFO - 09/02/20 19:29:08 - 1:20:39 - Epoch: [63][0]	Time 2.358 (2.358)	Data 1.601 (1.601)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:29:46 - 1:21:17 - Epoch: [63][50]	Time 1.139 (0.794)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0058
INFO - 09/02/20 19:30:21 - 1:21:53 - ============ Starting epoch 64 ... ============
INFO - 09/02/20 19:30:24 - 1:21:55 - Epoch: [64][0]	Time 2.328 (2.328)	Data 1.577 (1.577)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:31:06 - 1:22:37 - Epoch: [64][50]	Time 1.175 (0.869)	Data 0.001 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:31:38 - 1:23:09 - ============ Starting epoch 65 ... ============
INFO - 09/02/20 19:31:40 - 1:23:12 - Epoch: [65][0]	Time 2.680 (2.680)	Data 2.032 (2.032)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:32:23 - 1:23:54 - Epoch: [65][50]	Time 0.656 (0.884)	Data 0.000 (0.040)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:32:54 - 1:24:25 - ============ Starting epoch 66 ... ============
INFO - 09/02/20 19:32:57 - 1:24:28 - Epoch: [66][0]	Time 2.605 (2.605)	Data 1.966 (1.966)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:33:39 - 1:25:10 - Epoch: [66][50]	Time 0.695 (0.878)	Data 0.000 (0.039)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:34:10 - 1:25:42 - ============ Starting epoch 67 ... ============
INFO - 09/02/20 19:34:13 - 1:25:44 - Epoch: [67][0]	Time 2.329 (2.329)	Data 1.559 (1.559)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:34:55 - 1:26:26 - Epoch: [67][50]	Time 0.661 (0.878)	Data 0.000 (0.031)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:35:26 - 1:26:58 - ============ Starting epoch 68 ... ============
INFO - 09/02/20 19:35:29 - 1:27:00 - Epoch: [68][0]	Time 2.803 (2.803)	Data 1.976 (1.976)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:36:11 - 1:27:42 - Epoch: [68][50]	Time 0.635 (0.876)	Data 0.000 (0.039)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:36:43 - 1:28:14 - ============ Starting epoch 69 ... ============
INFO - 09/02/20 19:36:46 - 1:28:17 - Epoch: [69][0]	Time 2.675 (2.675)	Data 1.814 (1.814)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:37:27 - 1:28:58 - Epoch: [69][50]	Time 0.651 (0.867)	Data 0.000 (0.036)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:38:00 - 1:29:31 - ============ Starting epoch 70 ... ============
INFO - 09/02/20 19:38:03 - 1:29:34 - Epoch: [70][0]	Time 2.763 (2.763)	Data 1.665 (1.665)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:38:42 - 1:30:13 - Epoch: [70][50]	Time 0.691 (0.830)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:39:17 - 1:30:49 - ============ Starting epoch 71 ... ============
INFO - 09/02/20 19:39:20 - 1:30:52 - Epoch: [71][0]	Time 2.826 (2.826)	Data 1.692 (1.692)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:39:57 - 1:31:28 - Epoch: [71][50]	Time 0.690 (0.767)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:40:32 - 1:32:04 - ============ Starting epoch 72 ... ============
INFO - 09/02/20 19:40:35 - 1:32:07 - Epoch: [72][0]	Time 2.929 (2.929)	Data 1.747 (1.747)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:41:11 - 1:32:43 - Epoch: [72][50]	Time 0.699 (0.767)	Data 0.000 (0.035)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:41:50 - 1:33:21 - ============ Starting epoch 73 ... ============
INFO - 09/02/20 19:41:52 - 1:33:24 - Epoch: [73][0]	Time 2.443 (2.443)	Data 1.655 (1.655)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:42:26 - 1:33:57 - Epoch: [73][50]	Time 0.693 (0.705)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0057
INFO - 09/02/20 19:43:06 - 1:34:37 - ============ Starting epoch 74 ... ============
INFO - 09/02/20 19:43:09 - 1:34:40 - Epoch: [74][0]	Time 2.701 (2.701)	Data 1.976 (1.976)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:43:42 - 1:35:14 - Epoch: [74][50]	Time 0.635 (0.716)	Data 0.001 (0.039)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:44:23 - 1:35:54 - ============ Starting epoch 75 ... ============
INFO - 09/02/20 19:44:25 - 1:35:56 - Epoch: [75][0]	Time 2.333 (2.333)	Data 1.597 (1.597)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:44:59 - 1:36:30 - Epoch: [75][50]	Time 0.673 (0.707)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:45:39 - 1:37:10 - ============ Starting epoch 76 ... ============
INFO - 09/02/20 19:45:41 - 1:37:12 - Epoch: [76][0]	Time 2.301 (2.301)	Data 1.612 (1.612)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:46:15 - 1:37:46 - Epoch: [76][50]	Time 0.798 (0.704)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:46:55 - 1:38:26 - ============ Starting epoch 77 ... ============
INFO - 09/02/20 19:46:57 - 1:38:28 - Epoch: [77][0]	Time 2.360 (2.360)	Data 1.658 (1.658)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:47:32 - 1:39:03 - Epoch: [77][50]	Time 0.777 (0.727)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:48:11 - 1:39:42 - ============ Starting epoch 78 ... ============
INFO - 09/02/20 19:48:13 - 1:39:44 - Epoch: [78][0]	Time 2.307 (2.307)	Data 1.603 (1.603)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:48:49 - 1:40:20 - Epoch: [78][50]	Time 1.131 (0.754)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:49:26 - 1:40:58 - ============ Starting epoch 79 ... ============
INFO - 09/02/20 19:49:29 - 1:41:00 - Epoch: [79][0]	Time 2.674 (2.674)	Data 1.980 (1.980)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:50:08 - 1:41:40 - Epoch: [79][50]	Time 1.156 (0.824)	Data 0.000 (0.039)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:50:43 - 1:42:14 - ============ Starting epoch 80 ... ============
INFO - 09/02/20 19:50:46 - 1:42:17 - Epoch: [80][0]	Time 2.482 (2.482)	Data 1.719 (1.719)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:51:27 - 1:42:59 - Epoch: [80][50]	Time 1.192 (0.871)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:51:59 - 1:43:30 - ============ Starting epoch 81 ... ============
INFO - 09/02/20 19:52:02 - 1:43:33 - Epoch: [81][0]	Time 2.396 (2.396)	Data 1.663 (1.663)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:52:44 - 1:44:15 - Epoch: [81][50]	Time 0.687 (0.878)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:53:15 - 1:44:47 - ============ Starting epoch 82 ... ============
INFO - 09/02/20 19:53:18 - 1:44:49 - Epoch: [82][0]	Time 2.302 (2.302)	Data 1.653 (1.653)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:54:00 - 1:45:31 - Epoch: [82][50]	Time 0.644 (0.880)	Data 0.001 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0056
INFO - 09/02/20 19:54:32 - 1:46:03 - ============ Starting epoch 83 ... ============
INFO - 09/02/20 19:54:34 - 1:46:05 - Epoch: [83][0]	Time 2.348 (2.348)	Data 1.627 (1.627)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:55:16 - 1:46:47 - Epoch: [83][50]	Time 0.676 (0.873)	Data 0.000 (0.032)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:55:47 - 1:47:19 - ============ Starting epoch 84 ... ============
INFO - 09/02/20 19:55:50 - 1:47:21 - Epoch: [84][0]	Time 2.631 (2.631)	Data 1.954 (1.954)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:56:32 - 1:48:04 - Epoch: [84][50]	Time 0.654 (0.883)	Data 0.000 (0.039)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:57:04 - 1:48:35 - ============ Starting epoch 85 ... ============
INFO - 09/02/20 19:57:06 - 1:48:38 - Epoch: [85][0]	Time 2.561 (2.561)	Data 1.748 (1.748)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:57:48 - 1:49:20 - Epoch: [85][50]	Time 0.688 (0.874)	Data 0.000 (0.035)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:58:20 - 1:49:52 - ============ Starting epoch 86 ... ============
INFO - 09/02/20 19:58:23 - 1:49:54 - Epoch: [86][0]	Time 2.702 (2.702)	Data 1.876 (1.876)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:59:04 - 1:50:35 - Epoch: [86][50]	Time 0.634 (0.848)	Data 0.001 (0.037)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 19:59:37 - 1:51:09 - ============ Starting epoch 87 ... ============
INFO - 09/02/20 19:59:40 - 1:51:12 - Epoch: [87][0]	Time 2.868 (2.868)	Data 1.732 (1.732)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:00:19 - 1:51:50 - Epoch: [87][50]	Time 0.698 (0.811)	Data 0.000 (0.034)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:00:56 - 1:52:27 - ============ Starting epoch 88 ... ============
INFO - 09/02/20 20:00:58 - 1:52:30 - Epoch: [88][0]	Time 2.861 (2.861)	Data 1.676 (1.676)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:01:33 - 1:53:04 - Epoch: [88][50]	Time 0.684 (0.737)	Data 0.001 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:02:13 - 1:53:44 - ============ Starting epoch 89 ... ============
INFO - 09/02/20 20:02:15 - 1:53:46 - Epoch: [89][0]	Time 2.363 (2.363)	Data 1.663 (1.663)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:02:49 - 1:54:20 - Epoch: [89][50]	Time 0.683 (0.706)	Data 0.001 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:03:29 - 1:55:00 - ============ Starting epoch 90 ... ============
INFO - 09/02/20 20:03:32 - 1:55:03 - Epoch: [90][0]	Time 2.394 (2.394)	Data 1.685 (1.685)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:04:05 - 1:55:37 - Epoch: [90][50]	Time 0.686 (0.710)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0055
INFO - 09/02/20 20:04:45 - 1:56:17 - ============ Starting epoch 91 ... ============
INFO - 09/02/20 20:04:48 - 1:56:19 - Epoch: [91][0]	Time 2.374 (2.374)	Data 1.655 (1.655)	Loss 2.3026 (2.3026)	Lr: 0.0054
INFO - 09/02/20 20:05:21 - 1:56:52 - Epoch: [91][50]	Time 0.674 (0.704)	Data 0.000 (0.033)	Loss 2.3026 (2.3026)	Lr: 0.0054
INFO - 09/02/20 20:06:01 - 1:57:32 - ============ Starting epoch 92 ... ============
INFO - 09/02/20 20:06:04 - 1:57:35 - Epoch: [92][0]	Time 2.595 (2.595)	Data 1.838 (1.838)	Loss 2.3026 (2.3026)	Lr: 0.0054
INFO - 09/02/20 20:06:38 - 1:58:09 - Epoch: [92][50]	Time 0.629 (0.715)	Data 0.001 (0.036)	Loss 2.3026 (2.3026)	Lr: 0.0054
INFO - 09/02/20 20:07:18 - 1:58:49 - ============ Starting epoch 93 ... ============
INFO - 09/02/20 20:07:20 - 1:58:51 - Epoch: [93][0]	Time 2.272 (2.272)	Data 1.581 (1.581)	Loss 2.3026 (2.3026)	Lr: 0.0054
INFO - 09/02/20 20:07:54 - 1:59:25 - Epoch: [93][50]	Time 0.800 (0.715)	Data 0.000 (0.031)	Loss 2.3025 (2.3025)	Lr: 0.0054
INFO - 09/02/20 20:08:33 - 2:00:05 - ============ Starting epoch 94 ... ============
INFO - 09/02/20 20:08:36 - 2:00:07 - Epoch: [94][0]	Time 2.670 (2.670)	Data 1.955 (1.955)	Loss 2.3025 (2.3025)	Lr: 0.0054
INFO - 09/02/20 20:09:11 - 2:00:43 - Epoch: [94][50]	Time 0.876 (0.742)	Data 0.000 (0.039)	Loss 2.3024 (2.3024)	Lr: 0.0054
INFO - 09/02/20 20:09:50 - 2:01:21 - ============ Starting epoch 95 ... ============
INFO - 09/02/20 20:09:52 - 2:01:24 - Epoch: [95][0]	Time 2.222 (2.222)	Data 1.574 (1.574)	Loss 2.3020 (2.3020)	Lr: 0.0054
INFO - 09/02/20 20:10:31 - 2:02:02 - Epoch: [95][50]	Time 1.273 (0.807)	Data 0.001 (0.031)	Loss 2.2989 (2.3009)	Lr: 0.0054
INFO - 09/02/20 20:11:06 - 2:02:37 - ============ Starting epoch 96 ... ============
INFO - 09/02/20 20:11:08 - 2:02:40 - Epoch: [96][0]	Time 2.337 (2.337)	Data 1.600 (1.600)	Loss 2.2903 (2.2903)	Lr: 0.0054
INFO - 09/02/20 20:11:49 - 2:03:21 - Epoch: [96][50]	Time 1.116 (0.852)	Data 0.000 (0.032)	Loss 2.2731 (2.2837)	Lr: 0.0054
INFO - 09/02/20 20:12:22 - 2:03:53 - ============ Starting epoch 97 ... ============
INFO - 09/02/20 20:12:25 - 2:03:56 - Epoch: [97][0]	Time 2.602 (2.602)	Data 1.877 (1.877)	Loss 2.2675 (2.2675)	Lr: 0.0054
INFO - 09/02/20 20:13:07 - 2:04:38 - Epoch: [97][50]	Time 0.683 (0.889)	Data 0.000 (0.037)	Loss 2.2538 (2.2590)	Lr: 0.0054
INFO - 09/02/20 20:13:39 - 2:05:10 - ============ Starting epoch 98 ... ============
INFO - 09/02/20 20:13:41 - 2:05:12 - Epoch: [98][0]	Time 2.239 (2.239)	Data 1.574 (1.574)	Loss 2.2499 (2.2499)	Lr: 0.0053
INFO - 09/02/20 20:14:23 - 2:05:54 - Epoch: [98][50]	Time 0.672 (0.874)	Data 0.000 (0.031)	Loss 2.2282 (2.2404)	Lr: 0.0053
INFO - 09/02/20 20:14:54 - 2:06:26 - ============ Starting epoch 99 ... ============
INFO - 09/02/20 20:14:57 - 2:06:28 - Epoch: [99][0]	Time 2.332 (2.332)	Data 1.563 (1.563)	Loss 2.2368 (2.2368)	Lr: 0.0053
INFO - 09/02/20 20:15:39 - 2:07:10 - Epoch: [99][50]	Time 0.702 (0.878)	Data 0.001 (0.031)	Loss 2.2271 (2.2316)	Lr: 0.0053
INFO - 09/02/20 20:16:11 - 2:07:42 - ============ Starting epoch 100 ... ============
INFO - 09/02/20 20:16:13 - 2:07:44 - Epoch: [100][0]	Time 2.357 (2.357)	Data 1.709 (1.709)	Loss 2.2218 (2.2218)	Lr: 0.0053
INFO - 09/02/20 20:16:56 - 2:08:27 - Epoch: [100][50]	Time 0.663 (0.880)	Data 0.000 (0.034)	Loss 2.2117 (2.2266)	Lr: 0.0053
INFO - 09/02/20 20:17:28 - 2:08:59 - ============ Starting epoch 101 ... ============
INFO - 09/02/20 20:17:30 - 2:09:02 - Epoch: [101][0]	Time 2.774 (2.774)	Data 1.978 (1.978)	Loss 2.2188 (2.2188)	Lr: 0.0053
INFO - 09/02/20 20:18:12 - 2:09:43 - Epoch: [101][50]	Time 0.652 (0.873)	Data 0.000 (0.039)	Loss 2.2075 (2.2201)	Lr: 0.0053
INFO - 09/02/20 20:18:44 - 2:10:15 - ============ Starting epoch 102 ... ============
INFO - 09/02/20 20:18:47 - 2:10:18 - Epoch: [102][0]	Time 2.699 (2.699)	Data 1.844 (1.844)	Loss 2.2165 (2.2165)	Lr: 0.0053
INFO - 09/02/20 20:19:28 - 2:11:00 - Epoch: [102][50]	Time 0.693 (0.867)	Data 0.000 (0.036)	Loss 2.2215 (2.2138)	Lr: 0.0053
INFO - 09/02/20 20:20:01 - 2:11:32 - ============ Starting epoch 103 ... ============
INFO - 09/02/20 20:20:04 - 2:11:35 - Epoch: [103][0]	Time 2.830 (2.830)	Data 1.644 (1.644)	Loss 2.2188 (2.2188)	Lr: 0.0053
INFO - 09/02/20 20:20:43 - 2:12:14 - Epoch: [103][50]	Time 0.690 (0.822)	Data 0.000 (0.032)	Loss 2.1995 (2.2105)	Lr: 0.0053
INFO - 09/02/20 20:21:19 - 2:12:50 - ============ Starting epoch 104 ... ============
INFO - 09/02/20 20:21:22 - 2:12:53 - Epoch: [104][0]	Time 2.908 (2.908)	Data 1.707 (1.707)	Loss 2.2024 (2.2024)	Lr: 0.0053
INFO - 09/02/20 20:21:58 - 2:13:29 - Epoch: [104][50]	Time 0.693 (0.768)	Data 0.000 (0.034)	Loss 2.1977 (2.2030)	Lr: 0.0053
INFO - 09/02/20 20:22:37 - 2:14:08 - ============ Starting epoch 105 ... ============
INFO - 09/02/20 20:22:40 - 2:14:11 - Epoch: [105][0]	Time 2.462 (2.462)	Data 1.815 (1.815)	Loss 2.2099 (2.2099)	Lr: 0.0052
INFO - 09/02/20 20:23:14 - 2:14:45 - Epoch: [105][50]	Time 0.683 (0.716)	Data 0.000 (0.036)	Loss 2.2068 (2.2017)	Lr: 0.0052
INFO - 09/02/20 20:23:54 - 2:15:25 - ============ Starting epoch 106 ... ============
INFO - 09/02/20 20:23:56 - 2:15:27 - Epoch: [106][0]	Time 2.371 (2.371)	Data 1.623 (1.623)	Loss 2.1974 (2.1974)	Lr: 0.0052
INFO - 09/02/20 20:24:30 - 2:16:01 - Epoch: [106][50]	Time 0.633 (0.706)	Data 0.000 (0.032)	Loss 2.2039 (2.2022)	Lr: 0.0052
INFO - 09/02/20 20:25:10 - 2:16:41 - ============ Starting epoch 107 ... ============
INFO - 09/02/20 20:25:12 - 2:16:43 - Epoch: [107][0]	Time 2.317 (2.317)	Data 1.631 (1.631)	Loss 2.1940 (2.1940)	Lr: 0.0052
INFO - 09/02/20 20:25:46 - 2:17:17 - Epoch: [107][50]	Time 0.638 (0.711)	Data 0.000 (0.032)	Loss 2.1992 (2.1948)	Lr: 0.0052
INFO - 09/02/20 20:26:26 - 2:17:58 - ============ Starting epoch 108 ... ============
INFO - 09/02/20 20:26:29 - 2:18:00 - Epoch: [108][0]	Time 2.361 (2.361)	Data 1.628 (1.628)	Loss 2.1930 (2.1930)	Lr: 0.0052
INFO - 09/02/20 20:27:03 - 2:18:34 - Epoch: [108][50]	Time 0.799 (0.723)	Data 0.000 (0.032)	Loss 2.1812 (2.1954)	Lr: 0.0052
INFO - 09/02/20 20:27:42 - 2:19:14 - ============ Starting epoch 109 ... ============
INFO - 09/02/20 20:27:45 - 2:19:16 - Epoch: [109][0]	Time 2.424 (2.424)	Data 1.685 (1.685)	Loss 2.1901 (2.1901)	Lr: 0.0052
INFO - 09/02/20 20:28:20 - 2:19:51 - Epoch: [109][50]	Time 0.822 (0.736)	Data 0.000 (0.033)	Loss 2.1756 (2.1932)	Lr: 0.0052
INFO - 09/02/20 20:28:59 - 2:20:30 - ============ Starting epoch 110 ... ============
INFO - 09/02/20 20:29:01 - 2:20:33 - Epoch: [110][0]	Time 2.305 (2.305)	Data 1.648 (1.648)	Loss 2.1999 (2.1999)	Lr: 0.0052
INFO - 09/02/20 20:29:39 - 2:21:11 - Epoch: [110][50]	Time 1.136 (0.791)	Data 0.000 (0.033)	Loss 2.1766 (2.1890)	Lr: 0.0052
INFO - 09/02/20 20:30:15 - 2:21:47 - ============ Starting epoch 111 ... ============
INFO - 09/02/20 20:30:18 - 2:21:49 - Epoch: [111][0]	Time 2.536 (2.536)	Data 1.790 (1.790)	Loss 2.2036 (2.2036)	Lr: 0.0052
INFO - 09/02/20 20:30:56 - 2:22:27 - Epoch: [111][50]	Time 1.133 (0.787)	Data 0.000 (0.035)	Loss 2.1825 (2.1908)	Lr: 0.0051
INFO - 09/02/20 20:31:32 - 2:23:03 - ============ Starting epoch 112 ... ============
INFO - 09/02/20 20:31:34 - 2:23:05 - Epoch: [112][0]	Time 2.388 (2.388)	Data 1.683 (1.683)	Loss 2.1945 (2.1945)	Lr: 0.0051
INFO - 09/02/20 20:32:15 - 2:23:47 - Epoch: [112][50]	Time 1.154 (0.852)	Data 0.000 (0.033)	Loss 2.1876 (2.1916)	Lr: 0.0051
INFO - 09/02/20 20:32:49 - 2:24:20 - ============ Starting epoch 113 ... ============
INFO - 09/02/20 20:32:51 - 2:24:23 - Epoch: [113][0]	Time 2.477 (2.477)	Data 1.770 (1.770)	Loss 2.1816 (2.1816)	Lr: 0.0051
INFO - 09/02/20 20:33:34 - 2:25:05 - Epoch: [113][50]	Time 0.684 (0.884)	Data 0.000 (0.035)	Loss 2.1955 (2.1845)	Lr: 0.0051
INFO - 09/02/20 20:34:05 - 2:25:36 - ============ Starting epoch 114 ... ============
INFO - 09/02/20 20:34:07 - 2:25:39 - Epoch: [114][0]	Time 2.278 (2.278)	Data 1.578 (1.578)	Loss 2.1969 (2.1969)	Lr: 0.0051
INFO - 09/02/20 20:34:50 - 2:26:21 - Epoch: [114][50]	Time 0.691 (0.875)	Data 0.000 (0.031)	Loss 2.1761 (2.1906)	Lr: 0.0051
INFO - 09/02/20 20:35:22 - 2:26:53 - ============ Starting epoch 115 ... ============
INFO - 09/02/20 20:35:24 - 2:26:55 - Epoch: [115][0]	Time 2.467 (2.467)	Data 1.742 (1.742)	Loss 2.1687 (2.1687)	Lr: 0.0051
INFO - 09/02/20 20:36:07 - 2:27:38 - Epoch: [115][50]	Time 0.668 (0.887)	Data 0.000 (0.034)	Loss 2.1699 (2.1829)	Lr: 0.0051
INFO - 09/02/20 20:36:38 - 2:28:10 - ============ Starting epoch 116 ... ============
INFO - 09/02/20 20:36:41 - 2:28:12 - Epoch: [116][0]	Time 2.624 (2.624)	Data 1.968 (1.968)	Loss 2.1664 (2.1664)	Lr: 0.0051
INFO - 09/02/20 20:37:23 - 2:28:54 - Epoch: [116][50]	Time 0.647 (0.879)	Data 0.000 (0.039)	Loss 2.1906 (2.1859)	Lr: 0.0051
INFO - 09/02/20 20:37:54 - 2:29:26 - ============ Starting epoch 117 ... ============
INFO - 09/02/20 20:37:57 - 2:29:28 - Epoch: [117][0]	Time 2.732 (2.732)	Data 1.893 (1.893)	Loss 2.2051 (2.2051)	Lr: 0.0051
INFO - 09/02/20 20:38:39 - 2:30:11 - Epoch: [117][50]	Time 0.688 (0.882)	Data 0.000 (0.037)	Loss 2.1786 (2.1823)	Lr: 0.0050
INFO - 09/02/20 20:39:12 - 2:30:43 - ============ Starting epoch 118 ... ============
INFO - 09/02/20 20:39:15 - 2:30:46 - Epoch: [118][0]	Time 2.869 (2.869)	Data 1.884 (1.884)	Loss 2.1622 (2.1622)	Lr: 0.0050
INFO - 09/02/20 20:39:55 - 2:31:27 - Epoch: [118][50]	Time 0.687 (0.854)	Data 0.000 (0.037)	Loss 2.2026 (2.1799)	Lr: 0.0050
INFO - 09/02/20 20:40:29 - 2:32:01 - ============ Starting epoch 119 ... ============
INFO - 09/02/20 20:40:32 - 2:32:04 - Epoch: [119][0]	Time 2.914 (2.914)	Data 1.733 (1.733)	Loss 2.1805 (2.1805)	Lr: 0.0050
INFO - 09/02/20 20:41:10 - 2:32:41 - Epoch: [119][50]	Time 0.686 (0.791)	Data 0.000 (0.034)	Loss 2.1666 (2.1794)	Lr: 0.0050
INFO - 09/02/20 20:41:48 - 2:33:19 - ============ Starting epoch 120 ... ============
INFO - 09/02/20 20:41:50 - 2:33:22 - Epoch: [120][0]	Time 2.916 (2.916)	Data 1.678 (1.678)	Loss 2.1627 (2.1627)	Lr: 0.0050
INFO - 09/02/20 20:42:25 - 2:33:57 - Epoch: [120][50]	Time 0.695 (0.741)	Data 0.000 (0.033)	Loss 2.1789 (2.1728)	Lr: 0.0050
INFO - 09/02/20 20:43:04 - 2:34:35 - ============ Starting epoch 121 ... ============
INFO - 09/02/20 20:43:07 - 2:34:38 - Epoch: [121][0]	Time 2.678 (2.678)	Data 1.810 (1.810)	Loss 2.1912 (2.1912)	Lr: 0.0050
INFO - 09/02/20 20:43:40 - 2:35:12 - Epoch: [121][50]	Time 0.684 (0.713)	Data 0.001 (0.036)	Loss 2.1773 (2.1780)	Lr: 0.0050
INFO - 09/02/20 20:44:20 - 2:35:51 - ============ Starting epoch 122 ... ============
INFO - 09/02/20 20:44:22 - 2:35:54 - Epoch: [122][0]	Time 2.265 (2.265)	Data 1.620 (1.620)	Loss 2.1574 (2.1574)	Lr: 0.0050
INFO - 09/02/20 20:44:56 - 2:36:28 - Epoch: [122][50]	Time 0.694 (0.711)	Data 0.000 (0.032)	Loss 2.1860 (2.1797)	Lr: 0.0050
INFO - 09/02/20 20:45:37 - 2:37:08 - ============ Starting epoch 123 ... ============
INFO - 09/02/20 20:45:39 - 2:37:11 - Epoch: [123][0]	Time 2.660 (2.660)	Data 1.948 (1.948)	Loss 2.1885 (2.1885)	Lr: 0.0050
INFO - 09/02/20 20:46:13 - 2:37:45 - Epoch: [123][50]	Time 0.698 (0.717)	Data 0.001 (0.038)	Loss 2.1757 (2.1771)	Lr: 0.0049
INFO - 09/02/20 20:46:53 - 2:38:24 - ============ Starting epoch 124 ... ============
INFO - 09/02/20 20:46:56 - 2:38:27 - Epoch: [124][0]	Time 2.345 (2.345)	Data 1.616 (1.616)	Loss 2.1778 (2.1778)	Lr: 0.0049
INFO - 09/02/20 20:47:29 - 2:39:00 - Epoch: [124][50]	Time 0.628 (0.703)	Data 0.001 (0.032)	Loss 2.1701 (2.1782)	Lr: 0.0049
INFO - 09/02/20 20:48:09 - 2:39:41 - ============ Starting epoch 125 ... ============
INFO - 09/02/20 20:48:12 - 2:39:43 - Epoch: [125][0]	Time 2.454 (2.454)	Data 1.747 (1.747)	Loss 2.1694 (2.1694)	Lr: 0.0049
INFO - 09/02/20 20:48:46 - 2:40:18 - Epoch: [125][50]	Time 0.817 (0.725)	Data 0.000 (0.034)	Loss 2.1666 (2.1764)	Lr: 0.0049
INFO - 09/02/20 20:49:26 - 2:40:58 - ============ Starting epoch 126 ... ============
INFO - 09/02/20 20:49:29 - 2:41:00 - Epoch: [126][0]	Time 2.599 (2.599)	Data 1.830 (1.830)	Loss 2.1612 (2.1612)	Lr: 0.0049
INFO - 09/02/20 20:50:04 - 2:41:35 - Epoch: [126][50]	Time 0.767 (0.740)	Data 0.000 (0.036)	Loss 2.1655 (2.1717)	Lr: 0.0049
INFO - 09/02/20 20:50:43 - 2:42:14 - ============ Starting epoch 127 ... ============
INFO - 09/02/20 20:50:45 - 2:42:16 - Epoch: [127][0]	Time 2.497 (2.497)	Data 1.739 (1.739)	Loss 2.1747 (2.1747)	Lr: 0.0049
INFO - 09/02/20 20:51:24 - 2:42:55 - Epoch: [127][50]	Time 1.168 (0.806)	Data 0.001 (0.034)	Loss 2.1640 (2.1696)	Lr: 0.0049
INFO - 09/02/20 20:52:00 - 2:43:31 - ============ Starting epoch 128 ... ============
INFO - 09/02/20 20:52:02 - 2:43:33 - Epoch: [128][0]	Time 2.449 (2.449)	Data 1.734 (1.734)	Loss 2.1743 (2.1743)	Lr: 0.0049
INFO - 09/02/20 20:52:44 - 2:44:15 - Epoch: [128][50]	Time 1.181 (0.872)	Data 0.000 (0.034)	Loss 2.1750 (2.1768)	Lr: 0.0049
INFO - 09/02/20 20:53:16 - 2:44:47 - ============ Starting epoch 129 ... ============
INFO - 09/02/20 20:53:18 - 2:44:49 - Epoch: [129][0]	Time 2.315 (2.315)	Data 1.561 (1.561)	Loss 2.1800 (2.1800)	Lr: 0.0049
INFO - 09/02/20 20:54:00 - 2:45:32 - Epoch: [129][50]	Time 0.657 (0.875)	Data 0.000 (0.031)	Loss 2.1781 (2.1699)	Lr: 0.0048
INFO - 09/02/20 20:54:32 - 2:46:03 - ============ Starting epoch 130 ... ============
INFO - 09/02/20 20:54:34 - 2:46:06 - Epoch: [130][0]	Time 2.321 (2.321)	Data 1.648 (1.648)	Loss 2.1543 (2.1543)	Lr: 0.0048
INFO - 09/02/20 20:55:17 - 2:46:48 - Epoch: [130][50]	Time 0.699 (0.883)	Data 0.000 (0.033)	Loss 2.1474 (2.1678)	Lr: 0.0048
INFO - 09/02/20 20:55:49 - 2:47:20 - ============ Starting epoch 131 ... ============
INFO - 09/02/20 20:55:51 - 2:47:23 - Epoch: [131][0]	Time 2.672 (2.672)	Data 1.924 (1.924)	Loss 2.1772 (2.1772)	Lr: 0.0048
INFO - 09/02/20 20:56:34 - 2:48:05 - Epoch: [131][50]	Time 0.688 (0.882)	Data 0.000 (0.038)	Loss 2.1547 (2.1680)	Lr: 0.0048
INFO - 09/02/20 20:57:05 - 2:48:36 - ============ Starting epoch 132 ... ============
INFO - 09/02/20 20:57:07 - 2:48:39 - Epoch: [132][0]	Time 2.493 (2.493)	Data 1.778 (1.778)	Loss 2.1574 (2.1574)	Lr: 0.0048
INFO - 09/02/20 20:57:50 - 2:49:21 - Epoch: [132][50]	Time 0.701 (0.885)	Data 0.000 (0.035)	Loss 2.1742 (2.1638)	Lr: 0.0048
INFO - 09/02/20 20:58:22 - 2:49:53 - ============ Starting epoch 133 ... ============
INFO - 09/02/20 20:58:24 - 2:49:55 - Epoch: [133][0]	Time 2.550 (2.550)	Data 1.718 (1.718)	Loss 2.1758 (2.1758)	Lr: 0.0048
INFO - 09/02/20 20:59:07 - 2:50:38 - Epoch: [133][50]	Time 0.680 (0.881)	Data 0.000 (0.034)	Loss 2.1765 (2.1670)	Lr: 0.0048
INFO - 09/02/20 20:59:38 - 2:51:10 - ============ Starting epoch 134 ... ============
INFO - 09/02/20 20:59:41 - 2:51:12 - Epoch: [134][0]	Time 2.673 (2.673)	Data 1.848 (1.848)	Loss 2.1677 (2.1677)	Lr: 0.0048
INFO - 09/02/20 21:00:22 - 2:51:53 - Epoch: [134][50]	Time 0.641 (0.860)	Data 0.000 (0.037)	Loss 2.1695 (2.1687)	Lr: 0.0048
INFO - 09/02/20 21:00:55 - 2:52:26 - ============ Starting epoch 135 ... ============
INFO - 09/02/20 21:00:58 - 2:52:29 - Epoch: [135][0]	Time 2.924 (2.924)	Data 1.743 (1.743)	Loss 2.1764 (2.1764)	Lr: 0.0047
INFO - 09/02/20 21:01:38 - 2:53:09 - Epoch: [135][50]	Time 0.632 (0.842)	Data 0.000 (0.034)	Loss 2.1636 (2.1654)	Lr: 0.0047
INFO - 09/02/20 21:02:13 - 2:53:44 - ============ Starting epoch 136 ... ============
INFO - 09/02/20 21:02:16 - 2:53:47 - Epoch: [136][0]	Time 2.968 (2.968)	Data 1.778 (1.778)	Loss 2.1679 (2.1679)	Lr: 0.0047
INFO - 09/02/20 21:02:53 - 2:54:24 - Epoch: [136][50]	Time 0.691 (0.787)	Data 0.000 (0.035)	Loss 2.1616 (2.1671)	Lr: 0.0047
INFO - 09/02/20 21:03:30 - 2:55:02 - ============ Starting epoch 137 ... ============
INFO - 09/02/20 21:03:33 - 2:55:05 - Epoch: [137][0]	Time 2.926 (2.926)	Data 1.744 (1.744)	Loss 2.1532 (2.1532)	Lr: 0.0047
INFO - 09/02/20 21:04:08 - 2:55:39 - Epoch: [137][50]	Time 0.643 (0.736)	Data 0.000 (0.034)	Loss 2.1690 (2.1649)	Lr: 0.0047
INFO - 09/02/20 21:04:49 - 2:56:20 - ============ Starting epoch 138 ... ============
INFO - 09/02/20 21:04:51 - 2:56:22 - Epoch: [138][0]	Time 2.416 (2.416)	Data 1.730 (1.730)	Loss 2.1743 (2.1743)	Lr: 0.0047
INFO - 09/02/20 21:05:25 - 2:56:56 - Epoch: [138][50]	Time 0.661 (0.713)	Data 0.000 (0.034)	Loss 2.1684 (2.1630)	Lr: 0.0047
INFO - 09/02/20 21:06:05 - 2:57:36 - ============ Starting epoch 139 ... ============
INFO - 09/02/20 21:06:07 - 2:57:39 - Epoch: [139][0]	Time 2.408 (2.408)	Data 1.657 (1.657)	Loss 2.1585 (2.1585)	Lr: 0.0047
INFO - 09/02/20 21:06:41 - 2:58:12 - Epoch: [139][50]	Time 0.677 (0.708)	Data 0.000 (0.033)	Loss 2.1628 (2.1630)	Lr: 0.0047
INFO - 09/02/20 21:07:21 - 2:58:53 - ============ Starting epoch 140 ... ============
INFO - 09/02/20 21:07:24 - 2:58:55 - Epoch: [140][0]	Time 2.339 (2.339)	Data 1.656 (1.656)	Loss 2.1738 (2.1738)	Lr: 0.0046
INFO - 09/02/20 21:07:58 - 2:59:29 - Epoch: [140][50]	Time 0.780 (0.715)	Data 0.000 (0.033)	Loss 2.1473 (2.1599)	Lr: 0.0046
INFO - 09/02/20 21:08:38 - 3:00:09 - ============ Starting epoch 141 ... ============
INFO - 09/02/20 21:08:41 - 3:00:12 - Epoch: [141][0]	Time 2.463 (2.463)	Data 1.753 (1.753)	Loss 2.1620 (2.1620)	Lr: 0.0046
INFO - 09/02/20 21:09:14 - 3:00:46 - Epoch: [141][50]	Time 0.771 (0.709)	Data 0.000 (0.035)	Loss 2.1600 (2.1632)	Lr: 0.0046
INFO - 09/02/20 21:09:54 - 3:01:26 - ============ Starting epoch 142 ... ============
INFO - 09/02/20 21:09:57 - 3:01:28 - Epoch: [142][0]	Time 2.256 (2.256)	Data 1.583 (1.583)	Loss 2.1539 (2.1539)	Lr: 0.0046
INFO - 09/02/20 21:10:31 - 3:02:02 - Epoch: [142][50]	Time 0.779 (0.723)	Data 0.000 (0.031)	Loss 2.1682 (2.1586)	Lr: 0.0046
INFO - 09/02/20 21:11:11 - 3:02:42 - ============ Starting epoch 143 ... ============
INFO - 09/02/20 21:11:14 - 3:02:45 - Epoch: [143][0]	Time 2.715 (2.715)	Data 1.971 (1.971)	Loss 2.1605 (2.1605)	Lr: 0.0046
INFO - 09/02/20 21:11:50 - 3:03:21 - Epoch: [143][50]	Time 1.147 (0.764)	Data 0.000 (0.039)	Loss 2.1459 (2.1637)	Lr: 0.0046
INFO - 09/02/20 21:12:27 - 3:03:59 - ============ Starting epoch 144 ... ============
INFO - 09/02/20 21:12:30 - 3:04:01 - Epoch: [144][0]	Time 2.330 (2.330)	Data 1.674 (1.674)	Loss 2.1595 (2.1595)	Lr: 0.0046
INFO - 09/02/20 21:13:10 - 3:04:42 - Epoch: [144][50]	Time 1.134 (0.843)	Data 0.000 (0.033)	Loss 2.1658 (2.1604)	Lr: 0.0046
INFO - 09/02/20 21:13:43 - 3:05:15 - ============ Starting epoch 145 ... ============
INFO - 09/02/20 21:13:46 - 3:05:17 - Epoch: [145][0]	Time 2.365 (2.365)	Data 1.641 (1.641)	Loss 2.1595 (2.1595)	Lr: 0.0046
INFO - 09/02/20 21:14:29 - 3:06:00 - Epoch: [145][50]	Time 0.689 (0.886)	Data 0.000 (0.032)	Loss 2.1413 (2.1608)	Lr: 0.0045
INFO - 09/02/20 21:15:00 - 3:06:31 - ============ Starting epoch 146 ... ============
INFO - 09/02/20 21:15:02 - 3:06:34 - Epoch: [146][0]	Time 2.358 (2.358)	Data 1.622 (1.622)	Loss 2.1624 (2.1624)	Lr: 0.0045
INFO - 09/02/20 21:15:45 - 3:07:16 - Epoch: [146][50]	Time 0.677 (0.877)	Data 0.000 (0.032)	Loss 2.1527 (2.1603)	Lr: 0.0045
INFO - 09/02/20 21:16:16 - 3:07:47 - ============ Starting epoch 147 ... ============
INFO - 09/02/20 21:16:19 - 3:07:50 - Epoch: [147][0]	Time 2.703 (2.703)	Data 2.001 (2.001)	Loss 2.1685 (2.1685)	Lr: 0.0045
INFO - 09/02/20 21:17:01 - 3:08:33 - Epoch: [147][50]	Time 0.730 (0.889)	Data 0.000 (0.039)	Loss 2.1626 (2.1634)	Lr: 0.0045
INFO - 09/02/20 21:17:33 - 3:09:04 - ============ Starting epoch 148 ... ============
INFO - 09/02/20 21:17:36 - 3:09:07 - Epoch: [148][0]	Time 2.802 (2.802)	Data 1.985 (1.985)	Loss 2.1641 (2.1641)	Lr: 0.0045
INFO - 09/02/20 21:18:19 - 3:09:50 - Epoch: [148][50]	Time 0.666 (0.889)	Data 0.000 (0.039)	Loss 2.1651 (2.1532)	Lr: 0.0045
INFO - 09/02/20 21:18:50 - 3:10:22 - ============ Starting epoch 149 ... ============
INFO - 09/02/20 21:18:53 - 3:10:24 - Epoch: [149][0]	Time 2.833 (2.833)	Data 2.054 (2.054)	Loss 2.1713 (2.1713)	Lr: 0.0045
INFO - 09/02/20 21:19:34 - 3:11:06 - Epoch: [149][50]	Time 0.689 (0.865)	Data 0.001 (0.041)	Loss 2.1419 (2.1600)	Lr: 0.0045
INFO - 09/02/20 21:20:07 - 3:11:38 - ============ Starting epoch 150 ... ============
INFO - 09/02/20 21:20:10 - 3:11:41 - Epoch: [150][0]	Time 2.942 (2.942)	Data 1.796 (1.796)	Loss 2.1374 (2.1374)	Lr: 0.0045
INFO - 09/02/20 21:20:50 - 3:12:22 - Epoch: [150][50]	Time 0.646 (0.844)	Data 0.000 (0.036)	Loss 2.1577 (2.1596)	Lr: 0.0044
INFO - 09/02/20 21:21:26 - 3:12:57 - ============ Starting epoch 151 ... ============
INFO - 09/02/20 21:21:29 - 3:13:00 - Epoch: [151][0]	Time 2.879 (2.879)	Data 1.712 (1.712)	Loss 2.1559 (2.1559)	Lr: 0.0044
INFO - 09/02/20 21:22:05 - 3:13:37 - Epoch: [151][50]	Time 0.693 (0.768)	Data 0.000 (0.034)	Loss 2.1671 (2.1602)	Lr: 0.0044
INFO - 09/02/20 21:22:44 - 3:14:16 - ============ Starting epoch 152 ... ============
INFO - 09/02/20 21:22:47 - 3:14:18 - Epoch: [152][0]	Time 2.458 (2.458)	Data 1.743 (1.743)	Loss 2.1603 (2.1603)	Lr: 0.0044
INFO - 09/02/20 21:23:21 - 3:14:52 - Epoch: [152][50]	Time 0.689 (0.712)	Data 0.000 (0.034)	Loss 2.1592 (2.1582)	Lr: 0.0044
INFO - 09/02/20 21:24:01 - 3:15:32 - ============ Starting epoch 153 ... ============
INFO - 09/02/20 21:24:04 - 3:15:35 - Epoch: [153][0]	Time 2.574 (2.574)	Data 1.886 (1.886)	Loss 2.1467 (2.1467)	Lr: 0.0044
INFO - 09/02/20 21:24:38 - 3:16:09 - Epoch: [153][50]	Time 0.660 (0.715)	Data 0.000 (0.037)	Loss 2.1360 (2.1510)	Lr: 0.0044
INFO - 09/02/20 21:25:18 - 3:16:49 - ============ Starting epoch 154 ... ============
INFO - 09/02/20 21:25:20 - 3:16:51 - Epoch: [154][0]	Time 2.337 (2.337)	Data 1.629 (1.629)	Loss 2.1396 (2.1396)	Lr: 0.0044
INFO - 09/02/20 21:25:54 - 3:17:25 - Epoch: [154][50]	Time 0.689 (0.707)	Data 0.000 (0.032)	Loss 2.1361 (2.1575)	Lr: 0.0044
INFO - 09/02/20 21:26:34 - 3:18:05 - ============ Starting epoch 155 ... ============
INFO - 09/02/20 21:26:36 - 3:18:08 - Epoch: [155][0]	Time 2.389 (2.389)	Data 1.709 (1.709)	Loss 2.1494 (2.1494)	Lr: 0.0044
INFO - 09/02/20 21:27:10 - 3:18:42 - Epoch: [155][50]	Time 0.771 (0.717)	Data 0.001 (0.034)	Loss 2.1723 (2.1593)	Lr: 0.0043
INFO - 09/02/20 21:27:50 - 3:19:22 - ============ Starting epoch 156 ... ============
INFO - 09/02/20 21:27:53 - 3:19:24 - Epoch: [156][0]	Time 2.349 (2.349)	Data 1.622 (1.622)	Loss 2.1698 (2.1698)	Lr: 0.0043
INFO - 09/02/20 21:28:28 - 3:19:59 - Epoch: [156][50]	Time 0.803 (0.729)	Data 0.001 (0.032)	Loss 2.1469 (2.1582)	Lr: 0.0043
INFO - 09/02/20 21:29:06 - 3:20:38 - ============ Starting epoch 157 ... ============
INFO - 09/02/20 21:29:09 - 3:20:40 - Epoch: [157][0]	Time 2.433 (2.433)	Data 1.767 (1.767)	Loss 2.1515 (2.1515)	Lr: 0.0043
INFO - 09/02/20 21:29:46 - 3:21:17 - Epoch: [157][50]	Time 1.189 (0.777)	Data 0.000 (0.035)	Loss 2.1745 (2.1577)	Lr: 0.0043
INFO - 09/02/20 21:30:23 - 3:21:54 - ============ Starting epoch 158 ... ============
INFO - 09/02/20 21:30:25 - 3:21:57 - Epoch: [158][0]	Time 2.320 (2.320)	Data 1.647 (1.647)	Loss 2.1353 (2.1353)	Lr: 0.0043
INFO - 09/02/20 21:31:06 - 3:22:37 - Epoch: [158][50]	Time 1.212 (0.838)	Data 0.000 (0.033)	Loss 2.1602 (2.1527)	Lr: 0.0043
INFO - 09/02/20 21:31:39 - 3:23:10 - ============ Starting epoch 159 ... ============
INFO - 09/02/20 21:31:42 - 3:23:13 - Epoch: [159][0]	Time 2.346 (2.346)	Data 1.629 (1.629)	Loss 2.1493 (2.1493)	Lr: 0.0043
INFO - 09/02/20 21:32:24 - 3:23:55 - Epoch: [159][50]	Time 0.629 (0.873)	Data 0.000 (0.032)	Loss 2.1361 (2.1576)	Lr: 0.0043
INFO - 09/02/20 21:32:55 - 3:24:27 - ============ Starting epoch 160 ... ============
INFO - 09/02/20 21:32:58 - 3:24:29 - Epoch: [160][0]	Time 2.491 (2.491)	Data 1.791 (1.791)	Loss 2.1476 (2.1476)	Lr: 0.0043
INFO - 09/02/20 21:33:40 - 3:25:12 - Epoch: [160][50]	Time 0.699 (0.885)	Data 0.000 (0.035)	Loss 2.1335 (2.1527)	Lr: 0.0042
INFO - 09/02/20 21:34:12 - 3:25:43 - ============ Starting epoch 161 ... ============
INFO - 09/02/20 21:34:15 - 3:25:46 - Epoch: [161][0]	Time 2.524 (2.524)	Data 1.797 (1.797)	Loss 2.1445 (2.1445)	Lr: 0.0042
INFO - 09/02/20 21:34:57 - 3:26:28 - Epoch: [161][50]	Time 0.679 (0.881)	Data 0.000 (0.035)	Loss 2.1559 (2.1566)	Lr: 0.0042
INFO - 09/02/20 21:35:28 - 3:26:59 - ============ Starting epoch 162 ... ============
INFO - 09/02/20 21:35:31 - 3:27:02 - Epoch: [162][0]	Time 2.404 (2.404)	Data 1.690 (1.690)	Loss 2.1662 (2.1662)	Lr: 0.0042
INFO - 09/02/20 21:36:13 - 3:27:45 - Epoch: [162][50]	Time 0.662 (0.885)	Data 0.000 (0.033)	Loss 2.1415 (2.1586)	Lr: 0.0042
INFO - 09/02/20 21:36:45 - 3:28:17 - ============ Starting epoch 163 ... ============
INFO - 09/02/20 21:36:48 - 3:28:19 - Epoch: [163][0]	Time 2.753 (2.753)	Data 2.046 (2.046)	Loss 2.1436 (2.1436)	Lr: 0.0042
INFO - 09/02/20 21:37:31 - 3:29:02 - Epoch: [163][50]	Time 0.690 (0.890)	Data 0.000 (0.041)	Loss 2.1644 (2.1555)	Lr: 0.0042
INFO - 09/02/20 21:38:02 - 3:29:33 - ============ Starting epoch 164 ... ============
INFO - 09/02/20 21:38:05 - 3:29:36 - Epoch: [164][0]	Time 2.699 (2.699)	Data 1.916 (1.916)	Loss 2.1526 (2.1526)	Lr: 0.0042
INFO - 09/02/20 21:38:47 - 3:30:18 - Epoch: [164][50]	Time 0.708 (0.871)	Data 0.000 (0.038)	Loss 2.1539 (2.1545)	Lr: 0.0042
INFO - 09/02/20 21:39:19 - 3:30:50 - ============ Starting epoch 165 ... ============
INFO - 09/02/20 21:39:22 - 3:30:53 - Epoch: [165][0]	Time 2.595 (2.595)	Data 1.733 (1.733)	Loss 2.1233 (2.1233)	Lr: 0.0042
INFO - 09/02/20 21:40:03 - 3:31:34 - Epoch: [165][50]	Time 0.690 (0.859)	Data 0.000 (0.034)	Loss 2.1496 (2.1549)	Lr: 0.0041
INFO - 09/02/20 21:40:37 - 3:32:09 - ============ Starting epoch 166 ... ============
INFO - 09/02/20 21:40:41 - 3:32:12 - Epoch: [166][0]	Time 3.256 (3.256)	Data 2.102 (2.102)	Loss 2.1427 (2.1427)	Lr: 0.0041
INFO - 09/02/20 21:41:18 - 3:32:49 - Epoch: [166][50]	Time 0.689 (0.797)	Data 0.000 (0.042)	Loss 2.1641 (2.1526)	Lr: 0.0041
INFO - 09/02/20 21:41:55 - 3:33:26 - ============ Starting epoch 167 ... ============
INFO - 09/02/20 21:41:58 - 3:33:29 - Epoch: [167][0]	Time 3.203 (3.203)	Data 2.062 (2.062)	Loss 2.1502 (2.1502)	Lr: 0.0041
INFO - 09/02/20 21:42:33 - 3:34:04 - Epoch: [167][50]	Time 0.702 (0.751)	Data 0.000 (0.041)	Loss 2.1543 (2.1505)	Lr: 0.0041
INFO - 09/02/20 21:43:13 - 3:34:44 - ============ Starting epoch 168 ... ============
INFO - 09/02/20 21:43:15 - 3:34:47 - Epoch: [168][0]	Time 2.357 (2.357)	Data 1.649 (1.649)	Loss 2.1442 (2.1442)	Lr: 0.0041
INFO - 09/02/20 21:43:49 - 3:35:21 - Epoch: [168][50]	Time 0.700 (0.713)	Data 0.000 (0.033)	Loss 2.1558 (2.1507)	Lr: 0.0041
INFO - 09/02/20 21:44:30 - 3:36:01 - ============ Starting epoch 169 ... ============
INFO - 09/02/20 21:44:32 - 3:36:03 - Epoch: [169][0]	Time 2.338 (2.338)	Data 1.653 (1.653)	Loss 2.1746 (2.1746)	Lr: 0.0041
INFO - 09/02/20 21:45:06 - 3:36:37 - Epoch: [169][50]	Time 0.686 (0.706)	Data 0.000 (0.033)	Loss 2.1636 (2.1527)	Lr: 0.0041
INFO - 09/02/20 21:45:46 - 3:37:17 - ============ Starting epoch 170 ... ============
INFO - 09/02/20 21:45:48 - 3:37:20 - Epoch: [170][0]	Time 2.349 (2.349)	Data 1.633 (1.633)	Loss 2.1496 (2.1496)	Lr: 0.0041
INFO - 09/02/20 21:46:22 - 3:37:54 - Epoch: [170][50]	Time 0.647 (0.713)	Data 0.001 (0.032)	Loss 2.1455 (2.1543)	Lr: 0.0040
INFO - 09/02/20 21:47:03 - 3:38:34 - ============ Starting epoch 171 ... ============
INFO - 09/02/20 21:47:05 - 3:38:37 - Epoch: [171][0]	Time 2.668 (2.668)	Data 1.974 (1.974)	Loss 2.1610 (2.1610)	Lr: 0.0040
INFO - 09/02/20 21:47:40 - 3:39:11 - Epoch: [171][50]	Time 0.811 (0.727)	Data 0.000 (0.039)	Loss 2.1418 (2.1514)	Lr: 0.0040
INFO - 09/02/20 21:48:19 - 3:39:51 - ============ Starting epoch 172 ... ============
INFO - 09/02/20 21:48:22 - 3:39:53 - Epoch: [172][0]	Time 2.219 (2.219)	Data 1.567 (1.567)	Loss 2.1434 (2.1434)	Lr: 0.0040
INFO - 09/02/20 21:48:57 - 3:40:28 - Epoch: [172][50]	Time 0.824 (0.736)	Data 0.000 (0.031)	Loss 2.1518 (2.1497)	Lr: 0.0040
INFO - 09/02/20 21:49:36 - 3:41:07 - ============ Starting epoch 173 ... ============
INFO - 09/02/20 21:49:38 - 3:41:10 - Epoch: [173][0]	Time 2.275 (2.275)	Data 1.618 (1.618)	Loss 2.1814 (2.1814)	Lr: 0.0040
INFO - 09/02/20 21:50:17 - 3:41:48 - Epoch: [173][50]	Time 1.144 (0.795)	Data 0.000 (0.032)	Loss 2.1379 (2.1485)	Lr: 0.0040
INFO - 09/02/20 21:50:53 - 3:42:24 - ============ Starting epoch 174 ... ============
INFO - 09/02/20 21:50:56 - 3:42:27 - Epoch: [174][0]	Time 2.860 (2.860)	Data 2.131 (2.131)	Loss 2.1441 (2.1441)	Lr: 0.0040
INFO - 09/02/20 21:51:33 - 3:43:04 - Epoch: [174][50]	Time 1.140 (0.790)	Data 0.000 (0.042)	Loss 2.1336 (2.1460)	Lr: 0.0040
INFO - 09/02/20 21:52:10 - 3:43:41 - ============ Starting epoch 175 ... ============
INFO - 09/02/20 21:52:13 - 3:43:44 - Epoch: [175][0]	Time 2.703 (2.703)	Data 1.977 (1.977)	Loss 2.1332 (2.1332)	Lr: 0.0039
INFO - 09/02/20 21:52:54 - 3:44:25 - Epoch: [175][50]	Time 1.222 (0.863)	Data 0.000 (0.039)	Loss 2.1404 (2.1455)	Lr: 0.0039
INFO - 09/02/20 21:53:28 - 3:44:59 - ============ Starting epoch 176 ... ============
INFO - 09/02/20 21:53:30 - 3:45:01 - Epoch: [176][0]	Time 2.331 (2.331)	Data 1.562 (1.562)	Loss 2.1311 (2.1311)	Lr: 0.0039
INFO - 09/02/20 21:54:13 - 3:45:44 - Epoch: [176][50]	Time 0.683 (0.889)	Data 0.000 (0.031)	Loss 2.1376 (2.1493)	Lr: 0.0039
INFO - 09/02/20 21:54:44 - 3:46:16 - ============ Starting epoch 177 ... ============
INFO - 09/02/20 21:54:47 - 3:46:18 - Epoch: [177][0]	Time 2.699 (2.699)	Data 1.994 (1.994)	Loss 2.1501 (2.1501)	Lr: 0.0039
INFO - 09/02/20 21:55:30 - 3:47:01 - Epoch: [177][50]	Time 0.696 (0.888)	Data 0.000 (0.039)	Loss 2.1444 (2.1523)	Lr: 0.0039
INFO - 09/02/20 21:56:02 - 3:47:33 - ============ Starting epoch 178 ... ============
INFO - 09/02/20 21:56:04 - 3:47:36 - Epoch: [178][0]	Time 2.693 (2.693)	Data 1.987 (1.987)	Loss 2.1455 (2.1455)	Lr: 0.0039
INFO - 09/02/20 21:56:47 - 3:48:18 - Epoch: [178][50]	Time 0.683 (0.893)	Data 0.000 (0.039)	Loss 2.1481 (2.1519)	Lr: 0.0039
INFO - 09/02/20 21:57:19 - 3:48:50 - ============ Starting epoch 179 ... ============
INFO - 09/02/20 21:57:21 - 3:48:52 - Epoch: [179][0]	Time 2.542 (2.542)	Data 1.855 (1.855)	Loss 2.1445 (2.1445)	Lr: 0.0039
INFO - 09/02/20 21:58:04 - 3:49:35 - Epoch: [179][50]	Time 0.645 (0.885)	Data 0.001 (0.037)	Loss 2.1358 (2.1467)	Lr: 0.0039
INFO - 09/02/20 21:58:35 - 3:50:07 - ============ Starting epoch 180 ... ============
INFO - 09/02/20 21:58:38 - 3:50:09 - Epoch: [180][0]	Time 2.780 (2.780)	Data 1.940 (1.940)	Loss 2.1272 (2.1272)	Lr: 0.0038
INFO - 09/02/20 21:59:21 - 3:50:52 - Epoch: [180][50]	Time 0.637 (0.887)	Data 0.000 (0.038)	Loss 2.1400 (2.1491)	Lr: 0.0038
INFO - 09/02/20 21:59:53 - 3:51:24 - ============ Starting epoch 181 ... ============
INFO - 09/02/20 21:59:56 - 3:51:27 - Epoch: [181][0]	Time 2.634 (2.634)	Data 1.789 (1.789)	Loss 2.1576 (2.1576)	Lr: 0.0038
INFO - 09/02/20 22:00:37 - 3:52:08 - Epoch: [181][50]	Time 0.638 (0.859)	Data 0.000 (0.035)	Loss 2.1312 (2.1479)	Lr: 0.0038
INFO - 09/02/20 22:01:11 - 3:52:42 - ============ Starting epoch 182 ... ============
INFO - 09/02/20 22:01:14 - 3:52:45 - Epoch: [182][0]	Time 3.094 (3.094)	Data 1.981 (1.981)	Loss 2.1529 (2.1529)	Lr: 0.0038
INFO - 09/02/20 22:01:52 - 3:53:23 - Epoch: [182][50]	Time 0.702 (0.812)	Data 0.001 (0.039)	Loss 2.1556 (2.1512)	Lr: 0.0038
INFO - 09/02/20 22:02:30 - 3:54:01 - ============ Starting epoch 183 ... ============
INFO - 09/02/20 22:02:33 - 3:54:04 - Epoch: [183][0]	Time 3.186 (3.186)	Data 2.041 (2.041)	Loss 2.1484 (2.1484)	Lr: 0.0038
INFO - 09/02/20 22:03:08 - 3:54:39 - Epoch: [183][50]	Time 0.683 (0.748)	Data 0.000 (0.040)	Loss 2.1441 (2.1466)	Lr: 0.0038
INFO - 09/02/20 22:03:49 - 3:55:20 - ============ Starting epoch 184 ... ============
INFO - 09/02/20 22:03:51 - 3:55:22 - Epoch: [184][0]	Time 2.590 (2.590)	Data 1.843 (1.843)	Loss 2.1450 (2.1450)	Lr: 0.0038
INFO - 09/02/20 22:04:25 - 3:55:56 - Epoch: [184][50]	Time 0.660 (0.712)	Data 0.000 (0.036)	Loss 2.1289 (2.1483)	Lr: 0.0037
INFO - 09/02/20 22:05:05 - 3:56:36 - ============ Starting epoch 185 ... ============
INFO - 09/02/20 22:05:08 - 3:56:39 - Epoch: [185][0]	Time 2.421 (2.421)	Data 1.648 (1.648)	Loss 2.1516 (2.1516)	Lr: 0.0037
INFO - 09/02/20 22:05:42 - 3:57:13 - Epoch: [185][50]	Time 0.695 (0.719)	Data 0.000 (0.033)	Loss 2.1390 (2.1513)	Lr: 0.0037
INFO - 09/02/20 22:06:22 - 3:57:54 - ============ Starting epoch 186 ... ============
INFO - 09/02/20 22:06:25 - 3:57:56 - Epoch: [186][0]	Time 2.548 (2.548)	Data 1.838 (1.838)	Loss 2.1440 (2.1440)	Lr: 0.0037
INFO - 09/02/20 22:06:59 - 3:58:30 - Epoch: [186][50]	Time 0.802 (0.717)	Data 0.001 (0.036)	Loss 2.1422 (2.1383)	Lr: 0.0037
INFO - 09/02/20 22:07:39 - 3:59:10 - ============ Starting epoch 187 ... ============
INFO - 09/02/20 22:07:42 - 3:59:13 - Epoch: [187][0]	Time 2.447 (2.447)	Data 1.745 (1.745)	Loss 2.1479 (2.1479)	Lr: 0.0037
INFO - 09/02/20 22:08:16 - 3:59:47 - Epoch: [187][50]	Time 0.817 (0.726)	Data 0.001 (0.035)	Loss 2.1257 (2.1472)	Lr: 0.0037
INFO - 09/02/20 22:08:56 - 4:00:27 - ============ Starting epoch 188 ... ============
INFO - 09/02/20 22:08:59 - 4:00:30 - Epoch: [188][0]	Time 2.456 (2.456)	Data 1.746 (1.746)	Loss 2.1235 (2.1235)	Lr: 0.0037
INFO - 09/02/20 22:09:34 - 4:01:05 - Epoch: [188][50]	Time 0.789 (0.734)	Data 0.000 (0.035)	Loss 2.1418 (2.1439)	Lr: 0.0037
INFO - 09/02/20 22:10:13 - 4:01:45 - ============ Starting epoch 189 ... ============
INFO - 09/02/20 22:10:16 - 4:01:47 - Epoch: [189][0]	Time 2.294 (2.294)	Data 1.591 (1.591)	Loss 2.1586 (2.1586)	Lr: 0.0036
INFO - 09/02/20 22:10:51 - 4:02:22 - Epoch: [189][50]	Time 0.815 (0.737)	Data 0.000 (0.031)	Loss 2.1393 (2.1492)	Lr: 0.0036
INFO - 09/02/20 22:11:30 - 4:03:01 - ============ Starting epoch 190 ... ============
INFO - 09/02/20 22:11:32 - 4:03:04 - Epoch: [190][0]	Time 2.328 (2.328)	Data 1.646 (1.646)	Loss 2.1464 (2.1464)	Lr: 0.0036
INFO - 09/02/20 22:12:11 - 4:03:42 - Epoch: [190][50]	Time 1.137 (0.797)	Data 0.000 (0.033)	Loss 2.1284 (2.1464)	Lr: 0.0036
INFO - 09/02/20 22:12:47 - 4:04:18 - ============ Starting epoch 191 ... ============
INFO - 09/02/20 22:12:50 - 4:04:21 - Epoch: [191][0]	Time 2.444 (2.444)	Data 1.756 (1.756)	Loss 2.1401 (2.1401)	Lr: 0.0036
INFO - 09/02/20 22:13:31 - 4:05:02 - Epoch: [191][50]	Time 1.153 (0.854)	Data 0.001 (0.035)	Loss 2.1447 (2.1442)	Lr: 0.0036
INFO - 09/02/20 22:14:04 - 4:05:35 - ============ Starting epoch 192 ... ============
INFO - 09/02/20 22:14:06 - 4:05:37 - Epoch: [192][0]	Time 2.297 (2.297)	Data 1.564 (1.564)	Loss 2.1526 (2.1526)	Lr: 0.0036
INFO - 09/02/20 22:14:49 - 4:06:20 - Epoch: [192][50]	Time 0.701 (0.883)	Data 0.000 (0.031)	Loss 2.1477 (2.1473)	Lr: 0.0036
INFO - 09/02/20 22:15:21 - 4:06:52 - ============ Starting epoch 193 ... ============
INFO - 09/02/20 22:15:23 - 4:06:55 - Epoch: [193][0]	Time 2.401 (2.401)	Data 1.706 (1.706)	Loss 2.1507 (2.1507)	Lr: 0.0036
INFO - 09/02/20 22:16:06 - 4:07:37 - Epoch: [193][50]	Time 0.634 (0.885)	Data 0.000 (0.034)	Loss 2.1376 (2.1428)	Lr: 0.0035
INFO - 09/02/20 22:16:38 - 4:08:09 - ============ Starting epoch 194 ... ============
INFO - 09/02/20 22:16:40 - 4:08:11 - Epoch: [194][0]	Time 2.317 (2.317)	Data 1.556 (1.556)	Loss 2.1317 (2.1317)	Lr: 0.0035
INFO - 09/02/20 22:17:23 - 4:08:54 - Epoch: [194][50]	Time 0.683 (0.880)	Data 0.000 (0.031)	Loss 2.1445 (2.1482)	Lr: 0.0035
INFO - 09/02/20 22:17:54 - 4:09:25 - ============ Starting epoch 195 ... ============
INFO - 09/02/20 22:17:56 - 4:09:28 - Epoch: [195][0]	Time 2.342 (2.342)	Data 1.659 (1.659)	Loss 2.1433 (2.1433)	Lr: 0.0035
INFO - 09/02/20 22:18:40 - 4:10:11 - Epoch: [195][50]	Time 0.644 (0.893)	Data 0.000 (0.033)	Loss 2.1467 (2.1436)	Lr: 0.0035
INFO - 09/02/20 22:19:11 - 4:10:42 - ============ Starting epoch 196 ... ============
INFO - 09/02/20 22:19:14 - 4:10:45 - Epoch: [196][0]	Time 2.617 (2.617)	Data 1.777 (1.777)	Loss 2.1308 (2.1308)	Lr: 0.0035
INFO - 09/02/20 22:19:56 - 4:11:27 - Epoch: [196][50]	Time 0.690 (0.879)	Data 0.000 (0.035)	Loss 2.1276 (2.1404)	Lr: 0.0035
INFO - 09/02/20 22:20:28 - 4:12:00 - ============ Starting epoch 197 ... ============
INFO - 09/02/20 22:20:31 - 4:12:02 - Epoch: [197][0]	Time 2.600 (2.600)	Data 1.781 (1.781)	Loss 2.1383 (2.1383)	Lr: 0.0035
INFO - 09/02/20 22:21:12 - 4:12:43 - Epoch: [197][50]	Time 0.692 (0.858)	Data 0.000 (0.035)	Loss 2.1400 (2.1430)	Lr: 0.0035
INFO - 09/02/20 22:21:47 - 4:13:18 - ============ Starting epoch 198 ... ============
INFO - 09/02/20 22:21:50 - 4:13:21 - Epoch: [198][0]	Time 2.943 (2.943)	Data 1.735 (1.735)	Loss 2.1246 (2.1246)	Lr: 0.0035
INFO - 09/02/20 22:22:28 - 4:13:59 - Epoch: [198][50]	Time 0.696 (0.801)	Data 0.000 (0.034)	Loss 2.1308 (2.1413)	Lr: 0.0034
INFO - 09/02/20 22:23:06 - 4:14:38 - ============ Starting epoch 199 ... ============
INFO - 09/02/20 22:23:09 - 4:14:41 - Epoch: [199][0]	Time 2.924 (2.924)	Data 1.711 (1.711)	Loss 2.1486 (2.1486)	Lr: 0.0034
INFO - 09/02/20 22:23:43 - 4:15:14 - Epoch: [199][50]	Time 0.695 (0.719)	Data 0.000 (0.034)	Loss 2.1346 (2.1432)	Lr: 0.0034
INFO - 09/02/20 22:24:23 - 4:15:55 - ============ Starting epoch 200 ... ============
INFO - 09/02/20 22:24:26 - 4:15:57 - Epoch: [200][0]	Time 2.530 (2.530)	Data 1.778 (1.778)	Loss 2.1607 (2.1607)	Lr: 0.0034
INFO - 09/02/20 22:25:00 - 4:16:31 - Epoch: [200][50]	Time 0.700 (0.721)	Data 0.000 (0.035)	Loss 2.1543 (2.1457)	Lr: 0.0034
INFO - 09/02/20 22:25:41 - 4:17:12 - ============ Starting epoch 201 ... ============
INFO - 09/02/20 22:25:44 - 4:17:15 - Epoch: [201][0]	Time 2.614 (2.614)	Data 1.871 (1.871)	Loss 2.1350 (2.1350)	Lr: 0.0034
INFO - 09/02/20 22:26:18 - 4:17:49 - Epoch: [201][50]	Time 0.647 (0.717)	Data 0.000 (0.037)	Loss 2.1318 (2.1475)	Lr: 0.0034
INFO - 09/02/20 22:26:58 - 4:18:29 - ============ Starting epoch 202 ... ============
INFO - 09/02/20 22:27:00 - 4:18:31 - Epoch: [202][0]	Time 2.423 (2.423)	Data 1.717 (1.717)	Loss 2.1587 (2.1587)	Lr: 0.0034
INFO - 09/02/20 22:27:34 - 4:19:06 - Epoch: [202][50]	Time 0.858 (0.719)	Data 0.000 (0.034)	Loss 2.1229 (2.1443)	Lr: 0.0034
INFO - 09/02/20 22:28:15 - 4:19:47 - ============ Starting epoch 203 ... ============
INFO - 09/02/20 22:28:18 - 4:19:49 - Epoch: [203][0]	Time 2.702 (2.702)	Data 1.940 (1.940)	Loss 2.1423 (2.1423)	Lr: 0.0033
INFO - 09/02/20 22:28:52 - 4:20:24 - Epoch: [203][50]	Time 0.778 (0.727)	Data 0.000 (0.038)	Loss 2.1450 (2.1486)	Lr: 0.0033
INFO - 09/02/20 22:29:32 - 4:21:04 - ============ Starting epoch 204 ... ============
INFO - 09/02/20 22:29:35 - 4:21:06 - Epoch: [204][0]	Time 2.477 (2.477)	Data 1.806 (1.806)	Loss 2.1280 (2.1280)	Lr: 0.0033
INFO - 09/02/20 22:30:10 - 4:21:41 - Epoch: [204][50]	Time 0.811 (0.737)	Data 0.000 (0.036)	Loss 2.1359 (2.1430)	Lr: 0.0033
INFO - 09/02/20 22:30:49 - 4:22:20 - ============ Starting epoch 205 ... ============
INFO - 09/02/20 22:30:52 - 4:22:23 - Epoch: [205][0]	Time 2.686 (2.686)	Data 2.007 (2.007)	Loss 2.1315 (2.1315)	Lr: 0.0033
INFO - 09/02/20 22:31:30 - 4:23:01 - Epoch: [205][50]	Time 1.173 (0.805)	Data 0.000 (0.040)	Loss 2.1323 (2.1376)	Lr: 0.0033
INFO - 09/02/20 22:32:06 - 4:23:38 - ============ Starting epoch 206 ... ============
INFO - 09/02/20 22:32:09 - 4:23:40 - Epoch: [206][0]	Time 2.550 (2.550)	Data 1.758 (1.758)	Loss 2.0952 (2.0952)	Lr: 0.0033
INFO - 09/02/20 22:32:50 - 4:24:22 - Epoch: [206][50]	Time 1.157 (0.865)	Data 0.000 (0.035)	Loss 2.1525 (2.1476)	Lr: 0.0033
INFO - 09/02/20 22:33:23 - 4:24:54 - ============ Starting epoch 207 ... ============
INFO - 09/02/20 22:33:26 - 4:24:57 - Epoch: [207][0]	Time 2.641 (2.641)	Data 1.991 (1.991)	Loss 2.1332 (2.1332)	Lr: 0.0033
INFO - 09/02/20 22:34:09 - 4:25:40 - Epoch: [207][50]	Time 0.675 (0.891)	Data 0.000 (0.039)	Loss 2.1379 (2.1439)	Lr: 0.0032
INFO - 09/02/20 22:34:41 - 4:26:12 - ============ Starting epoch 208 ... ============
INFO - 09/02/20 22:34:43 - 4:26:14 - Epoch: [208][0]	Time 2.484 (2.484)	Data 1.782 (1.782)	Loss 2.1301 (2.1301)	Lr: 0.0032
INFO - 09/02/20 22:35:26 - 4:26:57 - Epoch: [208][50]	Time 0.702 (0.887)	Data 0.000 (0.035)	Loss 2.1188 (2.1426)	Lr: 0.0032
INFO - 09/02/20 22:35:57 - 4:27:29 - ============ Starting epoch 209 ... ============
INFO - 09/02/20 22:36:00 - 4:27:31 - Epoch: [209][0]	Time 2.449 (2.449)	Data 1.773 (1.773)	Loss 2.1365 (2.1365)	Lr: 0.0032
INFO - 09/02/20 22:36:43 - 4:28:14 - Epoch: [209][50]	Time 0.694 (0.886)	Data 0.000 (0.035)	Loss 2.1422 (2.1459)	Lr: 0.0032
INFO - 09/02/20 22:37:14 - 4:28:45 - ============ Starting epoch 210 ... ============
INFO - 09/02/20 22:37:17 - 4:28:48 - Epoch: [210][0]	Time 2.778 (2.778)	Data 1.926 (1.926)	Loss 2.1301 (2.1301)	Lr: 0.0032
INFO - 09/02/20 22:38:00 - 4:29:31 - Epoch: [210][50]	Time 0.674 (0.899)	Data 0.001 (0.038)	Loss 2.1331 (2.1410)	Lr: 0.0032
INFO - 09/02/20 22:38:32 - 4:30:03 - ============ Starting epoch 211 ... ============
INFO - 09/02/20 22:38:35 - 4:30:06 - Epoch: [211][0]	Time 2.481 (2.481)	Data 1.660 (1.660)	Loss 2.1558 (2.1558)	Lr: 0.0032
INFO - 09/02/20 22:39:16 - 4:30:47 - Epoch: [211][50]	Time 0.652 (0.863)	Data 0.001 (0.033)	Loss 2.1381 (2.1429)	Lr: 0.0032
INFO - 09/02/20 22:39:49 - 4:31:20 - ============ Starting epoch 212 ... ============
INFO - 09/02/20 22:39:52 - 4:31:23 - Epoch: [212][0]	Time 2.830 (2.830)	Data 1.654 (1.654)	Loss 2.1287 (2.1287)	Lr: 0.0031
INFO - 09/02/20 22:40:32 - 4:32:03 - Epoch: [212][50]	Time 0.651 (0.839)	Data 0.001 (0.033)	Loss 2.1305 (2.1429)	Lr: 0.0031
INFO - 09/02/20 22:41:07 - 4:32:39 - ============ Starting epoch 213 ... ============
INFO - 09/02/20 22:41:10 - 4:32:42 - Epoch: [213][0]	Time 3.111 (3.111)	Data 2.007 (2.007)	Loss 2.1570 (2.1570)	Lr: 0.0031
INFO - 09/02/20 22:41:47 - 4:33:19 - Epoch: [213][50]	Time 0.699 (0.786)	Data 0.000 (0.040)	Loss 2.1360 (2.1406)	Lr: 0.0031
INFO - 09/02/20 22:42:26 - 4:33:57 - ============ Starting epoch 214 ... ============
INFO - 09/02/20 22:42:28 - 4:34:00 - Epoch: [214][0]	Time 2.783 (2.783)	Data 1.605 (1.605)	Loss 2.1404 (2.1404)	Lr: 0.0031
INFO - 09/02/20 22:43:03 - 4:34:34 - Epoch: [214][50]	Time 0.689 (0.724)	Data 0.000 (0.032)	Loss 2.1579 (2.1442)	Lr: 0.0031
INFO - 09/02/20 22:43:43 - 4:35:14 - ============ Starting epoch 215 ... ============
INFO - 09/02/20 22:43:45 - 4:35:16 - Epoch: [215][0]	Time 2.333 (2.333)	Data 1.671 (1.671)	Loss 2.1552 (2.1552)	Lr: 0.0031
INFO - 09/02/20 22:44:20 - 4:35:51 - Epoch: [215][50]	Time 0.653 (0.719)	Data 0.000 (0.033)	Loss 2.1406 (2.1426)	Lr: 0.0031
INFO - 09/02/20 22:45:00 - 4:36:31 - ============ Starting epoch 216 ... ============
INFO - 09/02/20 22:45:02 - 4:36:34 - Epoch: [216][0]	Time 2.381 (2.381)	Data 1.648 (1.648)	Loss 2.1296 (2.1296)	Lr: 0.0031
INFO - 09/02/20 22:45:36 - 4:37:08 - Epoch: [216][50]	Time 0.691 (0.711)	Data 0.001 (0.033)	Loss 2.1446 (2.1424)	Lr: 0.0030
INFO - 09/02/20 22:46:17 - 4:37:48 - ============ Starting epoch 217 ... ============
INFO - 09/02/20 22:46:19 - 4:37:50 - Epoch: [217][0]	Time 2.563 (2.563)	Data 1.838 (1.838)	Loss 2.1368 (2.1368)	Lr: 0.0030
INFO - 09/02/20 22:46:53 - 4:38:24 - Epoch: [217][50]	Time 0.689 (0.718)	Data 0.000 (0.036)	Loss 2.1513 (2.1421)	Lr: 0.0030
INFO - 09/02/20 22:47:34 - 4:39:05 - ============ Starting epoch 218 ... ============
INFO - 09/02/20 22:47:37 - 4:39:08 - Epoch: [218][0]	Time 2.751 (2.751)	Data 1.979 (1.979)	Loss 2.1457 (2.1457)	Lr: 0.0030
INFO - 09/02/20 22:48:11 - 4:39:42 - Epoch: [218][50]	Time 0.811 (0.725)	Data 0.000 (0.039)	Loss 2.1335 (2.1399)	Lr: 0.0030
INFO - 09/02/20 22:48:51 - 4:40:23 - ============ Starting epoch 219 ... ============
INFO - 09/02/20 22:48:54 - 4:40:25 - Epoch: [219][0]	Time 2.402 (2.402)	Data 1.710 (1.710)	Loss 2.1334 (2.1334)	Lr: 0.0030
INFO - 09/02/20 22:49:28 - 4:41:00 - Epoch: [219][50]	Time 0.805 (0.725)	Data 0.000 (0.034)	Loss 2.1209 (2.1383)	Lr: 0.0030
INFO - 09/02/20 22:50:08 - 4:41:39 - ============ Starting epoch 220 ... ============
INFO - 09/02/20 22:50:10 - 4:41:41 - Epoch: [220][0]	Time 2.275 (2.275)	Data 1.626 (1.626)	Loss 2.1441 (2.1441)	Lr: 0.0030
INFO - 09/02/20 22:50:46 - 4:42:17 - Epoch: [220][50]	Time 0.881 (0.748)	Data 0.000 (0.032)	Loss 2.1299 (2.1416)	Lr: 0.0030
INFO - 09/02/20 22:51:25 - 4:42:56 - ============ Starting epoch 221 ... ============
INFO - 09/02/20 22:51:27 - 4:42:58 - Epoch: [221][0]	Time 2.390 (2.390)	Data 1.665 (1.665)	Loss 2.1510 (2.1510)	Lr: 0.0030
INFO - 09/02/20 22:52:06 - 4:43:37 - Epoch: [221][50]	Time 1.103 (0.803)	Data 0.000 (0.033)	Loss 2.1383 (2.1379)	Lr: 0.0029
INFO - 09/02/20 22:52:41 - 4:44:13 - ============ Starting epoch 222 ... ============
INFO - 09/02/20 22:52:44 - 4:44:15 - Epoch: [222][0]	Time 2.731 (2.731)	Data 1.964 (1.964)	Loss 2.1491 (2.1491)	Lr: 0.0029
INFO - 09/02/20 22:53:25 - 4:44:56 - Epoch: [222][50]	Time 1.181 (0.859)	Data 0.001 (0.039)	Loss 2.1275 (2.1414)	Lr: 0.0029
INFO - 09/02/20 22:53:59 - 4:45:30 - ============ Starting epoch 223 ... ============
INFO - 09/02/20 22:54:01 - 4:45:33 - Epoch: [223][0]	Time 2.790 (2.790)	Data 2.010 (2.010)	Loss 2.1465 (2.1465)	Lr: 0.0029
INFO - 09/02/20 22:54:44 - 4:46:16 - Epoch: [223][50]	Time 0.685 (0.896)	Data 0.001 (0.040)	Loss 2.1389 (2.1433)	Lr: 0.0029
INFO - 09/02/20 22:55:16 - 4:46:47 - ============ Starting epoch 224 ... ============
INFO - 09/02/20 22:55:18 - 4:46:49 - Epoch: [224][0]	Time 2.322 (2.322)	Data 1.638 (1.638)	Loss 2.1357 (2.1357)	Lr: 0.0029
INFO - 09/02/20 22:56:01 - 4:47:32 - Epoch: [224][50]	Time 0.697 (0.880)	Data 0.000 (0.032)	Loss 2.1351 (2.1420)	Lr: 0.0029
INFO - 09/02/20 22:56:32 - 4:48:03 - ============ Starting epoch 225 ... ============
INFO - 09/02/20 22:56:35 - 4:48:06 - Epoch: [225][0]	Time 2.492 (2.492)	Data 1.778 (1.778)	Loss 2.1450 (2.1450)	Lr: 0.0029
INFO - 09/02/20 22:57:18 - 4:48:49 - Epoch: [225][50]	Time 0.694 (0.896)	Data 0.000 (0.035)	Loss 2.1385 (2.1425)	Lr: 0.0029
INFO - 09/02/20 22:57:50 - 4:49:21 - ============ Starting epoch 226 ... ============
INFO - 09/02/20 22:57:52 - 4:49:23 - Epoch: [226][0]	Time 2.313 (2.313)	Data 1.627 (1.627)	Loss 2.1291 (2.1291)	Lr: 0.0028
INFO - 09/02/20 22:58:35 - 4:50:06 - Epoch: [226][50]	Time 0.682 (0.885)	Data 0.001 (0.032)	Loss 2.1329 (2.1396)	Lr: 0.0028
INFO - 09/02/20 22:59:07 - 4:50:38 - ============ Starting epoch 227 ... ============
INFO - 09/02/20 22:59:09 - 4:50:41 - Epoch: [227][0]	Time 2.687 (2.687)	Data 1.921 (1.921)	Loss 2.1371 (2.1371)	Lr: 0.0028
INFO - 09/02/20 22:59:51 - 4:51:22 - Epoch: [227][50]	Time 0.628 (0.873)	Data 0.001 (0.038)	Loss 2.1515 (2.1409)	Lr: 0.0028
INFO - 09/02/20 23:00:24 - 4:51:55 - ============ Starting epoch 228 ... ============
INFO - 09/02/20 23:00:27 - 4:51:58 - Epoch: [228][0]	Time 2.817 (2.817)	Data 1.987 (1.987)	Loss 2.1084 (2.1084)	Lr: 0.0028
INFO - 09/02/20 23:01:08 - 4:52:39 - Epoch: [228][50]	Time 0.638 (0.864)	Data 0.000 (0.039)	Loss 2.1390 (2.1376)	Lr: 0.0028
INFO - 09/02/20 23:01:42 - 4:53:13 - ============ Starting epoch 229 ... ============
INFO - 09/02/20 23:01:45 - 4:53:16 - Epoch: [229][0]	Time 2.764 (2.764)	Data 1.705 (1.705)	Loss 2.1322 (2.1322)	Lr: 0.0028
INFO - 09/02/20 23:02:23 - 4:53:54 - Epoch: [229][50]	Time 0.643 (0.809)	Data 0.000 (0.034)	Loss 2.1089 (2.1407)	Lr: 0.0028
INFO - 09/02/20 23:02:59 - 4:54:31 - ============ Starting epoch 230 ... ============
INFO - 09/02/20 23:03:03 - 4:54:34 - Epoch: [230][0]	Time 3.175 (3.175)	Data 2.004 (2.004)	Loss 2.1331 (2.1331)	Lr: 0.0028
INFO - 09/02/20 23:03:38 - 4:55:10 - Epoch: [230][50]	Time 0.640 (0.767)	Data 0.000 (0.040)	Loss 2.1431 (2.1374)	Lr: 0.0027
INFO - 09/02/20 23:04:15 - 4:55:46 - ============ Starting epoch 231 ... ============
INFO - 09/02/20 23:04:18 - 4:55:49 - Epoch: [231][0]	Time 3.085 (3.085)	Data 1.893 (1.893)	Loss 2.1255 (2.1255)	Lr: 0.0027
INFO - 09/02/20 23:04:55 - 4:56:26 - Epoch: [231][50]	Time 0.712 (0.785)	Data 0.000 (0.037)	Loss 2.1269 (2.1385)	Lr: 0.0027
INFO - 09/02/20 23:05:32 - 4:57:03 - ============ Starting epoch 232 ... ============
INFO - 09/02/20 23:05:35 - 4:57:06 - Epoch: [232][0]	Time 2.885 (2.885)	Data 1.763 (1.763)	Loss 2.1388 (2.1388)	Lr: 0.0027
INFO - 09/02/20 23:06:09 - 4:57:41 - Epoch: [232][50]	Time 0.638 (0.733)	Data 0.001 (0.035)	Loss 2.1260 (2.1367)	Lr: 0.0027
INFO - 09/02/20 23:06:49 - 4:58:20 - ============ Starting epoch 233 ... ============
INFO - 09/02/20 23:06:51 - 4:58:23 - Epoch: [233][0]	Time 2.482 (2.482)	Data 1.779 (1.779)	Loss 2.1270 (2.1270)	Lr: 0.0027
INFO - 09/02/20 23:07:25 - 4:58:57 - Epoch: [233][50]	Time 0.688 (0.718)	Data 0.001 (0.035)	Loss 2.1325 (2.1412)	Lr: 0.0027
INFO - 09/02/20 23:08:06 - 4:59:37 - ============ Starting epoch 234 ... ============
INFO - 09/02/20 23:08:08 - 4:59:39 - Epoch: [234][0]	Time 2.292 (2.292)	Data 1.567 (1.567)	Loss 2.1465 (2.1465)	Lr: 0.0027
INFO - 09/02/20 23:08:42 - 5:00:13 - Epoch: [234][50]	Time 0.689 (0.709)	Data 0.000 (0.031)	Loss 2.1513 (2.1393)	Lr: 0.0027
INFO - 09/02/20 23:09:22 - 5:00:54 - ============ Starting epoch 235 ... ============
INFO - 09/02/20 23:09:25 - 5:00:56 - Epoch: [235][0]	Time 2.645 (2.645)	Data 1.934 (1.934)	Loss 2.1223 (2.1223)	Lr: 0.0027
INFO - 09/02/20 23:09:59 - 5:01:30 - Epoch: [235][50]	Time 0.629 (0.717)	Data 0.001 (0.038)	Loss 2.1482 (2.1419)	Lr: 0.0026
INFO - 09/02/20 23:10:40 - 5:02:11 - ============ Starting epoch 236 ... ============
INFO - 09/02/20 23:10:42 - 5:02:13 - Epoch: [236][0]	Time 2.481 (2.481)	Data 1.782 (1.782)	Loss 2.1297 (2.1297)	Lr: 0.0026
INFO - 09/02/20 23:11:16 - 5:02:48 - Epoch: [236][50]	Time 0.807 (0.724)	Data 0.001 (0.035)	Loss 2.1448 (2.1401)	Lr: 0.0026
INFO - 09/02/20 23:11:56 - 5:03:28 - ============ Starting epoch 237 ... ============
INFO - 09/02/20 23:11:59 - 5:03:30 - Epoch: [237][0]	Time 2.355 (2.355)	Data 1.706 (1.706)	Loss 2.1367 (2.1367)	Lr: 0.0026
INFO - 09/02/20 23:12:34 - 5:04:05 - Epoch: [237][50]	Time 0.804 (0.732)	Data 0.000 (0.034)	Loss 2.1382 (2.1403)	Lr: 0.0026
INFO - 09/02/20 23:13:13 - 5:04:44 - ============ Starting epoch 238 ... ============
INFO - 09/02/20 23:13:15 - 5:04:47 - Epoch: [238][0]	Time 2.338 (2.338)	Data 1.683 (1.683)	Loss 2.1392 (2.1392)	Lr: 0.0026
INFO - 09/02/20 23:13:52 - 5:05:23 - Epoch: [238][50]	Time 1.127 (0.763)	Data 0.001 (0.033)	Loss 2.1341 (2.1375)	Lr: 0.0026
INFO - 09/02/20 23:14:30 - 5:06:01 - ============ Starting epoch 239 ... ============
INFO - 09/02/20 23:14:32 - 5:06:04 - Epoch: [239][0]	Time 2.301 (2.301)	Data 1.623 (1.623)	Loss 2.1334 (2.1334)	Lr: 0.0026
INFO - 09/02/20 23:15:12 - 5:06:43 - Epoch: [239][50]	Time 1.204 (0.814)	Data 0.001 (0.032)	Loss 2.1266 (2.1414)	Lr: 0.0026
INFO - 09/02/20 23:15:46 - 5:07:18 - ============ Starting epoch 240 ... ============
INFO - 09/02/20 23:15:49 - 5:07:20 - Epoch: [240][0]	Time 2.365 (2.365)	Data 1.641 (1.641)	Loss 2.1340 (2.1340)	Lr: 0.0025
INFO - 09/02/20 23:16:31 - 5:08:02 - Epoch: [240][50]	Time 1.193 (0.877)	Data 0.001 (0.033)	Loss 2.1365 (2.1419)	Lr: 0.0025
INFO - 09/02/20 23:17:04 - 5:08:35 - ============ Starting epoch 241 ... ============
INFO - 09/02/20 23:17:06 - 5:08:37 - Epoch: [241][0]	Time 2.382 (2.382)	Data 1.725 (1.725)	Loss 2.1307 (2.1307)	Lr: 0.0025
INFO - 09/02/20 23:17:49 - 5:09:20 - Epoch: [241][50]	Time 0.669 (0.888)	Data 0.000 (0.034)	Loss 2.1340 (2.1389)	Lr: 0.0025
INFO - 09/02/20 23:18:20 - 5:09:51 - ============ Starting epoch 242 ... ============
INFO - 09/02/20 23:18:22 - 5:09:54 - Epoch: [242][0]	Time 2.294 (2.294)	Data 1.627 (1.627)	Loss 2.1507 (2.1507)	Lr: 0.0025
INFO - 09/02/20 23:19:05 - 5:10:36 - Epoch: [242][50]	Time 0.680 (0.877)	Data 0.001 (0.032)	Loss 2.1202 (2.1392)	Lr: 0.0025
INFO - 09/02/20 23:19:37 - 5:11:08 - ============ Starting epoch 243 ... ============
INFO - 09/02/20 23:19:39 - 5:11:10 - Epoch: [243][0]	Time 2.682 (2.682)	Data 2.004 (2.004)	Loss 2.1350 (2.1350)	Lr: 0.0025
INFO - 09/02/20 23:20:22 - 5:11:54 - Epoch: [243][50]	Time 0.662 (0.898)	Data 0.001 (0.040)	Loss 2.1251 (2.1354)	Lr: 0.0025
INFO - 09/02/20 23:20:54 - 5:12:25 - ============ Starting epoch 244 ... ============
INFO - 09/02/20 23:20:56 - 5:12:28 - Epoch: [244][0]	Time 2.343 (2.343)	Data 1.638 (1.638)	Loss 2.1350 (2.1350)	Lr: 0.0025
INFO - 09/02/20 23:21:39 - 5:13:10 - Epoch: [244][50]	Time 0.669 (0.883)	Data 0.001 (0.032)	Loss 2.1243 (2.1363)	Lr: 0.0025
INFO - 09/02/20 23:22:11 - 5:13:42 - ============ Starting epoch 245 ... ============
INFO - 09/02/20 23:22:13 - 5:13:45 - Epoch: [245][0]	Time 2.769 (2.769)	Data 2.008 (2.008)	Loss 2.1507 (2.1507)	Lr: 0.0024
INFO - 09/02/20 23:22:56 - 5:14:27 - Epoch: [245][50]	Time 0.679 (0.892)	Data 0.001 (0.040)	Loss 2.1237 (2.1346)	Lr: 0.0024
INFO - 09/02/20 23:23:28 - 5:14:59 - ============ Starting epoch 246 ... ============
INFO - 09/02/20 23:23:31 - 5:15:02 - Epoch: [246][0]	Time 2.602 (2.602)	Data 1.773 (1.773)	Loss 2.1399 (2.1399)	Lr: 0.0024
INFO - 09/02/20 23:24:13 - 5:15:44 - Epoch: [246][50]	Time 0.698 (0.876)	Data 0.001 (0.035)	Loss 2.1430 (2.1391)	Lr: 0.0024
INFO - 09/02/20 23:24:45 - 5:16:16 - ============ Starting epoch 247 ... ============
INFO - 09/02/20 23:24:48 - 5:16:19 - Epoch: [247][0]	Time 2.845 (2.845)	Data 1.839 (1.839)	Loss 2.1373 (2.1373)	Lr: 0.0024
INFO - 09/02/20 23:25:29 - 5:17:00 - Epoch: [247][50]	Time 0.640 (0.856)	Data 0.000 (0.036)	Loss 2.1197 (2.1377)	Lr: 0.0024
INFO - 09/02/20 23:26:03 - 5:17:35 - ============ Starting epoch 248 ... ============
INFO - 09/02/20 23:26:07 - 5:17:38 - Epoch: [248][0]	Time 3.200 (3.200)	Data 1.946 (1.946)	Loss 2.1270 (2.1270)	Lr: 0.0024
INFO - 09/02/20 23:26:44 - 5:18:16 - Epoch: [248][50]	Time 0.709 (0.803)	Data 0.001 (0.038)	Loss 2.1252 (2.1370)	Lr: 0.0024
INFO - 09/02/20 23:27:22 - 5:18:54 - ============ Starting epoch 249 ... ============
INFO - 09/02/20 23:27:25 - 5:18:57 - Epoch: [249][0]	Time 2.976 (2.976)	Data 1.793 (1.793)	Loss 2.1253 (2.1253)	Lr: 0.0024
INFO - 09/02/20 23:28:00 - 5:19:31 - Epoch: [249][50]	Time 0.695 (0.735)	Data 0.000 (0.035)	Loss 2.1225 (2.1363)	Lr: 0.0024
INFO - 09/02/20 23:28:40 - 5:20:11 - ============ Starting epoch 250 ... ============
INFO - 09/02/20 23:28:42 - 5:20:14 - Epoch: [250][0]	Time 2.310 (2.310)	Data 1.598 (1.598)	Loss 2.1389 (2.1389)	Lr: 0.0023
INFO - 09/02/20 23:29:16 - 5:20:48 - Epoch: [250][50]	Time 0.691 (0.711)	Data 0.000 (0.032)	Loss 2.1278 (2.1377)	Lr: 0.0023
INFO - 09/02/20 23:29:57 - 5:21:28 - ============ Starting epoch 251 ... ============
INFO - 09/02/20 23:30:00 - 5:21:31 - Epoch: [251][0]	Time 2.354 (2.354)	Data 1.630 (1.630)	Loss 2.1143 (2.1143)	Lr: 0.0023
INFO - 09/02/20 23:30:34 - 5:22:05 - Epoch: [251][50]	Time 0.693 (0.715)	Data 0.000 (0.032)	Loss 2.1196 (2.1324)	Lr: 0.0023
INFO - 09/02/20 23:31:14 - 5:22:45 - ============ Starting epoch 252 ... ============
INFO - 09/02/20 23:31:17 - 5:22:48 - Epoch: [252][0]	Time 2.448 (2.448)	Data 1.765 (1.765)	Loss 2.1531 (2.1531)	Lr: 0.0023
INFO - 09/02/20 23:31:50 - 5:23:21 - Epoch: [252][50]	Time 0.668 (0.707)	Data 0.000 (0.035)	Loss 2.1299 (2.1366)	Lr: 0.0023
INFO - 09/02/20 23:32:31 - 5:24:02 - ============ Starting epoch 253 ... ============
INFO - 09/02/20 23:32:33 - 5:24:05 - Epoch: [253][0]	Time 2.599 (2.599)	Data 1.859 (1.859)	Loss 2.1353 (2.1353)	Lr: 0.0023
INFO - 09/02/20 23:33:08 - 5:24:39 - Epoch: [253][50]	Time 0.821 (0.730)	Data 0.000 (0.037)	Loss 2.1407 (2.1367)	Lr: 0.0023
INFO - 09/02/20 23:33:48 - 5:25:19 - ============ Starting epoch 254 ... ============
INFO - 09/02/20 23:33:50 - 5:25:22 - Epoch: [254][0]	Time 2.449 (2.449)	Data 1.746 (1.746)	Loss 2.1598 (2.1598)	Lr: 0.0023
INFO - 09/02/20 23:34:26 - 5:25:57 - Epoch: [254][50]	Time 0.813 (0.738)	Data 0.000 (0.035)	Loss 2.1367 (2.1391)	Lr: 0.0023
INFO - 09/02/20 23:35:04 - 5:26:36 - ============ Starting epoch 255 ... ============
INFO - 09/02/20 23:35:07 - 5:26:38 - Epoch: [255][0]	Time 2.481 (2.481)	Data 1.825 (1.825)	Loss 2.1366 (2.1366)	Lr: 0.0022
INFO - 09/02/20 23:35:45 - 5:27:16 - Epoch: [255][50]	Time 1.145 (0.795)	Data 0.000 (0.036)	Loss 2.1289 (2.1339)	Lr: 0.0022
INFO - 09/02/20 23:36:22 - 5:27:53 - ============ Starting epoch 256 ... ============
INFO - 09/02/20 23:36:24 - 5:27:55 - Epoch: [256][0]	Time 2.321 (2.321)	Data 1.604 (1.604)	Loss 2.1325 (2.1325)	Lr: 0.0022
INFO - 09/02/20 23:37:05 - 5:28:36 - Epoch: [256][50]	Time 1.229 (0.845)	Data 0.000 (0.032)	Loss 2.1209 (2.1340)	Lr: 0.0022
INFO - 09/02/20 23:37:38 - 5:29:10 - ============ Starting epoch 257 ... ============
INFO - 09/02/20 23:37:41 - 5:29:12 - Epoch: [257][0]	Time 2.299 (2.299)	Data 1.590 (1.590)	Loss 2.1460 (2.1460)	Lr: 0.0022
INFO - 09/02/20 23:38:23 - 5:29:54 - Epoch: [257][50]	Time 0.646 (0.878)	Data 0.001 (0.032)	Loss 2.1193 (2.1373)	Lr: 0.0022
INFO - 09/02/20 23:38:55 - 5:30:26 - ============ Starting epoch 258 ... ============
INFO - 09/02/20 23:38:57 - 5:30:29 - Epoch: [258][0]	Time 2.393 (2.393)	Data 1.638 (1.638)	Loss 2.1334 (2.1334)	Lr: 0.0022
INFO - 09/02/20 23:39:40 - 5:31:12 - Epoch: [258][50]	Time 0.687 (0.891)	Data 0.000 (0.033)	Loss 2.1239 (2.1353)	Lr: 0.0022
INFO - 09/02/20 23:40:12 - 5:31:43 - ============ Starting epoch 259 ... ============
INFO - 09/02/20 23:40:14 - 5:31:45 - Epoch: [259][0]	Time 2.343 (2.343)	Data 1.626 (1.626)	Loss 2.1529 (2.1529)	Lr: 0.0022
INFO - 09/02/20 23:40:57 - 5:32:28 - Epoch: [259][50]	Time 0.714 (0.884)	Data 0.000 (0.032)	Loss 2.1210 (2.1395)	Lr: 0.0022
INFO - 09/02/20 23:41:28 - 5:33:00 - ============ Starting epoch 260 ... ============
INFO - 09/02/20 23:41:31 - 5:33:02 - Epoch: [260][0]	Time 2.254 (2.254)	Data 1.612 (1.612)	Loss 2.1432 (2.1432)	Lr: 0.0021
INFO - 09/02/20 23:42:14 - 5:33:45 - Epoch: [260][50]	Time 0.712 (0.887)	Data 0.000 (0.032)	Loss 2.1238 (2.1347)	Lr: 0.0021
INFO - 09/02/20 23:42:45 - 5:34:17 - ============ Starting epoch 261 ... ============
INFO - 09/02/20 23:42:48 - 5:34:19 - Epoch: [261][0]	Time 2.604 (2.604)	Data 1.845 (1.845)	Loss 2.1301 (2.1301)	Lr: 0.0021
INFO - 09/02/20 23:43:31 - 5:35:02 - Epoch: [261][50]	Time 0.664 (0.891)	Data 0.000 (0.037)	Loss 2.1316 (2.1394)	Lr: 0.0021
INFO - 09/02/20 23:44:02 - 5:35:34 - ============ Starting epoch 262 ... ============
INFO - 09/02/20 23:44:05 - 5:35:36 - Epoch: [262][0]	Time 2.237 (2.237)	Data 1.598 (1.598)	Loss 2.1401 (2.1401)	Lr: 0.0021
INFO - 09/02/20 23:44:47 - 5:36:19 - Epoch: [262][50]	Time 0.668 (0.882)	Data 0.000 (0.032)	Loss 2.1056 (2.1315)	Lr: 0.0021
INFO - 09/02/20 23:45:19 - 5:36:50 - ============ Starting epoch 263 ... ============
INFO - 09/02/20 23:45:22 - 5:36:53 - Epoch: [263][0]	Time 2.591 (2.591)	Data 1.776 (1.776)	Loss 2.1176 (2.1176)	Lr: 0.0021
INFO - 09/02/20 23:46:04 - 5:37:35 - Epoch: [263][50]	Time 0.719 (0.881)	Data 0.000 (0.035)	Loss 2.1350 (2.1345)	Lr: 0.0021
INFO - 09/02/20 23:46:37 - 5:38:08 - ============ Starting epoch 264 ... ============
INFO - 09/02/20 23:46:40 - 5:38:11 - Epoch: [264][0]	Time 2.863 (2.863)	Data 1.687 (1.687)	Loss 2.1372 (2.1372)	Lr: 0.0021
INFO - 09/02/20 23:47:20 - 5:38:51 - Epoch: [264][50]	Time 0.649 (0.845)	Data 0.000 (0.033)	Loss 2.1319 (2.1365)	Lr: 0.0021
INFO - 09/02/20 23:47:55 - 5:39:26 - ============ Starting epoch 265 ... ============
INFO - 09/02/20 23:47:58 - 5:39:29 - Epoch: [265][0]	Time 2.926 (2.926)	Data 1.803 (1.803)	Loss 2.1386 (2.1386)	Lr: 0.0020
INFO - 09/02/20 23:48:35 - 5:40:06 - Epoch: [265][50]	Time 0.709 (0.787)	Data 0.000 (0.036)	Loss 2.1213 (2.1347)	Lr: 0.0020
INFO - 09/02/20 23:49:14 - 5:40:45 - ============ Starting epoch 266 ... ============
INFO - 09/02/20 23:49:17 - 5:40:48 - Epoch: [266][0]	Time 2.835 (2.835)	Data 1.628 (1.628)	Loss 2.1243 (2.1243)	Lr: 0.0020
INFO - 09/02/20 23:49:51 - 5:41:22 - Epoch: [266][50]	Time 0.693 (0.729)	Data 0.000 (0.032)	Loss 2.1163 (2.1314)	Lr: 0.0020
INFO - 09/02/20 23:50:31 - 5:42:03 - ============ Starting epoch 267 ... ============
INFO - 09/02/20 23:50:34 - 5:42:05 - Epoch: [267][0]	Time 2.403 (2.403)	Data 1.700 (1.700)	Loss 2.1291 (2.1291)	Lr: 0.0020
INFO - 09/02/20 23:51:08 - 5:42:39 - Epoch: [267][50]	Time 0.697 (0.710)	Data 0.001 (0.034)	Loss 2.1345 (2.1311)	Lr: 0.0020
INFO - 09/02/20 23:51:48 - 5:43:19 - ============ Starting epoch 268 ... ============
INFO - 09/02/20 23:51:51 - 5:43:22 - Epoch: [268][0]	Time 2.710 (2.710)	Data 1.988 (1.988)	Loss 2.1154 (2.1154)	Lr: 0.0020
INFO - 09/02/20 23:52:25 - 5:43:56 - Epoch: [268][50]	Time 0.666 (0.724)	Data 0.000 (0.039)	Loss 2.1148 (2.1361)	Lr: 0.0020
INFO - 09/02/20 23:53:06 - 5:44:37 - ============ Starting epoch 269 ... ============
INFO - 09/02/20 23:53:08 - 5:44:39 - Epoch: [269][0]	Time 2.443 (2.443)	Data 1.747 (1.747)	Loss 2.1181 (2.1181)	Lr: 0.0020
INFO - 09/02/20 23:53:42 - 5:45:14 - Epoch: [269][50]	Time 0.821 (0.720)	Data 0.000 (0.035)	Loss 2.1287 (2.1356)	Lr: 0.0020
INFO - 09/02/20 23:54:22 - 5:45:53 - ============ Starting epoch 270 ... ============
INFO - 09/02/20 23:54:24 - 5:45:56 - Epoch: [270][0]	Time 2.414 (2.414)	Data 1.744 (1.744)	Loss 2.1458 (2.1458)	Lr: 0.0020
INFO - 09/02/20 23:55:00 - 5:46:31 - Epoch: [270][50]	Time 0.788 (0.740)	Data 0.001 (0.035)	Loss 2.1190 (2.1308)	Lr: 0.0019
INFO - 09/02/20 23:55:39 - 5:47:11 - ============ Starting epoch 271 ... ============
INFO - 09/02/20 23:55:42 - 5:47:13 - Epoch: [271][0]	Time 2.538 (2.538)	Data 1.772 (1.772)	Loss 2.1512 (2.1512)	Lr: 0.0019
INFO - 09/02/20 23:56:19 - 5:47:51 - Epoch: [271][50]	Time 1.156 (0.784)	Data 0.001 (0.035)	Loss 2.1125 (2.1299)	Lr: 0.0019
INFO - 09/02/20 23:56:56 - 5:48:28 - ============ Starting epoch 272 ... ============
INFO - 09/02/20 23:56:59 - 5:48:30 - Epoch: [272][0]	Time 2.315 (2.315)	Data 1.598 (1.598)	Loss 2.1198 (2.1198)	Lr: 0.0019
INFO - 09/02/20 23:57:40 - 5:49:11 - Epoch: [272][50]	Time 1.160 (0.848)	Data 0.001 (0.032)	Loss 2.1306 (2.1337)	Lr: 0.0019
INFO - 09/02/20 23:58:13 - 5:49:44 - ============ Starting epoch 273 ... ============
INFO - 09/02/20 23:58:15 - 5:49:47 - Epoch: [273][0]	Time 2.374 (2.374)	Data 1.645 (1.645)	Loss 2.1292 (2.1292)	Lr: 0.0019
INFO - 09/02/20 23:58:58 - 5:50:30 - Epoch: [273][50]	Time 0.683 (0.892)	Data 0.000 (0.033)	Loss 2.1373 (2.1309)	Lr: 0.0019
INFO - 09/02/20 23:59:30 - 5:51:02 - ============ Starting epoch 274 ... ============
INFO - 09/02/20 23:59:33 - 5:51:04 - Epoch: [274][0]	Time 2.610 (2.610)	Data 1.926 (1.926)	Loss 2.1064 (2.1064)	Lr: 0.0019
INFO - 09/03/20 00:00:16 - 5:51:47 - Epoch: [274][50]	Time 0.678 (0.892)	Data 0.001 (0.038)	Loss 2.1119 (2.1236)	Lr: 0.0019
INFO - 09/03/20 00:00:47 - 5:52:19 - ============ Starting epoch 275 ... ============
INFO - 09/03/20 00:00:50 - 5:52:21 - Epoch: [275][0]	Time 2.385 (2.385)	Data 1.644 (1.644)	Loss 2.1121 (2.1121)	Lr: 0.0019
INFO - 09/03/20 00:01:33 - 5:53:04 - Epoch: [275][50]	Time 0.707 (0.887)	Data 0.001 (0.033)	Loss 2.1355 (2.1285)	Lr: 0.0018
INFO - 09/03/20 00:02:05 - 5:53:36 - ============ Starting epoch 276 ... ============
INFO - 09/03/20 00:02:07 - 5:53:38 - Epoch: [276][0]	Time 2.520 (2.520)	Data 1.815 (1.815)	Loss 2.1567 (2.1567)	Lr: 0.0018
INFO - 09/03/20 00:02:50 - 5:54:22 - Epoch: [276][50]	Time 0.698 (0.893)	Data 0.001 (0.036)	Loss 2.1184 (2.1315)	Lr: 0.0018
INFO - 09/03/20 00:03:22 - 5:54:53 - ============ Starting epoch 277 ... ============
INFO - 09/03/20 00:03:24 - 5:54:55 - Epoch: [277][0]	Time 2.325 (2.325)	Data 1.632 (1.632)	Loss 2.1253 (2.1253)	Lr: 0.0018
INFO - 09/03/20 00:04:07 - 5:55:38 - Epoch: [277][50]	Time 0.686 (0.883)	Data 0.001 (0.032)	Loss 2.1512 (2.1302)	Lr: 0.0018
INFO - 09/03/20 00:04:39 - 5:56:10 - ============ Starting epoch 278 ... ============
INFO - 09/03/20 00:04:41 - 5:56:13 - Epoch: [278][0]	Time 2.598 (2.598)	Data 1.801 (1.801)	Loss 2.0969 (2.0969)	Lr: 0.0018
INFO - 09/03/20 00:05:24 - 5:56:55 - Epoch: [278][50]	Time 0.703 (0.880)	Data 0.000 (0.036)	Loss 2.1090 (2.1244)	Lr: 0.0018
INFO - 09/03/20 00:05:56 - 5:57:27 - ============ Starting epoch 279 ... ============
INFO - 09/03/20 00:05:59 - 5:57:30 - Epoch: [279][0]	Time 2.813 (2.813)	Data 1.777 (1.777)	Loss 2.1031 (2.1031)	Lr: 0.0018
INFO - 09/03/20 00:06:40 - 5:58:11 - Epoch: [279][50]	Time 0.653 (0.855)	Data 0.001 (0.035)	Loss 2.1318 (2.1302)	Lr: 0.0018
INFO - 09/03/20 00:07:14 - 5:58:46 - ============ Starting epoch 280 ... ============
INFO - 09/03/20 00:07:17 - 5:58:49 - Epoch: [280][0]	Time 3.000 (3.000)	Data 1.816 (1.816)	Loss 2.1267 (2.1267)	Lr: 0.0018
INFO - 09/03/20 00:07:55 - 5:59:26 - Epoch: [280][50]	Time 0.707 (0.797)	Data 0.000 (0.036)	Loss 2.1462 (2.1321)	Lr: 0.0018
INFO - 09/03/20 00:08:33 - 6:00:04 - ============ Starting epoch 281 ... ============
INFO - 09/03/20 00:08:36 - 6:00:07 - Epoch: [281][0]	Time 2.814 (2.814)	Data 1.615 (1.615)	Loss 2.1316 (2.1316)	Lr: 0.0017
INFO - 09/03/20 00:09:11 - 6:00:42 - Epoch: [281][50]	Time 0.704 (0.738)	Data 0.000 (0.032)	Loss 2.1181 (2.1277)	Lr: 0.0017
INFO - 09/03/20 00:09:51 - 6:01:22 - ============ Starting epoch 282 ... ============
INFO - 09/03/20 00:09:54 - 6:01:25 - Epoch: [282][0]	Time 2.578 (2.578)	Data 1.845 (1.845)	Loss 2.1414 (2.1414)	Lr: 0.0017
INFO - 09/03/20 00:10:27 - 6:01:59 - Epoch: [282][50]	Time 0.693 (0.713)	Data 0.000 (0.037)	Loss 2.1195 (2.1282)	Lr: 0.0017
INFO - 09/03/20 00:11:08 - 6:02:39 - ============ Starting epoch 283 ... ============
INFO - 09/03/20 00:11:10 - 6:02:42 - Epoch: [283][0]	Time 2.325 (2.325)	Data 1.610 (1.610)	Loss 2.1318 (2.1318)	Lr: 0.0017
INFO - 09/03/20 00:11:44 - 6:03:16 - Epoch: [283][50]	Time 0.695 (0.714)	Data 0.000 (0.032)	Loss 2.1166 (2.1274)	Lr: 0.0017
INFO - 09/03/20 00:12:25 - 6:03:56 - ============ Starting epoch 284 ... ============
INFO - 09/03/20 00:12:27 - 6:03:59 - Epoch: [284][0]	Time 2.420 (2.420)	Data 1.696 (1.696)	Loss 2.1236 (2.1236)	Lr: 0.0017
INFO - 09/03/20 00:13:01 - 6:04:33 - Epoch: [284][50]	Time 0.808 (0.712)	Data 0.001 (0.034)	Loss 2.1384 (2.1299)	Lr: 0.0017
INFO - 09/03/20 00:13:41 - 6:05:13 - ============ Starting epoch 285 ... ============
INFO - 09/03/20 00:13:44 - 6:05:15 - Epoch: [285][0]	Time 2.644 (2.644)	Data 1.916 (1.916)	Loss 2.1246 (2.1246)	Lr: 0.0017
INFO - 09/03/20 00:14:19 - 6:05:50 - Epoch: [285][50]	Time 0.811 (0.737)	Data 0.000 (0.038)	Loss 2.1322 (2.1273)	Lr: 0.0017
INFO - 09/03/20 00:14:59 - 6:06:30 - ============ Starting epoch 286 ... ============
INFO - 09/03/20 00:15:01 - 6:06:32 - Epoch: [286][0]	Time 2.277 (2.277)	Data 1.588 (1.588)	Loss 2.1244 (2.1244)	Lr: 0.0017
INFO - 09/03/20 00:15:37 - 6:07:08 - Epoch: [286][50]	Time 1.110 (0.754)	Data 0.001 (0.031)	Loss 2.1115 (2.1290)	Lr: 0.0017
INFO - 09/03/20 00:16:15 - 6:07:47 - ============ Starting epoch 287 ... ============
INFO - 09/03/20 00:16:18 - 6:07:49 - Epoch: [287][0]	Time 2.456 (2.456)	Data 1.772 (1.772)	Loss 2.1219 (2.1219)	Lr: 0.0016
INFO - 09/03/20 00:16:56 - 6:08:28 - Epoch: [287][50]	Time 1.174 (0.804)	Data 0.001 (0.035)	Loss 2.1218 (2.1300)	Lr: 0.0016
INFO - 09/03/20 00:17:32 - 6:09:03 - ============ Starting epoch 288 ... ============
INFO - 09/03/20 00:17:34 - 6:09:06 - Epoch: [288][0]	Time 2.551 (2.551)	Data 1.826 (1.826)	Loss 2.1425 (2.1425)	Lr: 0.0016
INFO - 09/03/20 00:18:14 - 6:09:45 - Epoch: [288][50]	Time 1.156 (0.821)	Data 0.000 (0.036)	Loss 2.1363 (2.1259)	Lr: 0.0016
INFO - 09/03/20 00:18:50 - 6:10:21 - ============ Starting epoch 289 ... ============
INFO - 09/03/20 00:18:52 - 6:10:24 - Epoch: [289][0]	Time 2.682 (2.682)	Data 1.971 (1.971)	Loss 2.1280 (2.1280)	Lr: 0.0016
INFO - 09/03/20 00:19:34 - 6:11:06 - Epoch: [289][50]	Time 1.177 (0.873)	Data 0.001 (0.039)	Loss 2.1182 (2.1256)	Lr: 0.0016
INFO - 09/03/20 00:20:07 - 6:11:38 - ============ Starting epoch 290 ... ============
INFO - 09/03/20 00:20:09 - 6:11:40 - Epoch: [290][0]	Time 2.378 (2.378)	Data 1.631 (1.631)	Loss 2.1118 (2.1118)	Lr: 0.0016
INFO - 09/03/20 00:20:52 - 6:12:23 - Epoch: [290][50]	Time 0.705 (0.884)	Data 0.000 (0.032)	Loss 2.1074 (2.1232)	Lr: 0.0016
INFO - 09/03/20 00:21:24 - 6:12:55 - ============ Starting epoch 291 ... ============
INFO - 09/03/20 00:21:26 - 6:12:57 - Epoch: [291][0]	Time 2.453 (2.453)	Data 1.713 (1.713)	Loss 2.1169 (2.1169)	Lr: 0.0016
INFO - 09/03/20 00:22:09 - 6:13:40 - Epoch: [291][50]	Time 0.632 (0.888)	Data 0.001 (0.034)	Loss 2.1210 (2.1254)	Lr: 0.0016
INFO - 09/03/20 00:22:40 - 6:14:12 - ============ Starting epoch 292 ... ============
INFO - 09/03/20 00:22:43 - 6:14:14 - Epoch: [292][0]	Time 2.440 (2.440)	Data 1.688 (1.688)	Loss 2.1457 (2.1457)	Lr: 0.0016
INFO - 09/03/20 00:23:25 - 6:14:57 - Epoch: [292][50]	Time 0.657 (0.882)	Data 0.000 (0.033)	Loss 2.1184 (2.1228)	Lr: 0.0016
INFO - 09/03/20 00:23:57 - 6:15:28 - ============ Starting epoch 293 ... ============
INFO - 09/03/20 00:23:59 - 6:15:31 - Epoch: [293][0]	Time 2.613 (2.613)	Data 1.931 (1.931)	Loss 2.1310 (2.1310)	Lr: 0.0015
INFO - 09/03/20 00:24:43 - 6:16:14 - Epoch: [293][50]	Time 0.673 (0.897)	Data 0.000 (0.038)	Loss 2.1251 (2.1295)	Lr: 0.0015
INFO - 09/03/20 00:25:15 - 6:16:46 - ============ Starting epoch 294 ... ============
INFO - 09/03/20 00:25:17 - 6:16:48 - Epoch: [294][0]	Time 2.567 (2.567)	Data 1.762 (1.762)	Loss 2.1195 (2.1195)	Lr: 0.0015
INFO - 09/03/20 00:25:59 - 6:17:30 - Epoch: [294][50]	Time 0.689 (0.872)	Data 0.000 (0.035)	Loss 2.1301 (2.1235)	Lr: 0.0015
INFO - 09/03/20 00:26:32 - 6:18:03 - ============ Starting epoch 295 ... ============
INFO - 09/03/20 00:26:34 - 6:18:05 - Epoch: [295][0]	Time 2.725 (2.725)	Data 1.703 (1.703)	Loss 2.1093 (2.1093)	Lr: 0.0015
INFO - 09/03/20 00:27:15 - 6:18:46 - Epoch: [295][50]	Time 0.654 (0.854)	Data 0.000 (0.034)	Loss 2.1084 (2.1225)	Lr: 0.0015
INFO - 09/03/20 00:27:50 - 6:19:21 - ============ Starting epoch 296 ... ============
INFO - 09/03/20 00:27:53 - 6:19:24 - Epoch: [296][0]	Time 2.889 (2.889)	Data 1.692 (1.692)	Loss 2.1138 (2.1138)	Lr: 0.0015
INFO - 09/03/20 00:28:31 - 6:20:02 - Epoch: [296][50]	Time 0.682 (0.804)	Data 0.000 (0.033)	Loss 2.1181 (2.1255)	Lr: 0.0015
INFO - 09/03/20 00:29:08 - 6:20:39 - ============ Starting epoch 297 ... ============
INFO - 09/03/20 00:29:11 - 6:20:42 - Epoch: [297][0]	Time 3.146 (3.146)	Data 1.960 (1.960)	Loss 2.1019 (2.1019)	Lr: 0.0015
INFO - 09/03/20 00:29:46 - 6:21:17 - Epoch: [297][50]	Time 0.696 (0.749)	Data 0.000 (0.039)	Loss 2.1315 (2.1264)	Lr: 0.0015
INFO - 09/03/20 00:30:26 - 6:21:57 - ============ Starting epoch 298 ... ============
INFO - 09/03/20 00:30:29 - 6:22:00 - Epoch: [298][0]	Time 2.670 (2.670)	Data 1.932 (1.932)	Loss 2.1375 (2.1375)	Lr: 0.0015
INFO - 09/03/20 00:31:03 - 6:22:34 - Epoch: [298][50]	Time 0.683 (0.723)	Data 0.000 (0.038)	Loss 2.1110 (2.1261)	Lr: 0.0015
INFO - 09/03/20 00:31:43 - 6:23:15 - ============ Starting epoch 299 ... ============
INFO - 09/03/20 00:31:46 - 6:23:17 - Epoch: [299][0]	Time 2.592 (2.592)	Data 1.940 (1.940)	Loss 2.1179 (2.1179)	Lr: 0.0014
INFO - 09/03/20 00:32:20 - 6:23:51 - Epoch: [299][50]	Time 0.683 (0.717)	Data 0.000 (0.038)	Loss 2.1294 (2.1238)	Lr: 0.0014
INFO - 09/03/20 00:33:00 - 6:24:31 - ============ Starting epoch 300 ... ============
INFO - 09/03/20 00:33:03 - 6:24:34 - Epoch: [300][0]	Time 2.646 (2.646)	Data 1.969 (1.969)	Loss 2.1298 (2.1298)	Lr: 0.0014
INFO - 09/03/20 00:33:37 - 6:25:08 - Epoch: [300][50]	Time 0.718 (0.714)	Data 0.001 (0.039)	Loss 2.1263 (2.1225)	Lr: 0.0014
INFO - 09/03/20 00:34:18 - 6:25:49 - ============ Starting epoch 301 ... ============
INFO - 09/03/20 00:34:20 - 6:25:51 - Epoch: [301][0]	Time 2.353 (2.353)	Data 1.675 (1.675)	Loss 2.1176 (2.1176)	Lr: 0.0014
INFO - 09/03/20 00:34:55 - 6:26:26 - Epoch: [301][50]	Time 0.831 (0.734)	Data 0.000 (0.033)	Loss 2.0967 (2.1197)	Lr: 0.0014
INFO - 09/03/20 00:35:35 - 6:27:06 - ============ Starting epoch 302 ... ============
INFO - 09/03/20 00:35:37 - 6:27:08 - Epoch: [302][0]	Time 2.394 (2.394)	Data 1.679 (1.679)	Loss 2.1248 (2.1248)	Lr: 0.0014
INFO - 09/03/20 00:36:12 - 6:27:44 - Epoch: [302][50]	Time 0.798 (0.739)	Data 0.001 (0.033)	Loss 2.1260 (2.1233)	Lr: 0.0014
INFO - 09/03/20 00:36:51 - 6:28:23 - ============ Starting epoch 303 ... ============
INFO - 09/03/20 00:36:54 - 6:28:25 - Epoch: [303][0]	Time 2.520 (2.520)	Data 1.789 (1.789)	Loss 2.1447 (2.1447)	Lr: 0.0014
INFO - 09/03/20 00:37:30 - 6:29:01 - Epoch: [303][50]	Time 1.105 (0.759)	Data 0.001 (0.035)	Loss 2.1095 (2.1231)	Lr: 0.0014
INFO - 09/03/20 00:38:09 - 6:29:40 - ============ Starting epoch 304 ... ============
INFO - 09/03/20 00:38:11 - 6:29:43 - Epoch: [304][0]	Time 2.618 (2.618)	Data 1.962 (1.962)	Loss 2.1270 (2.1270)	Lr: 0.0014
INFO - 09/03/20 00:38:50 - 6:30:21 - Epoch: [304][50]	Time 1.102 (0.805)	Data 0.000 (0.039)	Loss 2.1258 (2.1253)	Lr: 0.0014
INFO - 09/03/20 00:39:26 - 6:30:57 - ============ Starting epoch 305 ... ============
INFO - 09/03/20 00:39:28 - 6:31:00 - Epoch: [305][0]	Time 2.792 (2.792)	Data 2.079 (2.079)	Loss 2.1324 (2.1324)	Lr: 0.0014
INFO - 09/03/20 00:40:10 - 6:31:41 - Epoch: [305][50]	Time 1.155 (0.874)	Data 0.001 (0.041)	Loss 2.1059 (2.1259)	Lr: 0.0013
INFO - 09/03/20 00:40:43 - 6:32:14 - ============ Starting epoch 306 ... ============
INFO - 09/03/20 00:40:45 - 6:32:17 - Epoch: [306][0]	Time 2.395 (2.395)	Data 1.653 (1.653)	Loss 2.1353 (2.1353)	Lr: 0.0013
INFO - 09/03/20 00:41:28 - 6:33:00 - Epoch: [306][50]	Time 0.702 (0.888)	Data 0.000 (0.033)	Loss 2.1071 (2.1241)	Lr: 0.0013
INFO - 09/03/20 00:42:00 - 6:33:31 - ============ Starting epoch 307 ... ============
INFO - 09/03/20 00:42:02 - 6:33:34 - Epoch: [307][0]	Time 2.742 (2.742)	Data 2.007 (2.007)	Loss 2.1146 (2.1146)	Lr: 0.0013
INFO - 09/03/20 00:42:45 - 6:34:16 - Epoch: [307][50]	Time 0.697 (0.888)	Data 0.000 (0.040)	Loss 2.1296 (2.1230)	Lr: 0.0013
INFO - 09/03/20 00:43:17 - 6:34:48 - ============ Starting epoch 308 ... ============
INFO - 09/03/20 00:43:19 - 6:34:50 - Epoch: [308][0]	Time 2.274 (2.274)	Data 1.590 (1.590)	Loss 2.1029 (2.1029)	Lr: 0.0013
INFO - 09/03/20 00:44:02 - 6:35:33 - Epoch: [308][50]	Time 0.685 (0.892)	Data 0.000 (0.032)	Loss 2.1191 (2.1198)	Lr: 0.0013
INFO - 09/03/20 00:44:34 - 6:36:05 - ============ Starting epoch 309 ... ============
INFO - 09/03/20 00:44:36 - 6:36:07 - Epoch: [309][0]	Time 2.379 (2.379)	Data 1.710 (1.710)	Loss 2.1386 (2.1386)	Lr: 0.0013
INFO - 09/03/20 00:45:19 - 6:36:50 - Epoch: [309][50]	Time 0.649 (0.884)	Data 0.000 (0.034)	Loss 2.1134 (2.1244)	Lr: 0.0013
INFO - 09/03/20 00:45:50 - 6:37:21 - ============ Starting epoch 310 ... ============
INFO - 09/03/20 00:45:53 - 6:37:24 - Epoch: [310][0]	Time 2.568 (2.568)	Data 1.750 (1.750)	Loss 2.1055 (2.1055)	Lr: 0.0013
INFO - 09/03/20 00:46:35 - 6:38:06 - Epoch: [310][50]	Time 0.662 (0.880)	Data 0.000 (0.035)	Loss 2.1077 (2.1215)	Lr: 0.0013
INFO - 09/03/20 00:47:07 - 6:38:39 - ============ Starting epoch 311 ... ============
INFO - 09/03/20 00:47:10 - 6:38:41 - Epoch: [311][0]	Time 2.568 (2.568)	Data 1.774 (1.774)	Loss 2.1285 (2.1285)	Lr: 0.0013
INFO - 09/03/20 00:47:51 - 6:39:23 - Epoch: [311][50]	Time 0.700 (0.863)	Data 0.000 (0.035)	Loss 2.1256 (2.1233)	Lr: 0.0013
INFO - 09/03/20 00:48:25 - 6:39:56 - ============ Starting epoch 312 ... ============
INFO - 09/03/20 00:48:28 - 6:39:59 - Epoch: [312][0]	Time 2.835 (2.835)	Data 1.685 (1.685)	Loss 2.1150 (2.1150)	Lr: 0.0013
INFO - 09/03/20 00:49:07 - 6:40:38 - Epoch: [312][50]	Time 0.653 (0.817)	Data 0.000 (0.033)	Loss 2.1066 (2.1228)	Lr: 0.0012
INFO - 09/03/20 00:49:42 - 6:41:14 - ============ Starting epoch 313 ... ============
INFO - 09/03/20 00:49:45 - 6:41:17 - Epoch: [313][0]	Time 3.014 (3.014)	Data 1.789 (1.789)	Loss 2.1326 (2.1326)	Lr: 0.0012
INFO - 09/03/20 00:50:22 - 6:41:53 - Epoch: [313][50]	Time 0.689 (0.781)	Data 0.001 (0.036)	Loss 2.1253 (2.1276)	Lr: 0.0012
INFO - 09/03/20 00:51:01 - 6:42:32 - ============ Starting epoch 314 ... ============
INFO - 09/03/20 00:51:04 - 6:42:35 - Epoch: [314][0]	Time 2.612 (2.612)	Data 1.798 (1.798)	Loss 2.1218 (2.1218)	Lr: 0.0012
INFO - 09/03/20 00:51:38 - 6:43:09 - Epoch: [314][50]	Time 0.682 (0.715)	Data 0.000 (0.036)	Loss 2.1257 (2.1263)	Lr: 0.0012
INFO - 09/03/20 00:52:18 - 6:43:49 - ============ Starting epoch 315 ... ============
INFO - 09/03/20 00:52:20 - 6:43:52 - Epoch: [315][0]	Time 2.638 (2.638)	Data 1.955 (1.955)	Loss 2.1151 (2.1151)	Lr: 0.0012
INFO - 09/03/20 00:52:54 - 6:44:26 - Epoch: [315][50]	Time 0.698 (0.717)	Data 0.000 (0.039)	Loss 2.1319 (2.1222)	Lr: 0.0012
INFO - 09/03/20 00:53:35 - 6:45:06 - ============ Starting epoch 316 ... ============
INFO - 09/03/20 00:53:38 - 6:45:09 - Epoch: [316][0]	Time 2.574 (2.574)	Data 1.853 (1.853)	Loss 2.1268 (2.1268)	Lr: 0.0012
INFO - 09/03/20 00:54:12 - 6:45:43 - Epoch: [316][50]	Time 0.654 (0.717)	Data 0.001 (0.037)	Loss 2.1268 (2.1271)	Lr: 0.0012
INFO - 09/03/20 00:54:52 - 6:46:23 - ============ Starting epoch 317 ... ============
INFO - 09/03/20 00:54:55 - 6:46:26 - Epoch: [317][0]	Time 2.690 (2.690)	Data 1.997 (1.997)	Loss 2.1417 (2.1417)	Lr: 0.0012
INFO - 09/03/20 00:55:29 - 6:47:00 - Epoch: [317][50]	Time 0.636 (0.716)	Data 0.000 (0.040)	Loss 2.1141 (2.1225)	Lr: 0.0012
INFO - 09/03/20 00:56:09 - 6:47:40 - ============ Starting epoch 318 ... ============
INFO - 09/03/20 00:56:11 - 6:47:43 - Epoch: [318][0]	Time 2.313 (2.313)	Data 1.601 (1.601)	Loss 2.1312 (2.1312)	Lr: 0.0012
INFO - 09/03/20 00:56:46 - 6:48:17 - Epoch: [318][50]	Time 0.785 (0.717)	Data 0.001 (0.032)	Loss 2.1122 (2.1236)	Lr: 0.0012
INFO - 09/03/20 00:57:26 - 6:48:57 - ============ Starting epoch 319 ... ============
INFO - 09/03/20 00:57:29 - 6:49:00 - Epoch: [319][0]	Time 2.406 (2.406)	Data 1.683 (1.683)	Loss 2.1079 (2.1079)	Lr: 0.0012
INFO - 09/03/20 00:58:04 - 6:49:35 - Epoch: [319][50]	Time 0.813 (0.731)	Data 0.001 (0.033)	Loss 2.1083 (2.1216)	Lr: 0.0011
INFO - 09/03/20 00:58:43 - 6:50:14 - ============ Starting epoch 320 ... ============
INFO - 09/03/20 00:58:45 - 6:50:17 - Epoch: [320][0]	Time 2.427 (2.427)	Data 1.743 (1.743)	Loss 2.1147 (2.1147)	Lr: 0.0011
INFO - 09/03/20 00:59:21 - 6:50:52 - Epoch: [320][50]	Time 1.148 (0.751)	Data 0.001 (0.035)	Loss 2.1123 (2.1245)	Lr: 0.0011
INFO - 09/03/20 01:00:00 - 6:51:31 - ============ Starting epoch 321 ... ============
INFO - 09/03/20 01:00:02 - 6:51:34 - Epoch: [321][0]	Time 2.453 (2.453)	Data 1.746 (1.746)	Loss 2.1181 (2.1181)	Lr: 0.0011
INFO - 09/03/20 01:00:41 - 6:52:13 - Epoch: [321][50]	Time 1.216 (0.815)	Data 0.000 (0.035)	Loss 2.1043 (2.1195)	Lr: 0.0011
INFO - 09/03/20 01:01:17 - 6:52:48 - ============ Starting epoch 322 ... ============
INFO - 09/03/20 01:01:19 - 6:52:50 - Epoch: [322][0]	Time 2.256 (2.256)	Data 1.606 (1.606)	Loss 2.1096 (2.1096)	Lr: 0.0011
INFO - 09/03/20 01:02:00 - 6:53:31 - Epoch: [322][50]	Time 1.153 (0.844)	Data 0.001 (0.032)	Loss 2.1225 (2.1272)	Lr: 0.0011
INFO - 09/03/20 01:02:33 - 6:54:04 - ============ Starting epoch 323 ... ============
INFO - 09/03/20 01:02:35 - 6:54:06 - Epoch: [323][0]	Time 2.252 (2.252)	Data 1.543 (1.543)	Loss 2.1180 (2.1180)	Lr: 0.0011
INFO - 09/03/20 01:03:18 - 6:54:50 - Epoch: [323][50]	Time 0.700 (0.892)	Data 0.000 (0.031)	Loss 2.1127 (2.1214)	Lr: 0.0011
INFO - 09/03/20 01:03:50 - 6:55:21 - ============ Starting epoch 324 ... ============
INFO - 09/03/20 01:03:53 - 6:55:24 - Epoch: [324][0]	Time 2.504 (2.504)	Data 1.814 (1.814)	Loss 2.1307 (2.1307)	Lr: 0.0011
INFO - 09/03/20 01:04:36 - 6:56:07 - Epoch: [324][50]	Time 0.689 (0.888)	Data 0.000 (0.036)	Loss 2.1110 (2.1231)	Lr: 0.0011
INFO - 09/03/20 01:05:07 - 6:56:38 - ============ Starting epoch 325 ... ============
INFO - 09/03/20 01:05:10 - 6:56:41 - Epoch: [325][0]	Time 2.526 (2.526)	Data 1.828 (1.828)	Loss 2.1395 (2.1395)	Lr: 0.0011
INFO - 09/03/20 01:05:52 - 6:57:23 - Epoch: [325][50]	Time 0.663 (0.885)	Data 0.000 (0.036)	Loss 2.1065 (2.1223)	Lr: 0.0011
INFO - 09/03/20 01:06:24 - 6:57:55 - ============ Starting epoch 326 ... ============
INFO - 09/03/20 01:06:27 - 6:57:58 - Epoch: [326][0]	Time 2.494 (2.494)	Data 1.619 (1.619)	Loss 2.1160 (2.1160)	Lr: 0.0011
INFO - 09/03/20 01:07:10 - 6:58:41 - Epoch: [326][50]	Time 0.669 (0.889)	Data 0.001 (0.032)	Loss 2.1088 (2.1194)	Lr: 0.0011
INFO - 09/03/20 01:07:42 - 6:59:13 - ============ Starting epoch 327 ... ============
INFO - 09/03/20 01:07:44 - 6:59:15 - Epoch: [327][0]	Time 2.505 (2.505)	Data 1.702 (1.702)	Loss 2.1161 (2.1161)	Lr: 0.0011
INFO - 09/03/20 01:08:26 - 6:59:57 - Epoch: [327][50]	Time 0.689 (0.866)	Data 0.001 (0.034)	Loss 2.1135 (2.1193)	Lr: 0.0010
INFO - 09/03/20 01:08:58 - 7:00:30 - ============ Starting epoch 328 ... ============
INFO - 09/03/20 01:09:01 - 7:00:33 - Epoch: [328][0]	Time 2.857 (2.857)	Data 1.826 (1.826)	Loss 2.1392 (2.1392)	Lr: 0.0010
INFO - 09/03/20 01:09:42 - 7:01:14 - Epoch: [328][50]	Time 0.635 (0.864)	Data 0.001 (0.036)	Loss 2.1194 (2.1227)	Lr: 0.0010
INFO - 09/03/20 01:10:17 - 7:01:48 - ============ Starting epoch 329 ... ============
INFO - 09/03/20 01:10:20 - 7:01:51 - Epoch: [329][0]	Time 2.814 (2.814)	Data 1.688 (1.688)	Loss 2.1131 (2.1131)	Lr: 0.0010
INFO - 09/03/20 01:10:58 - 7:02:29 - Epoch: [329][50]	Time 0.685 (0.801)	Data 0.000 (0.033)	Loss 2.1329 (2.1202)	Lr: 0.0010
INFO - 09/03/20 01:11:35 - 7:03:06 - ============ Starting epoch 330 ... ============
INFO - 09/03/20 01:11:38 - 7:03:09 - Epoch: [330][0]	Time 2.839 (2.839)	Data 1.686 (1.686)	Loss 2.1136 (2.1136)	Lr: 0.0010
INFO - 09/03/20 01:12:13 - 7:03:44 - Epoch: [330][50]	Time 0.630 (0.741)	Data 0.000 (0.033)	Loss 2.0971 (2.1179)	Lr: 0.0010
INFO - 09/03/20 01:12:54 - 7:04:25 - ============ Starting epoch 331 ... ============
INFO - 09/03/20 01:12:56 - 7:04:27 - Epoch: [331][0]	Time 2.372 (2.372)	Data 1.649 (1.649)	Loss 2.1344 (2.1344)	Lr: 0.0010
INFO - 09/03/20 01:13:30 - 7:05:01 - Epoch: [331][50]	Time 0.630 (0.718)	Data 0.000 (0.033)	Loss 2.1256 (2.1186)	Lr: 0.0010
INFO - 09/03/20 01:14:10 - 7:05:41 - ============ Starting epoch 332 ... ============
INFO - 09/03/20 01:14:13 - 7:05:44 - Epoch: [332][0]	Time 2.483 (2.483)	Data 1.704 (1.704)	Loss 2.1108 (2.1108)	Lr: 0.0010
INFO - 09/03/20 01:14:46 - 7:06:18 - Epoch: [332][50]	Time 0.626 (0.708)	Data 0.000 (0.034)	Loss 2.1138 (2.1207)	Lr: 0.0010
INFO - 09/03/20 01:15:27 - 7:06:58 - ============ Starting epoch 333 ... ============
INFO - 09/03/20 01:15:29 - 7:07:01 - Epoch: [333][0]	Time 2.670 (2.670)	Data 1.938 (1.938)	Loss 2.1158 (2.1158)	Lr: 0.0010
INFO - 09/03/20 01:16:04 - 7:07:35 - Epoch: [333][50]	Time 0.707 (0.723)	Data 0.000 (0.038)	Loss 2.1128 (2.1186)	Lr: 0.0010
INFO - 09/03/20 01:16:44 - 7:08:15 - ============ Starting epoch 334 ... ============
INFO - 09/03/20 01:16:47 - 7:08:18 - Epoch: [334][0]	Time 2.667 (2.667)	Data 1.943 (1.943)	Loss 2.1237 (2.1237)	Lr: 0.0010
INFO - 09/03/20 01:17:21 - 7:08:52 - Epoch: [334][50]	Time 0.625 (0.715)	Data 0.001 (0.038)	Loss 2.1167 (2.1214)	Lr: 0.0010
INFO - 09/03/20 01:18:01 - 7:09:32 - ============ Starting epoch 335 ... ============
INFO - 09/03/20 01:18:03 - 7:09:34 - Epoch: [335][0]	Time 2.245 (2.245)	Data 1.538 (1.538)	Loss 2.1360 (2.1360)	Lr: 0.0010
INFO - 09/03/20 01:18:37 - 7:10:09 - Epoch: [335][50]	Time 0.773 (0.716)	Data 0.000 (0.031)	Loss 2.1032 (2.1199)	Lr: 0.0010
INFO - 09/03/20 01:19:18 - 7:10:49 - ============ Starting epoch 336 ... ============
INFO - 09/03/20 01:19:20 - 7:10:51 - Epoch: [336][0]	Time 2.475 (2.475)	Data 1.791 (1.791)	Loss 2.1198 (2.1198)	Lr: 0.0010
INFO - 09/03/20 01:19:55 - 7:11:26 - Epoch: [336][50]	Time 0.771 (0.737)	Data 0.000 (0.035)	Loss 2.1069 (2.1198)	Lr: 0.0009
INFO - 09/03/20 01:20:35 - 7:12:06 - ============ Starting epoch 337 ... ============
INFO - 09/03/20 01:20:37 - 7:12:08 - Epoch: [337][0]	Time 2.445 (2.445)	Data 1.766 (1.766)	Loss 2.1087 (2.1087)	Lr: 0.0009
INFO - 09/03/20 01:21:14 - 7:12:45 - Epoch: [337][50]	Time 1.162 (0.768)	Data 0.001 (0.035)	Loss 2.1110 (2.1201)	Lr: 0.0009
INFO - 09/03/20 01:21:51 - 7:13:22 - ============ Starting epoch 338 ... ============
INFO - 09/03/20 01:21:54 - 7:13:25 - Epoch: [338][0]	Time 2.415 (2.415)	Data 1.670 (1.670)	Loss 2.1363 (2.1363)	Lr: 0.0009
INFO - 09/03/20 01:22:34 - 7:14:05 - Epoch: [338][50]	Time 1.226 (0.834)	Data 0.001 (0.033)	Loss 2.1116 (2.1186)	Lr: 0.0009
INFO - 09/03/20 01:23:08 - 7:14:40 - ============ Starting epoch 339 ... ============
INFO - 09/03/20 01:23:11 - 7:14:42 - Epoch: [339][0]	Time 2.514 (2.514)	Data 1.827 (1.827)	Loss 2.1268 (2.1268)	Lr: 0.0009
INFO - 09/03/20 01:23:54 - 7:15:25 - Epoch: [339][50]	Time 1.143 (0.891)	Data 0.000 (0.036)	Loss 2.1105 (2.1216)	Lr: 0.0009
INFO - 09/03/20 01:24:25 - 7:15:56 - ============ Starting epoch 340 ... ============
INFO - 09/03/20 01:24:28 - 7:15:59 - Epoch: [340][0]	Time 2.604 (2.604)	Data 1.829 (1.829)	Loss 2.1131 (2.1131)	Lr: 0.0009
INFO - 09/03/20 01:25:10 - 7:16:42 - Epoch: [340][50]	Time 0.630 (0.886)	Data 0.000 (0.036)	Loss 2.1068 (2.1166)	Lr: 0.0009
INFO - 09/03/20 01:25:42 - 7:17:14 - ============ Starting epoch 341 ... ============
INFO - 09/03/20 01:25:45 - 7:17:16 - Epoch: [341][0]	Time 2.584 (2.584)	Data 1.827 (1.827)	Loss 2.1364 (2.1364)	Lr: 0.0009
INFO - 09/03/20 01:26:28 - 7:17:59 - Epoch: [341][50]	Time 0.695 (0.894)	Data 0.000 (0.036)	Loss 2.1184 (2.1220)	Lr: 0.0009
INFO - 09/03/20 01:27:00 - 7:18:31 - ============ Starting epoch 342 ... ============
INFO - 09/03/20 01:27:02 - 7:18:33 - Epoch: [342][0]	Time 2.357 (2.357)	Data 1.666 (1.666)	Loss 2.1170 (2.1170)	Lr: 0.0009
INFO - 09/03/20 01:27:45 - 7:19:16 - Epoch: [342][50]	Time 0.631 (0.881)	Data 0.000 (0.033)	Loss 2.1114 (2.1190)	Lr: 0.0009
INFO - 09/03/20 01:28:16 - 7:19:47 - ============ Starting epoch 343 ... ============
INFO - 09/03/20 01:28:18 - 7:19:50 - Epoch: [343][0]	Time 2.403 (2.403)	Data 1.671 (1.671)	Loss 2.1246 (2.1246)	Lr: 0.0009
INFO - 09/03/20 01:29:01 - 7:20:33 - Epoch: [343][50]	Time 0.678 (0.892)	Data 0.000 (0.033)	Loss 2.1027 (2.1172)	Lr: 0.0009
INFO - 09/03/20 01:29:34 - 7:21:05 - ============ Starting epoch 344 ... ============
INFO - 09/03/20 01:29:36 - 7:21:08 - Epoch: [344][0]	Time 2.790 (2.790)	Data 1.967 (1.967)	Loss 2.1115 (2.1115)	Lr: 0.0009
INFO - 09/03/20 01:30:18 - 7:21:49 - Epoch: [344][50]	Time 0.694 (0.873)	Data 0.000 (0.039)	Loss 2.1278 (2.1200)	Lr: 0.0009
INFO - 09/03/20 01:30:51 - 7:22:22 - ============ Starting epoch 345 ... ============
INFO - 09/03/20 01:30:53 - 7:22:25 - Epoch: [345][0]	Time 2.790 (2.790)	Data 1.674 (1.674)	Loss 2.1153 (2.1153)	Lr: 0.0009
INFO - 09/03/20 01:31:34 - 7:23:05 - Epoch: [345][50]	Time 0.649 (0.849)	Data 0.000 (0.033)	Loss 2.0955 (2.1135)	Lr: 0.0009
INFO - 09/03/20 01:32:08 - 7:23:39 - ============ Starting epoch 346 ... ============
INFO - 09/03/20 01:32:11 - 7:23:42 - Epoch: [346][0]	Time 3.075 (3.075)	Data 2.022 (2.022)	Loss 2.1278 (2.1278)	Lr: 0.0009
INFO - 09/03/20 01:32:51 - 7:24:22 - Epoch: [346][50]	Time 0.650 (0.842)	Data 0.000 (0.040)	Loss 2.1214 (2.1176)	Lr: 0.0008
INFO - 09/03/20 01:33:26 - 7:24:57 - ============ Starting epoch 347 ... ============
INFO - 09/03/20 01:33:29 - 7:25:00 - Epoch: [347][0]	Time 3.158 (3.158)	Data 2.011 (2.011)	Loss 2.1112 (2.1112)	Lr: 0.0008
INFO - 09/03/20 01:34:06 - 7:25:37 - Epoch: [347][50]	Time 0.625 (0.783)	Data 0.000 (0.040)	Loss 2.1082 (2.1140)	Lr: 0.0008
INFO - 09/03/20 01:34:44 - 7:26:15 - ============ Starting epoch 348 ... ============
INFO - 09/03/20 01:34:47 - 7:26:18 - Epoch: [348][0]	Time 3.119 (3.119)	Data 1.961 (1.961)	Loss 2.1081 (2.1081)	Lr: 0.0008
INFO - 09/03/20 01:35:21 - 7:26:53 - Epoch: [348][50]	Time 0.693 (0.736)	Data 0.000 (0.039)	Loss 2.1051 (2.1205)	Lr: 0.0008
INFO - 09/03/20 01:36:02 - 7:27:33 - ============ Starting epoch 349 ... ============
INFO - 09/03/20 01:36:05 - 7:27:36 - Epoch: [349][0]	Time 2.737 (2.737)	Data 2.048 (2.048)	Loss 2.1415 (2.1415)	Lr: 0.0008
INFO - 09/03/20 01:36:39 - 7:28:10 - Epoch: [349][50]	Time 0.693 (0.724)	Data 0.000 (0.040)	Loss 2.0892 (2.1171)	Lr: 0.0008
INFO - 09/03/20 01:37:19 - 7:28:50 - ============ Starting epoch 350 ... ============
INFO - 09/03/20 01:37:22 - 7:28:53 - Epoch: [350][0]	Time 2.362 (2.362)	Data 1.701 (1.701)	Loss 2.1299 (2.1299)	Lr: 0.0008
INFO - 09/03/20 01:37:55 - 7:29:26 - Epoch: [350][50]	Time 0.688 (0.707)	Data 0.000 (0.034)	Loss 2.1044 (2.1140)	Lr: 0.0008
INFO - 09/03/20 01:38:36 - 7:30:07 - ============ Starting epoch 351 ... ============
INFO - 09/03/20 01:38:38 - 7:30:10 - Epoch: [351][0]	Time 2.385 (2.385)	Data 1.687 (1.687)	Loss 2.1072 (2.1072)	Lr: 0.0008
INFO - 09/03/20 01:39:13 - 7:30:44 - Epoch: [351][50]	Time 0.815 (0.719)	Data 0.000 (0.033)	Loss 2.1101 (2.1164)	Lr: 0.0008
INFO - 09/03/20 01:39:53 - 7:31:24 - ============ Starting epoch 352 ... ============
INFO - 09/03/20 01:39:55 - 7:31:27 - Epoch: [352][0]	Time 2.381 (2.381)	Data 1.690 (1.690)	Loss 2.1239 (2.1239)	Lr: 0.0008
INFO - 09/03/20 01:40:30 - 7:32:01 - Epoch: [352][50]	Time 0.814 (0.731)	Data 0.001 (0.034)	Loss 2.0951 (2.1179)	Lr: 0.0008
INFO - 09/03/20 01:41:09 - 7:32:41 - ============ Starting epoch 353 ... ============
INFO - 09/03/20 01:41:12 - 7:32:43 - Epoch: [353][0]	Time 2.215 (2.215)	Data 1.543 (1.543)	Loss 2.1207 (2.1207)	Lr: 0.0008
INFO - 09/03/20 01:41:48 - 7:33:20 - Epoch: [353][50]	Time 1.139 (0.766)	Data 0.001 (0.031)	Loss 2.1015 (2.1179)	Lr: 0.0008
INFO - 09/03/20 01:42:26 - 7:33:57 - ============ Starting epoch 354 ... ============
INFO - 09/03/20 01:42:29 - 7:34:00 - Epoch: [354][0]	Time 2.628 (2.628)	Data 1.903 (1.903)	Loss 2.1307 (2.1307)	Lr: 0.0008
INFO - 09/03/20 01:43:09 - 7:34:40 - Epoch: [354][50]	Time 1.159 (0.843)	Data 0.000 (0.038)	Loss 2.1055 (2.1181)	Lr: 0.0008
INFO - 09/03/20 01:43:43 - 7:35:14 - ============ Starting epoch 355 ... ============
INFO - 09/03/20 01:43:45 - 7:35:17 - Epoch: [355][0]	Time 2.450 (2.450)	Data 1.775 (1.775)	Loss 2.1204 (2.1204)	Lr: 0.0008
INFO - 09/03/20 01:44:28 - 7:35:59 - Epoch: [355][50]	Time 0.689 (0.883)	Data 0.001 (0.035)	Loss 2.1109 (2.1148)	Lr: 0.0008
INFO - 09/03/20 01:45:00 - 7:36:31 - ============ Starting epoch 356 ... ============
INFO - 09/03/20 01:45:02 - 7:36:33 - Epoch: [356][0]	Time 2.474 (2.474)	Data 1.752 (1.752)	Loss 2.1190 (2.1190)	Lr: 0.0008
INFO - 09/03/20 01:45:45 - 7:37:16 - Epoch: [356][50]	Time 0.708 (0.890)	Data 0.001 (0.035)	Loss 2.1109 (2.1211)	Lr: 0.0008
INFO - 09/03/20 01:46:17 - 7:37:48 - ============ Starting epoch 357 ... ============
INFO - 09/03/20 01:46:19 - 7:37:50 - Epoch: [357][0]	Time 2.465 (2.465)	Data 1.691 (1.691)	Loss 2.1140 (2.1140)	Lr: 0.0008
INFO - 09/03/20 01:47:02 - 7:38:33 - Epoch: [357][50]	Time 0.680 (0.881)	Data 0.001 (0.034)	Loss 2.1201 (2.1208)	Lr: 0.0008
INFO - 09/03/20 01:47:33 - 7:39:04 - ============ Starting epoch 358 ... ============
INFO - 09/03/20 01:47:36 - 7:39:07 - Epoch: [358][0]	Time 2.506 (2.506)	Data 1.801 (1.801)	Loss 2.1147 (2.1147)	Lr: 0.0008
INFO - 09/03/20 01:48:18 - 7:39:50 - Epoch: [358][50]	Time 0.693 (0.890)	Data 0.001 (0.036)	Loss 2.1024 (2.1125)	Lr: 0.0007
INFO - 09/03/20 01:48:50 - 7:40:21 - ============ Starting epoch 359 ... ============
INFO - 09/03/20 01:48:53 - 7:40:24 - Epoch: [359][0]	Time 2.314 (2.314)	Data 1.599 (1.599)	Loss 2.1074 (2.1074)	Lr: 0.0007
INFO - 09/03/20 01:49:36 - 7:41:07 - Epoch: [359][50]	Time 0.715 (0.889)	Data 0.000 (0.032)	Loss 2.1379 (2.1187)	Lr: 0.0007
INFO - 09/03/20 01:50:07 - 7:41:38 - ============ Starting epoch 360 ... ============
INFO - 09/03/20 01:50:09 - 7:41:41 - Epoch: [360][0]	Time 2.506 (2.506)	Data 1.749 (1.749)	Loss 2.1133 (2.1133)	Lr: 0.0007
INFO - 09/03/20 01:50:52 - 7:42:23 - Epoch: [360][50]	Time 0.655 (0.881)	Data 0.001 (0.035)	Loss 2.1255 (2.1158)	Lr: 0.0007
INFO - 09/03/20 01:51:24 - 7:42:55 - ============ Starting epoch 361 ... ============
INFO - 09/03/20 01:51:26 - 7:42:57 - Epoch: [361][0]	Time 2.420 (2.420)	Data 1.727 (1.727)	Loss 2.1119 (2.1119)	Lr: 0.0007
INFO - 09/03/20 01:52:09 - 7:43:40 - Epoch: [361][50]	Time 0.686 (0.892)	Data 0.000 (0.034)	Loss 2.1082 (2.1223)	Lr: 0.0007
INFO - 09/03/20 01:52:41 - 7:44:12 - ============ Starting epoch 362 ... ============
INFO - 09/03/20 01:52:43 - 7:44:15 - Epoch: [362][0]	Time 2.582 (2.582)	Data 1.781 (1.781)	Loss 2.1201 (2.1201)	Lr: 0.0007
INFO - 09/03/20 01:53:25 - 7:44:56 - Epoch: [362][50]	Time 0.654 (0.872)	Data 0.000 (0.035)	Loss 2.1121 (2.1174)	Lr: 0.0007
INFO - 09/03/20 01:53:57 - 7:45:29 - ============ Starting epoch 363 ... ============
INFO - 09/03/20 01:54:00 - 7:45:31 - Epoch: [363][0]	Time 2.619 (2.619)	Data 1.806 (1.806)	Loss 2.1099 (2.1099)	Lr: 0.0007
INFO - 09/03/20 01:54:42 - 7:46:13 - Epoch: [363][50]	Time 0.653 (0.867)	Data 0.000 (0.036)	Loss 2.1082 (2.1114)	Lr: 0.0007
INFO - 09/03/20 01:55:15 - 7:46:46 - ============ Starting epoch 364 ... ============
INFO - 09/03/20 01:55:18 - 7:46:49 - Epoch: [364][0]	Time 2.888 (2.888)	Data 1.731 (1.731)	Loss 2.1081 (2.1081)	Lr: 0.0007
INFO - 09/03/20 01:55:58 - 7:47:29 - Epoch: [364][50]	Time 0.699 (0.846)	Data 0.001 (0.034)	Loss 2.1035 (2.1166)	Lr: 0.0007
INFO - 09/03/20 01:56:33 - 7:48:05 - ============ Starting epoch 365 ... ============
INFO - 09/03/20 01:56:36 - 7:48:08 - Epoch: [365][0]	Time 2.962 (2.962)	Data 1.792 (1.792)	Loss 2.1358 (2.1358)	Lr: 0.0007
INFO - 09/03/20 01:57:13 - 7:48:44 - Epoch: [365][50]	Time 0.698 (0.774)	Data 0.000 (0.036)	Loss 2.1166 (2.1193)	Lr: 0.0007
INFO - 09/03/20 01:57:51 - 7:49:22 - ============ Starting epoch 366 ... ============
INFO - 09/03/20 01:57:54 - 7:49:26 - Epoch: [366][0]	Time 3.047 (3.047)	Data 1.927 (1.927)	Loss 2.1129 (2.1129)	Lr: 0.0007
INFO - 09/03/20 01:58:28 - 7:50:00 - Epoch: [366][50]	Time 0.713 (0.729)	Data 0.000 (0.038)	Loss 2.1276 (2.1238)	Lr: 0.0007
INFO - 09/03/20 01:59:09 - 7:50:40 - ============ Starting epoch 367 ... ============
INFO - 09/03/20 01:59:11 - 7:50:43 - Epoch: [367][0]	Time 2.462 (2.462)	Data 1.755 (1.755)	Loss 2.1332 (2.1332)	Lr: 0.0007
INFO - 09/03/20 01:59:45 - 7:51:17 - Epoch: [367][50]	Time 0.709 (0.712)	Data 0.000 (0.035)	Loss 2.0978 (2.1177)	Lr: 0.0007
INFO - 09/03/20 02:00:25 - 7:51:57 - ============ Starting epoch 368 ... ============
INFO - 09/03/20 02:00:28 - 7:51:59 - Epoch: [368][0]	Time 2.391 (2.391)	Data 1.676 (1.676)	Loss 2.1304 (2.1304)	Lr: 0.0007
INFO - 09/03/20 02:01:02 - 7:52:33 - Epoch: [368][50]	Time 0.694 (0.711)	Data 0.000 (0.033)	Loss 2.1002 (2.1165)	Lr: 0.0007
INFO - 09/03/20 02:01:42 - 7:53:14 - ============ Starting epoch 369 ... ============
INFO - 09/03/20 02:01:45 - 7:53:16 - Epoch: [369][0]	Time 2.535 (2.535)	Data 1.876 (1.876)	Loss 2.0992 (2.0992)	Lr: 0.0007
INFO - 09/03/20 02:02:19 - 7:53:50 - Epoch: [369][50]	Time 0.637 (0.715)	Data 0.000 (0.037)	Loss 2.1185 (2.1148)	Lr: 0.0007
INFO - 09/03/20 02:02:59 - 7:54:31 - ============ Starting epoch 370 ... ============
INFO - 09/03/20 02:03:02 - 7:54:33 - Epoch: [370][0]	Time 2.706 (2.706)	Data 1.987 (1.987)	Loss 2.1089 (2.1089)	Lr: 0.0007
INFO - 09/03/20 02:03:37 - 7:55:08 - Epoch: [370][50]	Time 0.810 (0.732)	Data 0.000 (0.039)	Loss 2.1178 (2.1137)	Lr: 0.0007
INFO - 09/03/20 02:04:16 - 7:55:47 - ============ Starting epoch 371 ... ============
INFO - 09/03/20 02:04:19 - 7:55:50 - Epoch: [371][0]	Time 2.488 (2.488)	Data 1.716 (1.716)	Loss 2.0959 (2.0959)	Lr: 0.0007
INFO - 09/03/20 02:04:55 - 7:56:26 - Epoch: [371][50]	Time 1.177 (0.764)	Data 0.000 (0.034)	Loss 2.1202 (2.1169)	Lr: 0.0007
INFO - 09/03/20 02:05:33 - 7:57:05 - ============ Starting epoch 372 ... ============
INFO - 09/03/20 02:05:36 - 7:57:07 - Epoch: [372][0]	Time 2.339 (2.339)	Data 1.616 (1.616)	Loss 2.1017 (2.1017)	Lr: 0.0007
INFO - 09/03/20 02:06:16 - 7:57:47 - Epoch: [372][50]	Time 1.161 (0.832)	Data 0.001 (0.032)	Loss 2.1086 (2.1181)	Lr: 0.0007
INFO - 09/03/20 02:06:50 - 7:58:21 - ============ Starting epoch 373 ... ============
INFO - 09/03/20 02:06:52 - 7:58:23 - Epoch: [373][0]	Time 2.386 (2.386)	Data 1.697 (1.697)	Loss 2.1186 (2.1186)	Lr: 0.0007
INFO - 09/03/20 02:07:35 - 7:59:06 - Epoch: [373][50]	Time 1.116 (0.882)	Data 0.000 (0.034)	Loss 2.1164 (2.1160)	Lr: 0.0007
INFO - 09/03/20 02:08:07 - 7:59:38 - ============ Starting epoch 374 ... ============
INFO - 09/03/20 02:08:10 - 7:59:41 - Epoch: [374][0]	Time 2.717 (2.717)	Data 1.934 (1.934)	Loss 2.1210 (2.1210)	Lr: 0.0007
INFO - 09/03/20 02:08:53 - 8:00:24 - Epoch: [374][50]	Time 0.906 (0.896)	Data 0.000 (0.038)	Loss 2.0975 (2.1187)	Lr: 0.0007
INFO - 09/03/20 02:09:24 - 8:00:56 - ============ Starting epoch 375 ... ============
INFO - 09/03/20 02:09:27 - 8:00:58 - Epoch: [375][0]	Time 2.511 (2.511)	Data 1.789 (1.789)	Loss 2.1212 (2.1212)	Lr: 0.0007
INFO - 09/03/20 02:10:09 - 8:01:41 - Epoch: [375][50]	Time 0.685 (0.883)	Data 0.000 (0.035)	Loss 2.1273 (2.1167)	Lr: 0.0007
INFO - 09/03/20 02:10:41 - 8:02:12 - ============ Starting epoch 376 ... ============
INFO - 09/03/20 02:10:43 - 8:02:15 - Epoch: [376][0]	Time 2.329 (2.329)	Data 1.566 (1.566)	Loss 2.1259 (2.1259)	Lr: 0.0007
INFO - 09/03/20 02:11:26 - 8:02:58 - Epoch: [376][50]	Time 0.685 (0.890)	Data 0.000 (0.031)	Loss 2.0899 (2.1152)	Lr: 0.0006
INFO - 09/03/20 02:11:58 - 8:03:29 - ============ Starting epoch 377 ... ============
INFO - 09/03/20 02:12:00 - 8:03:32 - Epoch: [377][0]	Time 2.382 (2.382)	Data 1.652 (1.652)	Loss 2.1165 (2.1165)	Lr: 0.0006
INFO - 09/03/20 02:12:43 - 8:04:14 - Epoch: [377][50]	Time 0.655 (0.883)	Data 0.000 (0.033)	Loss 2.1276 (2.1181)	Lr: 0.0006
INFO - 09/03/20 02:13:14 - 8:04:46 - ============ Starting epoch 378 ... ============
INFO - 09/03/20 02:13:17 - 8:04:48 - Epoch: [378][0]	Time 2.614 (2.614)	Data 1.854 (1.854)	Loss 2.1090 (2.1090)	Lr: 0.0006
INFO - 09/03/20 02:13:59 - 8:05:30 - Epoch: [378][50]	Time 0.702 (0.881)	Data 0.001 (0.037)	Loss 2.1042 (2.1152)	Lr: 0.0006
INFO - 09/03/20 02:14:32 - 8:06:03 - ============ Starting epoch 379 ... ============
INFO - 09/03/20 02:14:34 - 8:06:06 - Epoch: [379][0]	Time 2.540 (2.540)	Data 1.716 (1.716)	Loss 2.1119 (2.1119)	Lr: 0.0006
INFO - 09/03/20 02:15:16 - 8:06:47 - Epoch: [379][50]	Time 0.658 (0.864)	Data 0.000 (0.034)	Loss 2.1218 (2.1147)	Lr: 0.0006
INFO - 09/03/20 02:15:49 - 8:07:20 - ============ Starting epoch 380 ... ============
INFO - 09/03/20 02:15:52 - 8:07:23 - Epoch: [380][0]	Time 2.912 (2.912)	Data 1.756 (1.756)	Loss 2.1342 (2.1342)	Lr: 0.0006
INFO - 09/03/20 02:16:31 - 8:08:03 - Epoch: [380][50]	Time 0.684 (0.830)	Data 0.000 (0.035)	Loss 2.1199 (2.1131)	Lr: 0.0006
INFO - 09/03/20 02:17:07 - 8:08:39 - ============ Starting epoch 381 ... ============
INFO - 09/03/20 02:17:10 - 8:08:42 - Epoch: [381][0]	Time 2.980 (2.980)	Data 1.740 (1.740)	Loss 2.1042 (2.1042)	Lr: 0.0006
INFO - 09/03/20 02:17:47 - 8:09:18 - Epoch: [381][50]	Time 0.714 (0.773)	Data 0.001 (0.034)	Loss 2.1114 (2.1162)	Lr: 0.0006
INFO - 09/03/20 02:18:25 - 8:09:57 - ============ Starting epoch 382 ... ============
INFO - 09/03/20 02:18:28 - 8:10:00 - Epoch: [382][0]	Time 2.815 (2.815)	Data 1.787 (1.787)	Loss 2.1180 (2.1180)	Lr: 0.0006
INFO - 09/03/20 02:19:02 - 8:10:33 - Epoch: [382][50]	Time 0.633 (0.718)	Data 0.000 (0.035)	Loss 2.1176 (2.1190)	Lr: 0.0006
INFO - 09/03/20 02:19:42 - 8:11:14 - ============ Starting epoch 383 ... ============
INFO - 09/03/20 02:19:45 - 8:11:16 - Epoch: [383][0]	Time 2.422 (2.422)	Data 1.724 (1.724)	Loss 2.1271 (2.1271)	Lr: 0.0006
INFO - 09/03/20 02:20:19 - 8:11:50 - Epoch: [383][50]	Time 0.697 (0.711)	Data 0.001 (0.034)	Loss 2.1175 (2.1185)	Lr: 0.0006
INFO - 09/03/20 02:21:00 - 8:12:31 - ============ Starting epoch 384 ... ============
INFO - 09/03/20 02:21:02 - 8:12:33 - Epoch: [384][0]	Time 2.621 (2.621)	Data 1.913 (1.913)	Loss 2.1286 (2.1286)	Lr: 0.0006
INFO - 09/03/20 02:21:36 - 8:13:07 - Epoch: [384][50]	Time 0.652 (0.716)	Data 0.000 (0.038)	Loss 2.1164 (2.1153)	Lr: 0.0006
INFO - 09/03/20 02:22:17 - 8:13:48 - ============ Starting epoch 385 ... ============
INFO - 09/03/20 02:22:19 - 8:13:50 - Epoch: [385][0]	Time 2.550 (2.550)	Data 1.853 (1.853)	Loss 2.1029 (2.1029)	Lr: 0.0006
INFO - 09/03/20 02:22:53 - 8:14:24 - Epoch: [385][50]	Time 0.816 (0.715)	Data 0.000 (0.037)	Loss 2.1035 (2.1128)	Lr: 0.0006
INFO - 09/03/20 02:23:33 - 8:15:04 - ============ Starting epoch 386 ... ============
INFO - 09/03/20 02:23:35 - 8:15:07 - Epoch: [386][0]	Time 2.319 (2.319)	Data 1.610 (1.610)	Loss 2.1135 (2.1135)	Lr: 0.0006
INFO - 09/03/20 02:24:10 - 8:15:42 - Epoch: [386][50]	Time 0.827 (0.733)	Data 0.001 (0.032)	Loss 2.0923 (2.1160)	Lr: 0.0006
INFO - 09/03/20 02:24:50 - 8:16:21 - ============ Starting epoch 387 ... ============
INFO - 09/03/20 02:24:53 - 8:16:24 - Epoch: [387][0]	Time 2.427 (2.427)	Data 1.790 (1.790)	Loss 2.1018 (2.1018)	Lr: 0.0006
INFO - 09/03/20 02:25:28 - 8:17:00 - Epoch: [387][50]	Time 0.901 (0.747)	Data 0.000 (0.035)	Loss 2.0969 (2.1126)	Lr: 0.0006
INFO - 09/03/20 02:26:07 - 8:17:38 - ============ Starting epoch 388 ... ============
INFO - 09/03/20 02:26:10 - 8:17:41 - Epoch: [388][0]	Time 2.857 (2.857)	Data 2.097 (2.097)	Loss 2.1099 (2.1099)	Lr: 0.0006
INFO - 09/03/20 02:26:45 - 8:18:17 - Epoch: [388][50]	Time 0.781 (0.756)	Data 0.001 (0.042)	Loss 2.1210 (2.1200)	Lr: 0.0006
INFO - 09/03/20 02:27:25 - 8:18:56 - ============ Starting epoch 389 ... ============
INFO - 09/03/20 02:27:27 - 8:18:58 - Epoch: [389][0]	Time 2.296 (2.296)	Data 1.599 (1.599)	Loss 2.1084 (2.1084)	Lr: 0.0006
INFO - 09/03/20 02:28:05 - 8:19:37 - Epoch: [389][50]	Time 1.158 (0.797)	Data 0.001 (0.032)	Loss 2.1021 (2.1164)	Lr: 0.0006
INFO - 09/03/20 02:28:42 - 8:20:13 - ============ Starting epoch 390 ... ============
INFO - 09/03/20 02:28:44 - 8:20:15 - Epoch: [390][0]	Time 2.486 (2.486)	Data 1.779 (1.779)	Loss 2.1318 (2.1318)	Lr: 0.0006
INFO - 09/03/20 02:29:26 - 8:20:57 - Epoch: [390][50]	Time 1.180 (0.872)	Data 0.001 (0.035)	Loss 2.0862 (2.1161)	Lr: 0.0006
INFO - 09/03/20 02:29:58 - 8:21:29 - ============ Starting epoch 391 ... ============
INFO - 09/03/20 02:30:00 - 8:21:32 - Epoch: [391][0]	Time 2.335 (2.335)	Data 1.596 (1.596)	Loss 2.1095 (2.1095)	Lr: 0.0006
INFO - 09/03/20 02:30:44 - 8:22:15 - Epoch: [391][50]	Time 0.666 (0.893)	Data 0.001 (0.032)	Loss 2.0978 (2.1143)	Lr: 0.0006
INFO - 09/03/20 02:31:15 - 8:22:46 - ============ Starting epoch 392 ... ============
INFO - 09/03/20 02:31:18 - 8:22:49 - Epoch: [392][0]	Time 2.268 (2.268)	Data 1.558 (1.558)	Loss 2.1150 (2.1150)	Lr: 0.0006
INFO - 09/03/20 02:32:00 - 8:23:32 - Epoch: [392][50]	Time 0.680 (0.885)	Data 0.001 (0.031)	Loss 2.1003 (2.1163)	Lr: 0.0006
INFO - 09/03/20 02:32:32 - 8:24:03 - ============ Starting epoch 393 ... ============
INFO - 09/03/20 02:32:34 - 8:24:05 - Epoch: [393][0]	Time 2.437 (2.437)	Data 1.741 (1.741)	Loss 2.1019 (2.1019)	Lr: 0.0006
INFO - 09/03/20 02:33:17 - 8:24:48 - Epoch: [393][50]	Time 0.694 (0.884)	Data 0.001 (0.034)	Loss 2.1015 (2.1182)	Lr: 0.0006
INFO - 09/03/20 02:33:49 - 8:25:20 - ============ Starting epoch 394 ... ============
INFO - 09/03/20 02:33:51 - 8:25:23 - Epoch: [394][0]	Time 2.787 (2.787)	Data 2.020 (2.020)	Loss 2.1126 (2.1126)	Lr: 0.0006
INFO - 09/03/20 02:34:34 - 8:26:06 - Epoch: [394][50]	Time 0.665 (0.898)	Data 0.001 (0.040)	Loss 2.1225 (2.1129)	Lr: 0.0006
INFO - 09/03/20 02:35:06 - 8:26:38 - ============ Starting epoch 395 ... ============
INFO - 09/03/20 02:35:09 - 8:26:40 - Epoch: [395][0]	Time 2.489 (2.489)	Data 1.731 (1.731)	Loss 2.1122 (2.1122)	Lr: 0.0006
INFO - 09/03/20 02:35:50 - 8:27:22 - Epoch: [395][50]	Time 0.692 (0.865)	Data 0.001 (0.034)	Loss 2.1025 (2.1173)	Lr: 0.0006
INFO - 09/03/20 02:36:23 - 8:27:54 - ============ Starting epoch 396 ... ============
INFO - 09/03/20 02:36:26 - 8:27:57 - Epoch: [396][0]	Time 2.893 (2.893)	Data 1.774 (1.774)	Loss 2.1043 (2.1043)	Lr: 0.0006
INFO - 09/03/20 02:37:07 - 8:28:38 - Epoch: [396][50]	Time 0.732 (0.862)	Data 0.000 (0.035)	Loss 2.1272 (2.1153)	Lr: 0.0006
INFO - 09/03/20 02:37:41 - 8:29:13 - ============ Starting epoch 397 ... ============
INFO - 09/03/20 02:37:44 - 8:29:16 - Epoch: [397][0]	Time 2.966 (2.966)	Data 1.767 (1.767)	Loss 2.1139 (2.1139)	Lr: 0.0006
INFO - 09/03/20 02:38:22 - 8:29:54 - Epoch: [397][50]	Time 0.689 (0.806)	Data 0.000 (0.035)	Loss 2.1049 (2.1160)	Lr: 0.0006
INFO - 09/03/20 02:39:00 - 8:30:31 - ============ Starting epoch 398 ... ============
INFO - 09/03/20 02:39:03 - 8:30:34 - Epoch: [398][0]	Time 2.771 (2.771)	Data 1.687 (1.687)	Loss 2.1180 (2.1180)	Lr: 0.0006
INFO - 09/03/20 02:39:37 - 8:31:09 - Epoch: [398][50]	Time 0.692 (0.729)	Data 0.000 (0.033)	Loss 2.0834 (2.1081)	Lr: 0.0006
INFO - 09/03/20 02:40:18 - 8:31:49 - ============ Starting epoch 399 ... ============
INFO - 09/03/20 02:40:21 - 8:31:52 - Epoch: [399][0]	Time 2.721 (2.721)	Data 1.994 (1.994)	Loss 2.0972 (2.0972)	Lr: 0.0006
INFO - 09/03/20 02:40:55 - 8:32:26 - Epoch: [399][50]	Time 0.657 (0.720)	Data 0.000 (0.040)	Loss 2.1086 (2.1212)	Lr: 0.0006
